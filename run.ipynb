{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e8fd6ab",
   "metadata": {},
   "source": [
    "## From Movie Frames to the Brainâ€¦ and Back!\n",
    "\n",
    "**Student:** Florian David | florian.david@epfl.ch  \n",
    "**Institution:** Neuro-X, EPFL  \n",
    "**Last Update:** 21/06/2024  \n",
    "**Host Lab:** Medical Image Processing Lab (MIP:Lab), EPFL  \n",
    "**Supervisor:** Michael Chan  \n",
    "\n",
    "---\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "This project explores the relationship between visual stimuli from natural movies and their corresponding neural responses captured through fMRI recordings. This work aims to understand and predict brain activity patterns in response to movie watching.  \n",
    "\n",
    "This notebook is structured to train and test a deep neural network on already preprocessed data. The parameters in this notebook are the ones used to obtain the best results. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6051d3e6",
   "metadata": {},
   "source": [
    "Necessary imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c55f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import *\n",
    "from models import *\n",
    "from visualisation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e4cc36",
   "metadata": {},
   "source": [
    "Data loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3344615",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ID = 7774\n",
    "trainset, valset, testset = get_dataset(dataset_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7c85c6",
   "metadata": {},
   "source": [
    "Model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acfaaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "input = trainset['videos']\n",
    "label = trainset['fMRIs']\n",
    "mask_size = label.shape[1]\n",
    "model = EncoderDecoder(mask_size)\n",
    "num_epochs = 13\n",
    "lr = 1e-4\n",
    "criterion = ED_Loss(encoder_weight = 0.75)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "batch_size = 16\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "save_model_as = 'best_model'\n",
    "pretrained_decoder = None\n",
    "start_epoch = 1\n",
    "start_loss = None\n",
    "model_to_train = 'encoder_decoder'\n",
    "\n",
    "# Training loop\n",
    "model, history = train_model(input, label, model, num_epochs, lr, criterion, optimizer, batch_size, device, save_model_as, pretrained_decoder, start_epoch, start_loss, model_to_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d698670",
   "metadata": {},
   "source": [
    "Model testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0461ce8-8654-484c-b70d-3d197bf0ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing parameters\n",
    "inputs = testset['videos']\n",
    "labels = testset['fMRIs']\n",
    "model_to_test = model_to_train\n",
    "statistical_testing = True\n",
    "\n",
    "# Testing loop\n",
    "results = test_model(inputs, labels, model, criterion, device, pretrained_decoder, model_to_test, statistical_testing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
