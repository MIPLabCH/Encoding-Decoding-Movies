{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ca92e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c29cc0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede142de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag test decoder\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3\"\n",
    "\n",
    "from dataset_new import *\n",
    "from models_new_2 import *\n",
    "from visualisation_new_2 import *\n",
    "from perturbation import *\n",
    "\n",
    "\n",
    "\n",
    "### data loading ###\n",
    "\n",
    "dataset_ID = 6661 # ID of a specific dataset. 6661 refer to preprocessed data with a mask of shape (4609,). 6660 refers to preprocessed data with a mask of shape (15364,)\n",
    "mask_size = 4609 # number of voxels in the preprocessed fMRI data. either 4609 or 15364\n",
    "#trainset, valset, testset = get_dataset(dataset_ID, mask_size) # data are loaded into dictionaries\n",
    "\n",
    "trainset, valset, testset = get_dataset2(dataset_ID)\n",
    "\n",
    "print_dict_tree(testset)\n",
    "\n",
    "'''\n",
    "testset2 = {\n",
    "    \"fMRIs\": {\n",
    "        \"Sintel\": np.load(\"processed_data/sub-S01/test/Sintel.npy\"),\n",
    "        \"Payload\": np.load(\"processed_data/sub-S01/test/Payload.npy\"),\n",
    "        \"Chatter\": np.load(\"processed_data/sub-S01/test/Chatter.npy\")\n",
    "    },\n",
    "    \"videos\": {\n",
    "        \"Sintel\": np.load(\"processed_data/videos/test/Sintel.npy\"),\n",
    "        \"Payload\": np.load(\"processed_data/videos/test/Payload.npy\"),\n",
    "        \"Chatter\": np.load(\"processed_data/videos/test/Chatter.npy\")\n",
    "    }\n",
    "}\n",
    "\n",
    "print_dict_tree(testset2)\n",
    "'''\n",
    "\n",
    "def prepare_temporal_data_by_movie(fmri_data_dict, video_data_dict, window_size=3):\n",
    "    \"\"\"\n",
    "    Prepare temporal data with overlapping windows of TRs and their corresponding middle frames,\n",
    "    separately for each movie.\n",
    "    \n",
    "    Args:\n",
    "        fmri_data_dict: Dictionary of fMRI data per movie, where keys are movie names and \n",
    "                        values have shape (n_trs, mask_size)\n",
    "        video_data_dict: Dictionary of video frames per movie, where keys are movie names and \n",
    "                         values have shape (n_trs, 3, 112, 112, 32)\n",
    "        window_size: Number of consecutive TRs to use\n",
    "    \n",
    "    Returns:\n",
    "        tr_windows_dict: Dictionary of windows of consecutive TRs per movie\n",
    "        frame_targets_dict: Dictionary of middle frames for each TR in the windows per movie\n",
    "    \"\"\"\n",
    "    tr_windows_dict = {}\n",
    "    frame_targets_dict = {}\n",
    "    \n",
    "    # Process each movie separately\n",
    "    for movie_name in fmri_data_dict.keys():\n",
    "        fmri_data = fmri_data_dict[movie_name]\n",
    "        all_frames = video_data_dict[movie_name]\n",
    "        \n",
    "        n_trs = fmri_data.shape[0]\n",
    "        tr_windows = []\n",
    "        frame_targets = []\n",
    "        \n",
    "        # Create sliding windows of TRs\n",
    "        for i in range(n_trs - window_size + 1):\n",
    "            # Get window of TRs\n",
    "            tr_window = fmri_data[i:i+window_size]\n",
    "            tr_windows.append(tr_window)\n",
    "            \n",
    "            # Get middle frame for each TR in the window\n",
    "            frames_for_window = []\n",
    "            for j in range(window_size):\n",
    "                # Get middle frame (assuming 32 frames per TR)\n",
    "                middle_frame_idx = 15  # Middle of 32 frames (0-indexed, so 15 is the 16th frame)\n",
    "                middle_frame = all_frames[i+j, :, :, :, middle_frame_idx]\n",
    "                frames_for_window.append(middle_frame)\n",
    "            \n",
    "            frame_targets.append(np.stack(frames_for_window))\n",
    "        \n",
    "        # Store results for this movie\n",
    "        tr_windows_dict[movie_name] = np.array(tr_windows)\n",
    "        frame_targets_dict[movie_name] = np.array(frame_targets)\n",
    "    \n",
    "    return tr_windows_dict, frame_targets_dict\n",
    "\n",
    "\n",
    "window_size = 3 \n",
    "\n",
    "testset3 = {\n",
    "    \"fMRIs\": {},\n",
    "    \"videos\": {}\n",
    "}\n",
    "\n",
    "testset3['fMRIs'], testset3['videos'] = prepare_temporal_data_by_movie(\n",
    "    testset['fMRIs'], \n",
    "    testset['videos'], \n",
    "    window_size=window_size\n",
    ")\n",
    "\n",
    "print_dict_tree(testset3)\n",
    "print(\"testset3 videos =\", testset3[\"videos\"].keys())\n",
    "\n",
    "\n",
    "\n",
    "specific_frames_train = [681,681,681, 248,248,248, 3008,3008,3008, 1561, 1561, 1561, 1821, 1821, 1821, 2639, 2639, 2639, 467,467,467, 3558,3558,3558, 2173,2173,2173, 2119, 2119, 2119]\n",
    "testset_small = {\n",
    "    \"fMRIs\": {\n",
    "        \"subdict1\": {}\n",
    "    },\n",
    "    \"videos\": {\n",
    "        \"subdict1\": {}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Process training data to create temporal windows\n",
    "#testset_small['fMRIs'][\"subdict1\"], testset_small['videos'][\"subdict1\"] = prepare_temporal_data(\n",
    "#    testset['fMRIs'][specific_frames_train], \n",
    "#    testset['videos'][specific_frames_train], \n",
    "#    window_size=window_size\n",
    "#)\n",
    "\n",
    "\n",
    "#tag test decoder\n",
    "\n",
    "\n",
    "def test_new_decoder(real=True, model_name='decoder_4609_1650', test_on_train=False, test_input = testset['fMRIs'], test_label = testset['videos'], add_name='', regions = [], temporal=False):\n",
    "    '''\n",
    "    Tests the decoder\n",
    "    if real=False (default) -> tests on brain activity coming from encoder\n",
    "    if real=True -> tests on real brain activity\n",
    "    model_name is the name of the file with the model to be used\n",
    "    test_on_train is for testing on the trainset\n",
    "    test_input has the fMRIs for testing. Should be a dictionary with one subdictionary for each film.\n",
    "    Each subdictionary is shaped (N, 4609) where N is the number of TRs for that film\n",
    "    test_label has the films. Also one subdictionary for each film\n",
    "    add_name is for adding something to the end of the name so the output isnt just the names of the film and model, so that doesnt get overwritten\n",
    "    regions is an array with all the ids of the regions we wish to turn off for this run, for instance\n",
    "    regions=[1,4,5] would turn off regions 1, 4 and 5. Look at turn_off_regions for what is the region of each ID\n",
    "    '''\n",
    "    print(\"testing decoder\", model_name)\n",
    "\n",
    "#    if regions != []:\n",
    "#        fmri_regions_off = test_input.copy()\n",
    "#        for video_name in test_input.keys():\n",
    "#            fmri_regions_off[video_name] = turn_off_regions(test_input[video_name], regions)\n",
    "#        test_input = fmri_regions_off\n",
    "    \n",
    "\n",
    "    #load decoder part of encoder decoder\n",
    "    model = TemporalDecoder(mask_size)\n",
    "#    model = Decoder(mask_size)\n",
    "    #save_model_as = 'decoder_4609_50'\n",
    "    #save_model_as = 'decoder_4609_1650'\n",
    "    state_dict = torch.load(model_name)\n",
    "    model.load_state_dict(state_dict)\n",
    "    #model = model1.decoder\n",
    "\n",
    "    #load data\n",
    "#    if real:\n",
    "#        test_input = testset['fMRIs']\n",
    "#        test_label = testset['videos']\n",
    "#    else:\n",
    "    if not real:\n",
    "        test_input = model1.encoder(testset['videos'])\n",
    "        test_label = testset['videos']\n",
    "\n",
    "    if test_on_train:\n",
    "        num_samples = trainset[\"fMRIs\"].shape[0]\n",
    "\n",
    "        # Generate random indices based on that number\n",
    "        random_indices = np.random.choice(num_samples, size=30, replace=False)\n",
    "\n",
    "        # Create the testset with random samples\n",
    "        testset2 = {\n",
    "            \"fMRIs\": {\n",
    "                \"test\": trainset[\"fMRIs\"][random_indices]  # Shape will be (30, 4609)\n",
    "            },\n",
    "            \"videos\": {\n",
    "                \"test\": trainset[\"videos\"][random_indices]  # Shape will be (30, 3, 112, 112, 32)\n",
    "            }\n",
    "        }\n",
    "        test_input = testset2['fMRIs']\n",
    "        test_label = testset2['videos']\n",
    "\n",
    "\n",
    "    criterion = Temporal_D_Loss()\n",
    "#    criterion = D_Loss()\n",
    "    device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "    pretrained_decoder=None\n",
    "    model_to_test='decoder'\n",
    "    statistical_testing = False\n",
    "    display_plots = True\n",
    "    save_plots = False\n",
    "\n",
    "    test_model(test_input, test_label, model, criterion, device, pretrained_decoder, model_to_test, statistical_testing, display_plots, save_plots, model_name=model_name + add_name, temporal=temporal)\n",
    "    return\n",
    "\n",
    "\n",
    "#test_new_decoder(real=True, model_name='/media/RCPNAS/MIP/Michael/students_work/rodrigo/temporal_decoder_4609_350', test_input = testset3['fMRIs'], test_label = testset3['videos'], regions=[], add_name='', temporal=True)\n",
    "\n",
    "test_new_decoder(real=True, model_name='/media/RCPNAS/MIP/Michael/students_work/rodrigo/temporal_decoder_4609_351_TRwindow5', test_input = testset3['fMRIs'], test_label = testset3['videos'], regions=[], add_name='', temporal=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cf422b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435a92e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae16ae2a",
   "metadata": {},
   "source": [
    "# All code being ran for current perturbation (the losses for plotting are not updated though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d58c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### necessary imports ###\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3\"\n",
    "\n",
    "from dataset_new import *\n",
    "from models_new_2 import *\n",
    "from visualisation_new_2 import *\n",
    "from perturbation import *\n",
    "\n",
    "\n",
    "### data loading ###\n",
    "\n",
    "dataset_ID = 6661 # ID of a specific dataset. 6661 refer to preprocessed data with a mask of shape (4609,). 6660 refers to preprocessed data with a mask of shape (15364,)\n",
    "mask_size = 4609 # number of voxels in the preprocessed fMRI data. either 4609 or 15364\n",
    "trainset, valset, testset = get_dataset(dataset_ID, mask_size) # data are loaded into dictionaries\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------end of cell 1--------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#test_new_decoder(real=True, model_name='decoder_4609_1650', test_on_train=False, test_input = testset['fMRIs'], test_label = testset['videos'], add_name='', regions = [], mask_slice=None)\n",
    "\n",
    "def extract_frames(testset, specific_frames):\n",
    "    \"\"\"\n",
    "    Extract specific frames from testset and combine them into a single array.\n",
    "    \n",
    "    Parameters:\n",
    "    - testset: Dictionary with 'fMRIs' and 'videos' keys, each containing subdictionaries for each movie\n",
    "    - specific_frames: Dictionary mapping movie names to lists of frame indices to extract\n",
    "    \n",
    "    Returns:\n",
    "    - filtered_data: Dictionary with 'fMRIs' and 'videos' keys, each containing concatenated arrays of selected frames\n",
    "    \"\"\"\n",
    "    # Create lists to store selected frames\n",
    "    selected_fmris = []\n",
    "    selected_videos = []\n",
    "    \n",
    "    # Loop through each movie in specific_frames\n",
    "    for movie_name, frames in specific_frames.items():\n",
    "        # Check if the movie exists in testset\n",
    "        if movie_name not in testset['fMRIs'] or movie_name not in testset['videos']:\n",
    "            print(f\"Warning: {movie_name} not found in testset\")\n",
    "            continue\n",
    "        \n",
    "        # Get fMRI and video data for this movie\n",
    "        movie_fmri = testset['fMRIs'][movie_name]\n",
    "        movie_video = testset['videos'][movie_name]\n",
    "        \n",
    "        # Loop through each frame index\n",
    "        for frame in frames:\n",
    "            # Check if frame index is valid\n",
    "            if frame >= len(movie_fmri):\n",
    "                print(f\"Warning: Frame {frame} out of range for {movie_name} (max={len(movie_fmri)-1})\")\n",
    "                continue\n",
    "            \n",
    "            # Add frame to selected lists\n",
    "            selected_fmris.append(movie_fmri[frame])\n",
    "            selected_videos.append(movie_video[frame])\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    if selected_fmris:\n",
    "        fmris_array = np.array(selected_fmris)\n",
    "        videos_array = np.array(selected_videos)\n",
    "    else:\n",
    "        print(\"No valid frames found\")\n",
    "        return None\n",
    "    \n",
    "    # Create filtered dataset with all frames in a single array\n",
    "    filtered_data = {\n",
    "        'fMRIs': {'combined': fmris_array},\n",
    "        'videos': {'combined': videos_array}\n",
    "    }\n",
    "    \n",
    "    # Print the structure of the filtered dataset\n",
    "    print(\"Filtered dataset structure:\")\n",
    "    print(\"fMRIs\")\n",
    "    for movie, data in filtered_data['fMRIs'].items():\n",
    "        print(f\"  {movie} (shape: {data.shape})\")\n",
    "    print(\"videos\")\n",
    "    for movie, data in filtered_data['videos'].items():\n",
    "        print(f\"  {movie} (shape: {data.shape})\")\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def extract_frames_train(trainset, specific_frames_train):\n",
    "    \"\"\"\n",
    "    Extract specific frames from testset and combine them into a single array.\n",
    "    \n",
    "    Parameters:\n",
    "    - trainset: Dictionary with 'fMRIs' and 'videos' keys, each containing subdictionaries for each movie\n",
    "    - specific_frames: Dictionary mapping movie names to lists of frame indices to extract\n",
    "    \n",
    "    Returns:\n",
    "    - filtered_data: Dictionary with 'fMRIs' and 'videos' keys, each containing concatenated arrays of selected frames\n",
    "    \"\"\"\n",
    "    # Create lists to store selected frames\n",
    "    selected_fmris = []\n",
    "    selected_videos = []\n",
    "    \n",
    "    # Get fMRI and video data for this movie\n",
    "    movie_fmri = trainset['fMRIs']\n",
    "    movie_video = trainset['videos']\n",
    "    \n",
    "    # Loop through each frame index\n",
    "    for frame in specific_frames_train:\n",
    "        # Check if frame index is valid\n",
    "        if frame >= len(movie_fmri):\n",
    "            print(f\"Warning: Frame {frame} out of range (max={len(movie_fmri)-1})\")\n",
    "            continue\n",
    "        \n",
    "        # Add frame to selected lists\n",
    "        selected_fmris.append(movie_fmri[frame])\n",
    "        selected_videos.append(movie_video[frame])\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    if selected_fmris:\n",
    "        fmris_array = np.array(selected_fmris)\n",
    "        videos_array = np.array(selected_videos)\n",
    "    else:\n",
    "        print(\"No valid frames found\")\n",
    "        return None\n",
    "    \n",
    "    # Create filtered dataset with all frames in a single array\n",
    "    filtered_data = {\n",
    "        'fMRIs': {'combined': fmris_array},\n",
    "        'videos': {'combined': videos_array}\n",
    "    }\n",
    "    \n",
    "    # Print the structure of the filtered dataset\n",
    "    print(\"Filtered dataset structure:\")\n",
    "    print(\"fMRIs\")\n",
    "    for movie, data in filtered_data['fMRIs'].items():\n",
    "        print(f\"  {movie} (shape: {data.shape})\")\n",
    "    print(\"videos\")\n",
    "    for movie, data in filtered_data['videos'].items():\n",
    "        print(f\"  {movie} (shape: {data.shape})\")\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def extract_frames_train_new(specific_frames_train):\n",
    "    \"\"\"\n",
    "    Extract specific frames from trainset of new dataset and combine them into a single array.\n",
    "    \n",
    "    Parameters:\n",
    "    - testset: Dictionary with 'fMRIs' and 'videos' keys, each containing subdictionaries for each movie\n",
    "    - specific_frames: Dictionary mapping movie names to lists of frame indices to extract\n",
    "    \n",
    "    Returns:\n",
    "    - filtered_data: Dictionary with 'fMRIs' and 'videos' keys, each containing concatenated arrays of selected frames\n",
    "    \"\"\"\n",
    "    # Create lists to store selected frames\n",
    "    selected_fmris = []\n",
    "    selected_videos = []\n",
    "    \n",
    "    # Get fMRI and video data for this movie\n",
    "    #movie_fmri = trainset['fMRIs']\n",
    "    #movie_video = trainset['videos']\n",
    "\n",
    "    fmris = np.load('processed_data/sub-S32/train.npy')\n",
    "    videos = np.load('processed_data/videos/videos.npy')\n",
    "    \n",
    "    # Loop through each frame index\n",
    "    for frame in specific_frames_train:\n",
    "        # Check if frame index is valid\n",
    "        if frame >= len(fmris):\n",
    "            print(f\"Warning: Frame {frame} out of range (max={len(fmris)-1})\")\n",
    "            continue\n",
    "        \n",
    "        # Add frame to selected lists\n",
    "        selected_fmris.append(fmris[frame])\n",
    "        selected_videos.append(videos[frame])\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "#    if selected_fmris:\n",
    "#        fmris_array = np.array(selected_fmris)\n",
    "#        videos_array = np.array(selected_videos)\n",
    "#    else:\n",
    "#        print(\"No valid frames found\")\n",
    "#        return None\n",
    "    \n",
    "    # Create filtered dataset with all frames in a single array\n",
    "    filtered_data = {\n",
    "        'fMRIs': {'combined': selected_fmris},\n",
    "        'videos': {'combined': selected_videos}\n",
    "    }\n",
    "    \n",
    "    # Print the structure of the filtered dataset\n",
    "    print(\"Filtered dataset structure:\")\n",
    "    print(\"fMRIs\")\n",
    "    for movie, data in filtered_data['fMRIs'].items():\n",
    "        print(f\"  {movie} (shape: {len(data)})\")\n",
    "    print(\"videos\")\n",
    "    for movie, data in filtered_data['videos'].items():\n",
    "        print(f\"  {movie} (shape: {len(data)})\")\n",
    "    \n",
    "    print(filtered_data['videos'])\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "specific_frames = {\n",
    "    'AfterTheRain': [42],\n",
    "    'BetweenViewings': [111],\n",
    "    'Chatter': [21],\n",
    "    'FirstBite': [33],          #gotta change this one\n",
    "    'LessonLearned': [15, 36],\n",
    "    'Payload': [18, 30],\n",
    "    'Spaceman': [12],\n",
    "    'TearsOfSteel': [39],\n",
    "    'YouAgain': [300, 495]\n",
    "}\n",
    "\n",
    "specific_frames_train = [681, 248, 3008, 1561, 1821, 2639, 467, 3558, 2173, 2119]\n",
    "#frame 2119 from the trainset is a very nice frame with a face\n",
    "\n",
    "\n",
    "# Call the function to create the filtered dataset\n",
    "filtered_testset = extract_frames(testset, specific_frames)\n",
    "filtered_trainset = extract_frames_train(trainset, specific_frames_train)\n",
    "\n",
    "trainset2 = {}\n",
    "trainset2['fMRIs'] = np.memmap(f'encoder_dataset_{dataset_ID}/trainset/fMRIs.npy', dtype='float32', mode='r')\n",
    "trainset2['videos'] = np.memmap(f'encoder_dataset_{dataset_ID}/trainset/videos.npy', dtype='float32', mode='r')\n",
    "\n",
    "print(\"trainset fmris shape =\", trainset2['fMRIs'].shape)\n",
    "print(\"trainset videos shape =\", trainset2['videos'].shape)\n",
    "\n",
    "'''\n",
    "trainset_new = {}\n",
    "#trainset_new['fMRIs'] = np.memmap(f'processed_data/sub-S32/train.npy', dtype='float32', mode='r').reshape(-1, mask_size)\n",
    "#trainset_new['videos'] = np.memmap(f'processed_data/videos/videos.npy', dtype='float32', mode='r').reshape(-1, 3, 112, 112, 32)\n",
    "\n",
    "trainset_new['fMRIs'] = np.load('processed_data/sub-average/train.npy')\n",
    "trainset_new['videos'] = np.load('processed_data/videos/videos.npy')\n",
    "\n",
    "print(\"trainset_new fmris shape =\", trainset_new['fMRIs'].shape)\n",
    "print(\"trainset_new videos shape =\", trainset_new['videos'].shape)\n",
    "\n",
    "filtered_trainset_new = extract_frames_train(trainset_new, specific_frames_train)     #made so the fmri data is on a normalized subject\n",
    "\n",
    "#print_dict_tree(filtered_testset)\n",
    "\n",
    "#test_new_decoder(real=True, model_name='decoder_4609_1650', test_on_train=False, test_input = testset['fMRIs'], test_label = testset['videos'], add_name='', regions = [], mask_slice=None)\n",
    "\n",
    "#tag test filtered\n",
    "#test_new_decoder(real=True, model_name='decoder_4609_350', test_input = filtered_testset['fMRIs'], test_label = filtered_testset['videos'], add_name='_mask_slice20', save_plots=False, mask_slice=0, all_frames=True)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------end of cell 2--------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#tag blocks\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#i took out the comment here\n",
    "\n",
    "\n",
    "\n",
    "def load_and_reshape_data(file_path):\n",
    "    \"\"\"Load region data and reshape to 3D\"\"\"\n",
    "    regions_2d = np.load(file_path, mmap_mode='r')\n",
    "    print(\"regions_2d shape =\", regions_2d.shape)\n",
    "    regions_3d = regions_2d.reshape(91, 109, 91)\n",
    "    return regions_3d\n",
    "\n",
    "\n",
    "def find_bounds(data_3d):\n",
    "    \"\"\"\n",
    "    Find the minimum and maximum coordinates in each dimension where brain data exists.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_3d : numpy.ndarray\n",
    "        3D brain data where non-zero values represent brain regions\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        ((x_min, x_max), (y_min, y_max), (z_min, z_max))\n",
    "        The minimum and maximum coordinates in each dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find the indices of all non-zero voxels (brain regions)\n",
    "    non_zero_voxels = np.where(data_3d > 0)\n",
    "    \n",
    "    # If there are no non-zero voxels, return the full dimensions\n",
    "    if len(non_zero_voxels[0]) == 0:\n",
    "        print(\"Warning: No non-zero values found in the data\")\n",
    "        return (0, data_3d.shape[0]-1), (0, data_3d.shape[1]-1), (0, data_3d.shape[2]-1)\n",
    "    \n",
    "    # Get the minimum and maximum indices in each dimension\n",
    "    x_min, x_max = np.min(non_zero_voxels[0]), np.max(non_zero_voxels[0])\n",
    "    y_min, y_max = np.min(non_zero_voxels[1]), np.max(non_zero_voxels[1])\n",
    "    z_min, z_max = np.min(non_zero_voxels[2]), np.max(non_zero_voxels[2])\n",
    "    #print(\"non_zero_voxels =\", non_zero_voxels)\n",
    "    #print(\"non_zero_voxels[0] =\", non_zero_voxels[0])\n",
    "    #print(\"non_zero_voxels[1] =\", non_zero_voxels[1])\n",
    "    #print(\"non_zero_voxels[2] =\", non_zero_voxels[2])\n",
    "    \n",
    "    print(f\"Brain boundaries found:\")\n",
    "    print(f\"  X range: {x_min} to {x_max} (width: {x_max-x_min+1})\")\n",
    "    print(f\"  Y range: {y_min} to {y_max} (height: {y_max-y_min+1})\")\n",
    "    print(f\"  Z range: {z_min} to {z_max} (depth: {z_max-z_min+1})\")\n",
    "    \n",
    "    return (x_min, x_max), (y_min, y_max), (z_min, z_max)\n",
    "\n",
    "\n",
    "def visualize_blocks(data_3d, blocks, num_blocks=(3, 3, 3), selected_block=None, figsize=None):\n",
    "    \"\"\"\n",
    "    Visualize brain blocks using maximum intensity projection for each z-layer\n",
    "    Shows axial views for each layer along the z-dimension\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_3d : numpy.ndarray\n",
    "        3D brain data\n",
    "    blocks : dict\n",
    "        Dictionary mapping block IDs to block boundaries\n",
    "    num_blocks : tuple\n",
    "        Number of blocks along each dimension (x, y, z)\n",
    "    selected_block : int, optional\n",
    "        If provided, highlight this block\n",
    "    figsize : tuple, optional\n",
    "        Figure size, if None will be calculated based on z-dimension blocks\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as patches\n",
    "    \n",
    "    # Unpack the number of blocks in each dimension\n",
    "    nx, ny, nz = num_blocks\n",
    "    \n",
    "    # If figsize is not specified, calculate it based on number of z layers\n",
    "    if figsize is None:\n",
    "        figsize = (6 * nz, 6)\n",
    "    \n",
    "    # Create the figure with the appropriate number of subplots (one per z-layer)\n",
    "    fig, axes = plt.subplots(1, nz, figsize=figsize)\n",
    "    if nz == 1:\n",
    "        axes = [axes]  # Make sure axes is always a list for consistency\n",
    "    \n",
    "    fig.suptitle(f\"Brain Divided into {nx}x{ny}x{nz} Blocks\", fontsize=16)\n",
    "    \n",
    "    # Get block division boundaries\n",
    "    x_divisions = []\n",
    "    y_divisions = []\n",
    "    z_divisions = []\n",
    "    \n",
    "    for block_id, ((x_min, x_max), (y_min, y_max), (z_min, z_max)) in blocks.items():\n",
    "        x_divisions.extend([x_min, x_max])\n",
    "        y_divisions.extend([y_min, y_max])\n",
    "        z_divisions.extend([z_min, z_max])\n",
    "    \n",
    "    # Get unique boundary values\n",
    "    x_divisions = sorted(list(set(x_divisions)))\n",
    "    y_divisions = sorted(list(set(y_divisions)))\n",
    "    z_divisions = sorted(list(set(z_divisions)))\n",
    "    \n",
    "    # Print the division boundaries\n",
    "    print(\"X divisions:\", x_divisions)\n",
    "    print(\"Y divisions:\", y_divisions)\n",
    "    print(\"Z divisions:\", z_divisions)\n",
    "    \n",
    "    # Process each z-layer\n",
    "    for z_idx in range(nz):\n",
    "        # Get z-boundaries for this layer\n",
    "        z_min = z_divisions[z_idx]\n",
    "        z_max = z_divisions[z_idx + 1]\n",
    "        \n",
    "        # Create layer name with actual z-range\n",
    "        layer_name = f\"Layer {z_idx} (z={z_min}-{z_max-1})\"\n",
    "        \n",
    "        # Extract the data for this z-layer\n",
    "        layer_data = data_3d[:, :, z_min:z_max]\n",
    "        \n",
    "        # Create maximum intensity projection along z-axis for just this layer\n",
    "        layer_projection = np.max(layer_data > 0, axis=2).astype(float)\n",
    "        print(f\"Max layer_projection for layer {z_idx}=\", np.max(layer_projection))\n",
    "        \n",
    "        # Plot the projection\n",
    "        im = axes[z_idx].imshow(layer_projection, cmap='gray', origin='lower')\n",
    "        axes[z_idx].set_title(layer_name)\n",
    "        \n",
    "        # Get the data extent for proper coordinate mapping\n",
    "        height, width = layer_projection.shape\n",
    "        \n",
    "        # Add grid lines using data coordinates instead of pixel coordinates\n",
    "        for x in x_divisions[1:-1]:\n",
    "            axes[z_idx].axhline(x, color='cyan', linestyle='-', alpha=0.7, linewidth=1)\n",
    "        \n",
    "        for y in y_divisions[1:-1]:\n",
    "            axes[z_idx].axvline(y, color='cyan', linestyle='-', alpha=0.7, linewidth=1)\n",
    "        \n",
    "        # Add block numbers for this layer\n",
    "        for y_idx in range(ny):\n",
    "            for x_idx in range(nx):\n",
    "                # Calculate block ID (1-based index) using the formula:\n",
    "                # block_id = 1 + x_idx + y_idx * nx + z_idx * nx * ny\n",
    "                block_id = 1 + x_idx + y_idx * nx + z_idx * nx * ny\n",
    "                \n",
    "                # Get x, y boundaries for this block\n",
    "                x_min, x_max = x_divisions[x_idx], x_divisions[x_idx + 1]\n",
    "                y_min, y_max = y_divisions[y_idx], y_divisions[y_idx + 1]\n",
    "                \n",
    "                # Calculate center of block in data coordinates\n",
    "                x_center = (x_min + x_max) / 2\n",
    "                y_center = (y_min + y_max) / 2\n",
    "                \n",
    "                # Add block ID label with a bounding box\n",
    "                text_box = dict(facecolor='black', alpha=0.5, boxstyle='round')\n",
    "                \n",
    "                # Place the text in the center of the block\n",
    "                axes[z_idx].text(y_center, x_center, str(block_id), \n",
    "                               ha='center', va='center', color='yellow', fontweight='bold',\n",
    "                               fontsize=12, bbox=text_box)\n",
    "                \n",
    "                # Highlight the selected block if needed\n",
    "                if selected_block and block_id == selected_block:\n",
    "                    rect = patches.Rectangle((y_min, x_min), y_max-y_min, x_max-x_min, \n",
    "                                          fill=False, edgecolor='red', linewidth=2)\n",
    "                    axes[z_idx].add_patch(rect)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save figure if requested\n",
    "    if hasattr(plt, 'savefig') and selected_block is not None:\n",
    "        plt.savefig(f'brain_blocks_{nx}x{ny}x{nz}_with_{selected_block}_highlighted.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return blocks\n",
    "\n",
    "\n",
    "def visualize_blocks_2(data_3d, blocks, losses, num_blocks=(3, 3, 3), figsize=None):\n",
    "    \"\"\"\n",
    "    Visualize brain blocks using maximum intensity projection for each z-layer\n",
    "    Shows axial views for each layer along the z-dimension and displays loss values\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_3d : numpy.ndarray\n",
    "        3D brain data\n",
    "    blocks : dict\n",
    "        Dictionary mapping block IDs to block boundaries\n",
    "    losses : array-like\n",
    "        Array of loss values, one per block (index 0 corresponds to block 1)\n",
    "    num_blocks : tuple\n",
    "        Number of blocks along each dimension (x, y, z)\n",
    "    figsize : tuple, optional\n",
    "        Figure size, if None will be calculated based on z-dimension blocks\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as patches\n",
    "    \n",
    "    # Unpack the number of blocks in each dimension\n",
    "    nx, ny, nz = num_blocks\n",
    "    \n",
    "    # Convert losses to numpy array if it isn't already\n",
    "    losses = np.array(losses)\n",
    "    \n",
    "    # Verify number of loss values matches number of blocks\n",
    "    total_blocks = nx * ny * nz\n",
    "    if len(losses) != total_blocks:\n",
    "        raise ValueError(f\"Expected {total_blocks} loss values, but got {len(losses)}\")\n",
    "    \n",
    "    # Find the block with the highest absolute loss\n",
    "    max_abs_loss_idx = np.argmax(np.abs(losses))\n",
    "    # Convert to 1-based indexing for block ID\n",
    "    selected_block = max_abs_loss_idx + 1\n",
    "    max_abs_loss_value = losses[max_abs_loss_idx]\n",
    "    \n",
    "    print(f\"Block {selected_block} has the highest absolute loss: {max_abs_loss_value}\")\n",
    "    \n",
    "    # If figsize is not specified, calculate it based on number of z layers\n",
    "    if figsize is None:\n",
    "        figsize = (6 * nz, 6)\n",
    "    \n",
    "    # Create the figure with the appropriate number of subplots (one per z-layer)\n",
    "    fig, axes = plt.subplots(1, nz, figsize=figsize)\n",
    "    if nz == 1:\n",
    "        axes = [axes]  # Make sure axes is always a list for consistency\n",
    "    \n",
    "    fig.suptitle(f\"Brain Divided into {nx}x{ny}x{nz} Blocks with Loss Values\", fontsize=16)\n",
    "    \n",
    "    # Get block division boundaries\n",
    "    x_divisions = []\n",
    "    y_divisions = []\n",
    "    z_divisions = []\n",
    "    \n",
    "    for block_id, ((x_min, x_max), (y_min, y_max), (z_min, z_max)) in blocks.items():\n",
    "        x_divisions.extend([x_min, x_max])\n",
    "        y_divisions.extend([y_min, y_max])\n",
    "        z_divisions.extend([z_min, z_max])\n",
    "    \n",
    "    # Get unique boundary values\n",
    "    x_divisions = sorted(list(set(x_divisions)))\n",
    "    y_divisions = sorted(list(set(y_divisions)))\n",
    "    z_divisions = sorted(list(set(z_divisions)))\n",
    "    \n",
    "    # Print the division boundaries\n",
    "    print(\"X divisions:\", x_divisions)\n",
    "    print(\"Y divisions:\", y_divisions)\n",
    "    print(\"Z divisions:\", z_divisions)\n",
    "    \n",
    "    # Process each z-layer\n",
    "    for z_idx in range(nz):\n",
    "        # Get z-boundaries for this layer\n",
    "        z_min = z_divisions[z_idx]\n",
    "        z_max = z_divisions[z_idx + 1]\n",
    "        \n",
    "        # Create layer name with actual z-range\n",
    "        layer_name = f\"Layer {z_idx} (z={z_min}-{z_max-1})\"\n",
    "        \n",
    "        # Extract the data for this z-layer\n",
    "        layer_data = data_3d[:, :, z_min:z_max]\n",
    "        \n",
    "        # Create maximum intensity projection along z-axis for just this layer\n",
    "        layer_projection = np.max(layer_data > 0, axis=2).astype(float)\n",
    "        print(f\"Max layer_projection for layer {z_idx}=\", np.max(layer_projection))\n",
    "        \n",
    "        # Plot the projection\n",
    "        im = axes[z_idx].imshow(layer_projection, cmap='gray', origin='lower')\n",
    "        axes[z_idx].set_title(layer_name)\n",
    "        \n",
    "        # Add grid lines using data coordinates instead of pixel coordinates\n",
    "        for x in x_divisions[1:-1]:\n",
    "            axes[z_idx].axhline(x, color='cyan', linestyle='-', alpha=0.7, linewidth=1)\n",
    "        \n",
    "        for y in y_divisions[1:-1]:\n",
    "            axes[z_idx].axvline(y, color='cyan', linestyle='-', alpha=0.7, linewidth=1)\n",
    "        \n",
    "        # Add block numbers and loss values for this layer\n",
    "        for y_idx in range(ny):\n",
    "            for x_idx in range(nx):\n",
    "                # Calculate block ID (1-based index) using the formula:\n",
    "                # block_id = 1 + x_idx + y_idx * nx + z_idx * nx * ny\n",
    "                block_id = 1 + x_idx + y_idx * nx + z_idx * nx * ny\n",
    "                \n",
    "                # Get loss value for this block (subtract 1 for 0-based indexing)\n",
    "                loss_value = losses[block_id - 1]\n",
    "                \n",
    "                # Get x, y boundaries for this block\n",
    "                x_min, x_max = x_divisions[x_idx], x_divisions[x_idx + 1]\n",
    "                y_min, y_max = y_divisions[y_idx], y_divisions[y_idx + 1]\n",
    "                \n",
    "                # Calculate center of block in data coordinates\n",
    "                x_center = (x_min + x_max) / 2\n",
    "                y_center = (y_min + y_max) / 2\n",
    "                \n",
    "                # Add block ID and loss value label with a bounding box\n",
    "                text_box = dict(facecolor='black', alpha=0.5, boxstyle='round')\n",
    "                \n",
    "                # Place the text in the center of the block\n",
    "                axes[z_idx].text(y_center, x_center, f\"{block_id}\\n{loss_value:.3f}\", \n",
    "                               ha='center', va='center', color='yellow', fontweight='bold',\n",
    "                               fontsize=10, bbox=text_box)\n",
    "                \n",
    "                # Highlight the block with the highest absolute loss\n",
    "                if block_id == selected_block:\n",
    "                    rect = patches.Rectangle((y_min, x_min), y_max-y_min, x_max-x_min, \n",
    "                                          fill=False, edgecolor='red', linewidth=2)\n",
    "                    axes[z_idx].add_patch(rect)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save figure if requested\n",
    "    if hasattr(plt, 'savefig'):\n",
    "        plt.savefig(f'brain_blocks_{nx}x{ny}x{nz}_losses.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return blocks\n",
    "\n",
    "\n",
    "def divide_brain_into_blocks(data_3d, num_blocks=(3, 3, 3)):\n",
    "    \"\"\"Divide the 3D brain data into blocks\"\"\"\n",
    "    x_size, y_size, z_size = data_3d.shape\n",
    "    \n",
    "    # Calculate the size of each block\n",
    "    x_block_size = x_size // num_blocks[0]\n",
    "    y_block_size = y_size // num_blocks[1]\n",
    "    z_block_size = z_size // num_blocks[2]\n",
    "    \n",
    "    # Create a dictionary to store block boundaries\n",
    "    blocks = {}\n",
    "    block_id = 1\n",
    "    \n",
    "    for z in range(num_blocks[2]):\n",
    "        z_min = z * z_block_size\n",
    "        z_max = (z + 1) * z_block_size if z < num_blocks[2] - 1 else z_size\n",
    "        \n",
    "        for y in range(num_blocks[1]):\n",
    "            y_min = y * y_block_size\n",
    "            y_max = (y + 1) * y_block_size if y < num_blocks[1] - 1 else y_size\n",
    "            \n",
    "            for x in range(num_blocks[0]):\n",
    "                x_min = x * x_block_size\n",
    "                x_max = (x + 1) * x_block_size if x < num_blocks[0] - 1 else x_size\n",
    "                \n",
    "                blocks[block_id] = ((x_min, x_max), (y_min, y_max), (z_min, z_max))\n",
    "                block_id += 1\n",
    "    \n",
    "    #num_layers = num_blocks[2]\n",
    "\n",
    "    \n",
    "    return blocks\n",
    "\n",
    "\n",
    "def get_regions_in_block(data_3d, block_boundaries):\n",
    "    \"\"\"Get all region IDs contained within a block\"\"\"\n",
    "    (x_min, x_max), (y_min, y_max), (z_min, z_max) = block_boundaries\n",
    "    \n",
    "    # Extract the block\n",
    "    block_data = data_3d[x_min:x_max, y_min:y_max, z_min:z_max]\n",
    "    \n",
    "    # Get unique region IDs (excluding 0/background)\n",
    "    unique_regions = np.unique(block_data)\n",
    "    unique_regions = unique_regions[unique_regions > 0]\n",
    "    \n",
    "    return unique_regions\n",
    "\n",
    "\n",
    "def get_block_indices_1d(regions_3d, block_boundaries):\n",
    "    \"\"\"\n",
    "    Get the 1D indices corresponding to a 3D block\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    regions_3d : numpy.ndarray\n",
    "        3D array of brain regions\n",
    "    block_boundaries : tuple\n",
    "        ((x_min, x_max), (y_min, y_max), (z_min, z_max)) for the block\n",
    "    shape : tuple\n",
    "        Shape of the full 3D array (default: (91, 109, 91))\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        1D indices corresponding to the block\n",
    "    \"\"\"\n",
    "    # Create a copy of the 3D array filled with zeros\n",
    "    block_mask = np.zeros_like(regions_3d)\n",
    "    \n",
    "    # Extract the block boundaries\n",
    "    (x_min, x_max), (y_min, y_max), (z_min, z_max) = block_boundaries\n",
    "    \n",
    "    # Set the block to 1\n",
    "    block_mask[x_min:x_max, y_min:y_max, z_min:z_max] = 1\n",
    "    \n",
    "    # Reshape to 1D\n",
    "    block_mask_1d = block_mask.reshape(-1)\n",
    "    \n",
    "    # Get the indices where the mask is 1\n",
    "    block_indices = np.where(block_mask_1d == 1)[0]\n",
    "    \n",
    "    return block_indices\n",
    "\n",
    "\n",
    "def convert_blocks_to_uncut_space(blocks, x_min, y_min, z_min):\n",
    "    \"\"\"\n",
    "    Convert block coordinates from cut space to uncut space\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    blocks : dict\n",
    "        Dictionary with block IDs as keys and coordinate ranges as values\n",
    "    x_min, y_min, z_min : int\n",
    "        Minimum coordinates of the cut region in the original space\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with block IDs and coordinate ranges in uncut space\n",
    "    \"\"\"\n",
    "    uncut_blocks = {}\n",
    "    \n",
    "    for block_id, ((x_start, x_end), (y_start, y_end), (z_start, z_end)) in blocks.items():\n",
    "        # Adjust coordinates to uncut space\n",
    "        uncut_x = (x_start + x_min, x_end + x_min)\n",
    "        uncut_y = (y_start + y_min, y_end + y_min)\n",
    "        uncut_z = (z_start + z_min, z_end + z_min)\n",
    "        \n",
    "        uncut_blocks[block_id] = (uncut_x, uncut_y, uncut_z)\n",
    "    \n",
    "    return uncut_blocks\n",
    "\n",
    "\n",
    "def turn_off_block_new(fmri_2d, flat_mask, block_id, blocks, x_min, y_min, z_min):\n",
    "    \"\"\"\n",
    "    Turn off a specific block in fMRI data using a mask\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fmri_2d : numpy.ndarray\n",
    "        2D array of fMRI data (samples x voxels)\n",
    "    flat_mask : numpy.ndarray\n",
    "        Flattened mask indicating which voxels in 3D space are used in fMRI data\n",
    "    block_id : int\n",
    "        ID of the block to turn off\n",
    "    blocks : dict\n",
    "        Dictionary with block IDs and coordinates in cut space\n",
    "    x_min, y_min, z_min : int\n",
    "        Minimum coordinates of the cut region in the original space\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Modified fMRI data with the specified block turned off\n",
    "    \"\"\"\n",
    "    # Get the original 3D shape\n",
    "    original_shape = (91, 109, 91)  # Adjust if your shape is different\n",
    "    \n",
    "    # Reshape flat_mask to 3D\n",
    "    mask_3d = flat_mask.reshape(original_shape)\n",
    "    \n",
    "    # Convert block coordinates to uncut space\n",
    "    uncut_blocks = convert_blocks_to_uncut_space(blocks, x_min, y_min, z_min)\n",
    "    \n",
    "    # Get the block boundaries in uncut space\n",
    "    block_boundaries = uncut_blocks[block_id]\n",
    "    (x_min_block, x_max_block), (y_min_block, y_max_block), (z_min_block, z_max_block) = block_boundaries\n",
    "    \n",
    "    # Create a copy of the mask for this block\n",
    "    block_mask_3d = mask_3d.copy()\n",
    "    \n",
    "    # Zero out everything outside the block\n",
    "    block_mask_3d[:x_min_block, :, :] = 0\n",
    "    block_mask_3d[x_max_block:, :, :] = 0\n",
    "    block_mask_3d[:, :y_min_block, :] = 0\n",
    "    block_mask_3d[:, y_max_block:, :] = 0\n",
    "    block_mask_3d[:, :, :z_min_block] = 0\n",
    "    block_mask_3d[:, :, z_max_block:] = 0\n",
    "    \n",
    "    # Now block_mask_3d contains only voxels that are both in the mask and in the block\n",
    "    flat_block_mask = block_mask_3d.flatten()\n",
    "    \n",
    "    # Get non-zero indices in the original mask\n",
    "    original_non_zero = np.nonzero(flat_mask)[0]\n",
    "    \n",
    "    # Get non-zero indices in the block mask\n",
    "    block_non_zero = np.nonzero(flat_block_mask)[0]\n",
    "    \n",
    "    # Find where these block indices appear in the original non-zero indices\n",
    "    indices_to_turn_off = np.where(np.isin(original_non_zero, block_non_zero))[0]\n",
    "    \n",
    "    # Calculate statistics before turning off\n",
    "    zeros_before = (fmri_2d == 0).sum()\n",
    "    total_values = fmri_2d.size\n",
    "    percent_zeros_before = (zeros_before / total_values) * 100\n",
    "    print(f\"Before turning off block {block_id} - Zeros: {zeros_before}/{total_values} ({percent_zeros_before:.2f}%)\")\n",
    "    print(f\"Block {block_id} contains {len(indices_to_turn_off)} voxels out of 4609 total non-zero voxels\")\n",
    "    \n",
    "    # Create a copy of the fMRI data\n",
    "    fmri_modified = fmri_2d.copy()\n",
    "    \n",
    "    # Turn off the block\n",
    "    if len(indices_to_turn_off) > 0:\n",
    "        fmri_modified[:, indices_to_turn_off] = 0\n",
    "    \n",
    "    # Calculate statistics after turning off\n",
    "    zeros_after = (fmri_modified == 0).sum()\n",
    "    percent_zeros_after = (zeros_after / total_values) * 100\n",
    "    new_zeros = zeros_after - zeros_before\n",
    "    percent_increase = (new_zeros / total_values) * 100\n",
    "    \n",
    "    print(f\"After turning off block {block_id} - Zeros: {zeros_after}/{total_values} ({percent_zeros_after:.2f}%)\")\n",
    "    print(f\"Values turned off: {new_zeros}/{total_values} ({percent_increase:.2f}%)\")\n",
    "    \n",
    "    return fmri_modified\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------end of cell 3------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#tag blocks + ou tag blocks 2\n",
    "#  2\n",
    "\n",
    "'''\n",
    "def visualize_blocks_2(data_3d, blocks, losses, num_blocks=(3, 3, 3), figsize=None):\n",
    "    \"\"\"\n",
    "    Visualize brain blocks using maximum intensity projection for each z-layer\n",
    "    Shows axial views for each layer along the z-dimension and displays loss values\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_3d : numpy.ndarray\n",
    "        3D brain data\n",
    "    blocks : dict\n",
    "        Dictionary mapping block IDs to block boundaries\n",
    "    losses : array-like\n",
    "        Array of loss values, one per block (index 0 corresponds to block 1)\n",
    "    num_blocks : tuple\n",
    "        Number of blocks along each dimension (x, y, z)\n",
    "    figsize : tuple, optional\n",
    "        Figure size, if None will be calculated based on z-dimension blocks\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as patches\n",
    "    \n",
    "    # Unpack the number of blocks in each dimension\n",
    "    nx, ny, nz = num_blocks\n",
    "    \n",
    "    # Convert losses to numpy array if it isn't already\n",
    "    losses = np.array(losses)\n",
    "    \n",
    "    # Verify number of loss values matches number of blocks\n",
    "    total_blocks = nx * ny * nz\n",
    "    if len(losses) != total_blocks:\n",
    "        raise ValueError(f\"Expected {total_blocks} loss values, but got {len(losses)}\")\n",
    "    \n",
    "    # Find the block with the highest absolute loss\n",
    "    max_abs_loss_idx = np.argmax(np.abs(losses))\n",
    "    # Convert to 1-based indexing for block ID\n",
    "    selected_block = max_abs_loss_idx + 1\n",
    "    max_abs_loss_value = losses[max_abs_loss_idx]\n",
    "    \n",
    "    print(f\"Block {selected_block} has the highest absolute loss: {max_abs_loss_value}\")\n",
    "    \n",
    "    # If figsize is not specified, calculate it based on number of z layers\n",
    "    if figsize is None:\n",
    "        figsize = (6 * nz, 6)\n",
    "    \n",
    "    # Create the figure with the appropriate number of subplots (one per z-layer)\n",
    "    fig, axes = plt.subplots(1, nz, figsize=figsize)\n",
    "    if nz == 1:\n",
    "        axes = [axes]  # Make sure axes is always a list for consistency\n",
    "    \n",
    "    fig.suptitle(f\"Brain Divided into {nx}x{ny}x{nz} Blocks with Loss Values\", fontsize=16)\n",
    "    \n",
    "    # Get block division boundaries\n",
    "    x_divisions = []\n",
    "    y_divisions = []\n",
    "    z_divisions = []\n",
    "    \n",
    "    for block_id, ((x_min, x_max), (y_min, y_max), (z_min, z_max)) in blocks.items():\n",
    "        x_divisions.extend([x_min, x_max])\n",
    "        y_divisions.extend([y_min, y_max])\n",
    "        z_divisions.extend([z_min, z_max])\n",
    "    \n",
    "    # Get unique boundary values\n",
    "    x_divisions = sorted(list(set(x_divisions)))\n",
    "    y_divisions = sorted(list(set(y_divisions)))\n",
    "    z_divisions = sorted(list(set(z_divisions)))\n",
    "    \n",
    "    # Print the division boundaries\n",
    "    print(\"X divisions:\", x_divisions)\n",
    "    print(\"Y divisions:\", y_divisions)\n",
    "    print(\"Z divisions:\", z_divisions)\n",
    "    \n",
    "    # Process each z-layer\n",
    "    for z_idx in range(nz):\n",
    "        # Get z-boundaries for this layer\n",
    "        z_min = z_divisions[z_idx]\n",
    "        z_max = z_divisions[z_idx + 1]\n",
    "        \n",
    "        # Create layer name with actual z-range\n",
    "        layer_name = f\"Layer {z_idx} (z={z_min}-{z_max-1})\"\n",
    "        \n",
    "        # Extract the data for this z-layer\n",
    "        layer_data = data_3d[:, :, z_min:z_max]\n",
    "        \n",
    "        # Create maximum intensity projection along z-axis for just this layer\n",
    "        layer_projection = np.max(layer_data > 0, axis=2).astype(float)\n",
    "        print(f\"Max layer_projection for layer {z_idx}=\", np.max(layer_projection))\n",
    "        \n",
    "        # Plot the projection\n",
    "        im = axes[z_idx].imshow(layer_projection, cmap='gray', origin='lower')\n",
    "        axes[z_idx].set_title(layer_name)\n",
    "        \n",
    "        # Add grid lines using data coordinates instead of pixel coordinates\n",
    "        for x in x_divisions[1:-1]:\n",
    "            axes[z_idx].axhline(x, color='cyan', linestyle='-', alpha=0.7, linewidth=1)\n",
    "        \n",
    "        for y in y_divisions[1:-1]:\n",
    "            axes[z_idx].axvline(y, color='cyan', linestyle='-', alpha=0.7, linewidth=1)\n",
    "        \n",
    "        # Add block numbers and loss values for this layer\n",
    "        for y_idx in range(ny):\n",
    "            for x_idx in range(nx):\n",
    "                # Calculate block ID (1-based index) using the formula:\n",
    "                # block_id = 1 + x_idx + y_idx * nx + z_idx * nx * ny\n",
    "                block_id = 1 + x_idx + y_idx * nx + z_idx * nx * ny\n",
    "                \n",
    "                # Get loss value for this block (subtract 1 for 0-based indexing)\n",
    "                loss_value = losses[block_id - 1]\n",
    "                \n",
    "                # Get x, y boundaries for this block\n",
    "                x_min, x_max = x_divisions[x_idx], x_divisions[x_idx + 1]\n",
    "                y_min, y_max = y_divisions[y_idx], y_divisions[y_idx + 1]\n",
    "                \n",
    "                # Calculate center of block in data coordinates\n",
    "                x_center = (x_min + x_max) / 2\n",
    "                y_center = (y_min + y_max) / 2\n",
    "                \n",
    "                # Add block ID and loss value label with a bounding box\n",
    "                text_box = dict(facecolor='black', alpha=0.5, boxstyle='round')\n",
    "                \n",
    "                # Place the text in the center of the block\n",
    "                axes[z_idx].text(y_center, x_center, f\"{block_id}\\n{loss_value:.3f}\", \n",
    "                               ha='center', va='center', color='yellow', fontweight='bold',\n",
    "                               fontsize=10, bbox=text_box)\n",
    "                \n",
    "                # Highlight the block with the highest absolute loss\n",
    "                if block_id == selected_block:\n",
    "                    rect = patches.Rectangle((y_min, x_min), y_max-y_min, x_max-x_min, \n",
    "                                          fill=False, edgecolor='red', linewidth=2)\n",
    "                    axes[z_idx].add_patch(rect)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save figure if requested\n",
    "    if hasattr(plt, 'savefig'):\n",
    "        plt.savefig(f'brain_blocks_{nx}x{ny}x{nz}_losses.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return blocks\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def visualize_blocks_3(data_3d, blocks, losses, num_blocks=(3, 3, 3), figsize=None, colormap='viridis'):\n",
    "    \"\"\"\n",
    "    Visualize brain blocks using maximum intensity projection for each z-layer\n",
    "    Shows axial views for each layer along the z-dimension and displays loss values with color-coded blocks\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_3d : numpy.ndarray\n",
    "        3D brain data\n",
    "    blocks : dict\n",
    "        Dictionary mapping block IDs to block boundaries\n",
    "    losses : array-like\n",
    "        Array of loss values, one per block (index 0 corresponds to block 1)\n",
    "    num_blocks : tuple\n",
    "        Number of blocks along each dimension (x, y, z)\n",
    "    figsize : tuple, optional\n",
    "        Figure size, if None will be calculated based on z-dimension blocks\n",
    "    colormap : str\n",
    "        Matplotlib colormap name to use for loss values\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as patches\n",
    "    import matplotlib.colors as colors\n",
    "    \n",
    "    # Unpack the number of blocks in each dimension\n",
    "    nx, ny, nz = num_blocks\n",
    "    \n",
    "    # Convert losses to numpy array if it isn't already\n",
    "    losses = np.array(losses)\n",
    "    \n",
    "    # Verify number of loss values matches number of blocks\n",
    "    total_blocks = nx * ny * nz\n",
    "    if len(losses) != total_blocks:\n",
    "        raise ValueError(f\"Expected {total_blocks} loss values, but got {len(losses)}\")\n",
    "    \n",
    "    # Find the block with the highest absolute loss\n",
    "    max_abs_loss_idx = np.argmax(np.abs(losses))\n",
    "    # Convert to 1-based indexing for block ID\n",
    "    selected_block = max_abs_loss_idx + 1\n",
    "    max_abs_loss_value = losses[max_abs_loss_idx]\n",
    "    \n",
    "    print(f\"Block {selected_block} has the highest absolute loss: {max_abs_loss_value}\")\n",
    "    \n",
    "    # Create a colormap normalization based on min/max loss values\n",
    "    norm = colors.Normalize(vmin=np.min(losses), vmax=np.max(losses))\n",
    "    cmap = plt.cm.get_cmap(colormap)\n",
    "    \n",
    "    # If figsize is not specified, calculate it based on number of z layers\n",
    "    if figsize is None:\n",
    "        figsize = (6 * nz, 6)\n",
    "    \n",
    "    # Create the figure with the appropriate number of subplots (one per z-layer)\n",
    "    fig, axes = plt.subplots(1, nz, figsize=figsize)\n",
    "    if nz == 1:\n",
    "        axes = [axes]  # Make sure axes is always a list for consistency\n",
    "    \n",
    "    fig.suptitle(f\"Brain Divided into {nx}x{ny}x{nz} Blocks with Loss Values\", fontsize=16)\n",
    "    \n",
    "    # Get block division boundaries\n",
    "    x_divisions = []\n",
    "    y_divisions = []\n",
    "    z_divisions = []\n",
    "    \n",
    "    for block_id, ((x_min, x_max), (y_min, y_max), (z_min, z_max)) in blocks.items():\n",
    "        x_divisions.extend([x_min, x_max])\n",
    "        y_divisions.extend([y_min, y_max])\n",
    "        z_divisions.extend([z_min, z_max])\n",
    "    \n",
    "    # Get unique boundary values\n",
    "    x_divisions = sorted(list(set(x_divisions)))\n",
    "    y_divisions = sorted(list(set(y_divisions)))\n",
    "    z_divisions = sorted(list(set(z_divisions)))\n",
    "    \n",
    "    # Print the division boundaries\n",
    "    print(\"X divisions:\", x_divisions)\n",
    "    print(\"Y divisions:\", y_divisions)\n",
    "    print(\"Z divisions:\", z_divisions)\n",
    "    \n",
    "    # Process each z-layer\n",
    "    for z_idx in range(nz):\n",
    "        # Get z-boundaries for this layer\n",
    "        z_min = z_divisions[z_idx]\n",
    "        z_max = z_divisions[z_idx + 1]\n",
    "        \n",
    "        # Create layer name with actual z-range\n",
    "        layer_name = f\"Layer {z_idx} (z={z_min}-{z_max-1})\"\n",
    "        \n",
    "        # Extract the data for this z-layer\n",
    "        layer_data = data_3d[:, :, z_min:z_max]\n",
    "        \n",
    "        # Create maximum intensity projection along z-axis for just this layer\n",
    "        layer_projection = np.max(layer_data > 0, axis=2).astype(float)\n",
    "        print(f\"Max layer_projection for layer {z_idx}=\", np.max(layer_projection))\n",
    "        \n",
    "        # Create a brain mask - identifies where brain tissue exists\n",
    "        brain_mask = layer_projection > 0\n",
    "        \n",
    "        # Plot black background\n",
    "        axes[z_idx].imshow(np.zeros_like(layer_projection), cmap='gray', origin='lower')\n",
    "        axes[z_idx].set_title(layer_name)\n",
    "        \n",
    "        # We're removing the grid lines as requested\n",
    "        # No more axhline or axvline calls here\n",
    "        \n",
    "        # Add colored blocks and loss values for this layer\n",
    "        for y_idx in range(ny):\n",
    "            for x_idx in range(nx):\n",
    "                # Calculate block ID (1-based index) using the formula:\n",
    "                # block_id = 1 + x_idx + y_idx * nx + z_idx * nx * ny\n",
    "                block_id = 1 + x_idx + y_idx * nx + z_idx * nx * ny\n",
    "                \n",
    "                # Get loss value for this block (subtract 1 for 0-based indexing)\n",
    "                loss_value = losses[block_id - 1]\n",
    "                \n",
    "                # Get x, y boundaries for this block\n",
    "                x_min, x_max = x_divisions[x_idx], x_divisions[x_idx + 1]\n",
    "                y_min, y_max = y_divisions[y_idx], y_divisions[y_idx + 1]\n",
    "                \n",
    "                # Calculate center of block in data coordinates\n",
    "                x_center = (x_min + x_max) / 2\n",
    "                y_center = (y_min + y_max) / 2\n",
    "                \n",
    "                # Get color from colormap based on loss value\n",
    "                block_color = cmap(norm(loss_value))\n",
    "                \n",
    "                # Create a mask for this block\n",
    "                block_mask = np.zeros_like(layer_projection, dtype=bool)\n",
    "                block_mask[x_min:x_max, y_min:y_max] = True\n",
    "                \n",
    "                # Combine with brain mask to only color brain regions\n",
    "                block_brain_mask = block_mask & brain_mask\n",
    "                \n",
    "                # If there are brain voxels in this block, add the colored overlay\n",
    "                if np.any(block_brain_mask):\n",
    "                    # Create a colored overlay image for this block\n",
    "                    colored_overlay = np.zeros((*layer_projection.shape, 4))  # RGBA\n",
    "                    colored_overlay[block_brain_mask, :] = block_color\n",
    "                    \n",
    "                    # Add the colored overlay to the plot\n",
    "                    axes[z_idx].imshow(colored_overlay, origin='lower', interpolation='nearest')\n",
    "                    \n",
    "                    # We're removing the white outlines around each block\n",
    "                    # No more Rectangle patch with fill=False\n",
    "                \n",
    "                # Add block ID and loss value label with a bounding box\n",
    "                text_box = dict(facecolor='black', alpha=0.7, boxstyle='round')\n",
    "                \n",
    "                # Place the text in the center of the block\n",
    "                axes[z_idx].text(y_center, x_center, f\"{block_id}\\n{loss_value:.3f}\", \n",
    "                               ha='center', va='center', color='white', fontweight='bold',\n",
    "                               fontsize=10, bbox=text_box)\n",
    "                \n",
    "                # Highlight the block with the highest absolute loss\n",
    "                if block_id == selected_block:\n",
    "                    highlight_rect = patches.Rectangle(\n",
    "                        (y_min, x_min), y_max-y_min, x_max-x_min,\n",
    "                        fill=False, edgecolor='red', linewidth=2\n",
    "                    )\n",
    "                    axes[z_idx].add_patch(highlight_rect)\n",
    "    \n",
    "    # Add a colorbar to show the mapping between loss values and colors\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    \n",
    "    # Create a separate axis for the colorbar below the brain images\n",
    "    cax = fig.add_axes([0.15, 0.05, 0.7, 0.02])  # [left, bottom, width, height]\n",
    "    cbar = fig.colorbar(sm, cax=cax, orientation='horizontal')\n",
    "    cbar.set_label('Loss Value')\n",
    "    \n",
    "    # Adjust layout to make room for colorbar\n",
    "    plt.tight_layout(rect=[0, 0.1, 1, 0.95])\n",
    "    plt.show()\n",
    "    \n",
    "    # Save figure if requested\n",
    "    if hasattr(plt, 'savefig'):\n",
    "        plt.savefig(f'brain_blocks_{nx}x{ny}x{nz}_losses_colormap.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return blocks\n",
    "\n",
    "def test_new_decoder(real=True, model_name='decoder_4609_1650', test_on_train=False, test_input=testset['fMRIs'], \n",
    "                     test_label=testset['videos'], add_name='', regions=[], block_id=None, save_plots=False, all_frames=False,\n",
    "                     change_mode='off', num_blocks=None, metric=\"ssim\", zones=None):\n",
    "    '''\n",
    "    Tests the decoder with brain block analysis\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    real : bool\n",
    "        If True, tests on real brain activity; if False, tests on brain activity from encoder\n",
    "    model_name : str\n",
    "        Name of the model file to be used\n",
    "    test_on_train : bool\n",
    "        If True, tests on the training set\n",
    "    test_input : dict\n",
    "        Dictionary with fMRIs for testing (one subdictionary for each film)\n",
    "    test_label : dict\n",
    "        Dictionary with films (one subdictionary for each film)\n",
    "    add_name : str\n",
    "        String to add to the end of output name to avoid overwriting\n",
    "    regions : list\n",
    "        List of region IDs to turn off (legacy parameter, use block_id instead)\n",
    "    block_id : int\n",
    "        ID of the 3D block to turn off (1-27)\n",
    "    save_plots : bool\n",
    "        If True, saves plots\n",
    "    all_frames : bool\n",
    "        If True, runs test_model_all, otherwise runs test_model\n",
    "    change_mode : str\n",
    "        'off' or 'amplify'\n",
    "    zones (str or int, optional): Zones to consider for testing. Default is \"quadrants\", can also be \"center_bg\".\n",
    "                                  If it is an integer, the function will analyze a number of zones = that integer squared.\n",
    "                                  For example, if zones = 4, the function will analyze 16 zones (4x4).\n",
    "\n",
    "    '''\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as patches\n",
    "\n",
    "    print(\"zones = \", zones, \"\\n\")\n",
    "    \n",
    "    # Helper functions for brain blocks (included directly to avoid import issues)\n",
    "    \n",
    "    print(\"Testing decoder\", model_name)\n",
    "    \n",
    "    # Load the model\n",
    "    model = Decoder(mask_size)\n",
    "    state_dict = torch.load(model_name)\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    # Testing parameters\n",
    "    criterion = D_Loss()\n",
    "    device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "    pretrained_decoder = None\n",
    "    model_to_test = 'decoder'\n",
    "    statistical_testing = False\n",
    "    display_plots = True\n",
    "    \n",
    "    # Handle special case for training data\n",
    "    if test_on_train:\n",
    "        num_samples = trainset[\"fMRIs\"].shape[0]\n",
    "        random_indices = np.random.choice(num_samples, size=30, replace=False)\n",
    "        testset2 = {\n",
    "            \"fMRIs\": {\n",
    "                \"test\": trainset[\"fMRIs\"][random_indices]\n",
    "            },\n",
    "            \"videos\": {\n",
    "                \"test\": trainset[\"videos\"][random_indices]\n",
    "            }\n",
    "        }\n",
    "        test_input = testset2['fMRIs']\n",
    "        test_label = testset2['videos']\n",
    "    \n",
    "    # Check if we're using a brain block\n",
    "    if num_blocks is not None:\n",
    "#        print(f\"Testing with brain block {block_id}\")\n",
    "        \n",
    "        # Load the 3D brain data\n",
    "        regions_3d = load_and_reshape_data('region_ids_4609+.npy')\n",
    "\n",
    "\n",
    "        # Cut to the tightest rectangular prism around the brain\n",
    "        (x_min, x_max), (y_min, y_max), (z_min, z_max) = find_bounds(regions_3d)\n",
    "        brain_data = regions_3d[x_min:x_max+1, y_min:y_max+1, z_min:z_max+1]\n",
    "#        brain_data = regions_3d\n",
    "        print(f\"Original shape: {regions_3d.shape}, Brain shape: {brain_data.shape}\")\n",
    "\n",
    "        # Divide into blocks\n",
    "        blocks = divide_brain_into_blocks(brain_data, num_blocks)\n",
    "        \n",
    "        # Visualize the blocks with the specified block highlighted (using the layer-wise visualization)\n",
    "#   ->     visualize_blocks(brain_data, blocks, num_blocks=num_blocks, selected_block=block_id)\n",
    "\n",
    "        #brain_data is just for getting coordinates for the blocks, then we turn them off in the fmri original data\n",
    "\n",
    "        \n",
    "#        # Check if the block ID is valid\n",
    "#        if block_id not in blocks:\n",
    "#            print(f\"Error: Block ID {block_id} not found in blocks dictionary\")\n",
    "#            return None\n",
    "        \n",
    "        # Turn off the specified block in all input videos\n",
    "        \n",
    "\n",
    "        mask4609 = np.load('mask_schaefer1000_4609.npy')\n",
    "\n",
    "        # Flatten the mask\n",
    "        flat_mask = mask4609.flatten()\n",
    "\n",
    "        print(\"brain_data.shape =\", brain_data.shape)\n",
    "\n",
    "        modified_input = {}\n",
    "\n",
    "        if block_id is not None:                    #if some block is specified\n",
    "            for video_name in test_input.keys():\n",
    "                print(f\"Turning off block {block_id} for video {video_name}\")\n",
    "\n",
    "                visualize_blocks(brain_data, blocks, num_blocks=num_blocks, selected_block=block_id)\n",
    "                \n",
    "                # Use the existing turn_off_regions function for the regions in this block\n",
    "                if change_mode == 'off':\n",
    "    #                modified_data = turn_off_regions(test_input[video_name], regions_in_block)\n",
    "    #                modified_data = turn_off_block(brain_data, blocks, block_id, test_input[video_name])\n",
    "                    modified_data = turn_off_block_new(test_input[video_name], flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "    #                                turn_off_block_new(fmri_2d, flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "                else:\n",
    "                    modified_data = turn_off_block_new(test_input[video_name], flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "    #                modified_data = turn_off_block(brain_data, blocks, block_id, test_input[video_name])\n",
    "    #                modified_data = turn_off_regions(test_input[video_name], regions_in_block, \n",
    "    #                                               mode='amplify', amplify_factor=4)\n",
    "                \n",
    "                modified_input[video_name] = modified_data\n",
    "                \n",
    "            # Use the modified input for testing\n",
    "            test_input = modified_input\n",
    "\n",
    "            if all_frames:\n",
    "                test_model_all(test_input, test_label, model, criterion, device, \n",
    "                            pretrained_decoder, model_to_test, statistical_testing, \n",
    "                            display_plots, save_plots, model_name=model_name + add_name, metric=metric)\n",
    "                return None\n",
    "            else:\n",
    "                test_model(test_input, test_label, model, criterion, device, \n",
    "                        pretrained_decoder, model_to_test, statistical_testing, \n",
    "                        display_plots, save_plots, model_name=model_name + add_name)\n",
    "                #           metric=metric)\n",
    "                return None\n",
    "            \n",
    "\n",
    "\n",
    "        elif block_id is None:\n",
    "            losses = []\n",
    "            #loop through all blocks\n",
    "            for block_id in range(1, num_blocks[0] * num_blocks[1] * num_blocks[2] + 1):\n",
    "                for video_name in test_input.keys():\n",
    "                    \n",
    "                    # Use the existing turn_off_regions function for the regions in this block\n",
    "                    if change_mode == 'off':\n",
    "                        modified_data = turn_off_block_new(test_input[video_name], flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "                    else:\n",
    "                        modified_data = turn_off_block_new(test_input[video_name], flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "                    \n",
    "                    modified_input[video_name] = modified_data\n",
    "                    \n",
    "                # Use the modified input for testing\n",
    "                test_input2 = modified_input\n",
    "\n",
    "                if all_frames:\n",
    "                    results = test_model_all(test_input2, test_label, model, criterion, device, \n",
    "                                pretrained_decoder, model_to_test, statistical_testing, \n",
    "                                display_plots, save_plots, model_name=model_name + add_name, metric=metric, mean_flag=True, \n",
    "                                zones=zones)\n",
    "                    \n",
    "                    if metric == \"tv\":\n",
    "#                        print(\"keys do test performance =\", results['test_performance'].keys())\n",
    "                        mean_loss = results['test_performance']\n",
    "\n",
    "                    elif metric == \"ssim\":\n",
    "                        mean_loss = results['test_performance']\n",
    "                    \n",
    "                else:\n",
    "                    test_model(test_input2, test_label, model, criterion, device, \n",
    "                            pretrained_decoder, model_to_test, statistical_testing, \n",
    "                            display_plots, save_plots, model_name=model_name + add_name)\n",
    "                    #           metric=metric)\n",
    "                print(\"Turned off block\", block_id, \", mean loss =\", mean_loss)\n",
    "                losses.append(mean_loss)\n",
    "\n",
    "            lossiest = np.argmax(losses)\n",
    "            print(\"Block with the biggest change =\", lossiest)\n",
    "                \n",
    "            #visualize_blocks_2(brain_data, blocks, num_blocks=num_blocks, losses=losses)\n",
    "            # Example usage:\n",
    "            visualize_blocks_3(\n",
    "                brain_data,\n",
    "                blocks,\n",
    "                losses,\n",
    "                num_blocks=(2, 2, 2),\n",
    "                colormap='viridis'  # Other colormaps: 'hot', 'coolwarm', 'RdBu_r', etc.\n",
    "            )\n",
    "            \n",
    "                #gonna have to make this function which plots with the loss for each zone\n",
    "                #and shows in red the block with the biggest change\n",
    "\n",
    "            return None\n",
    "                \n",
    "                # Use the existing turn_off_regions function for the regions in this block\n",
    "#                if change_mode == 'off':\n",
    "\n",
    "#                if all_frames:\n",
    "#                    results = test_model_all(test_input, test_label, model, criterion, device, \n",
    "#                                pretrained_decoder, model_to_test, statistical_testing, \n",
    "#                                display_plots, save_plots, model_name=model_name + add_name, metric=metric)\n",
    "#                    if metric == \"tv\":\n",
    "#                        mean_loss = results['test_performance']['mean_tv_D']\n",
    "#                    elif metric == \"ssim\":\n",
    "#                        mean_loss = results['test_performance']['mean_ssim_D']\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#    elif block_id is None and num_blocks is not None:       #loop through all blocks\n",
    "#        for block_id in range(1, num_blocks[0] * num_blocks[1] * num_blocks[2]):\n",
    "        \n",
    "#        losses = []\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    # Original code for regions list\n",
    "    elif regions:\n",
    "        # Specific regions case\n",
    "        fmri_regions_off = test_input.copy()\n",
    "        \n",
    "        for video_name in test_input.keys():\n",
    "            fmri_regions_off[video_name] = turn_off_regions(test_input[video_name], regions)\n",
    "            \n",
    "        test_input = fmri_regions_off\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"test input shape =\", print_dict_tree(test_input))\n",
    "    print(\"test label shape =\", print_dict_tree(test_label))\n",
    "\n",
    "    # Run the appropriate test model function\n",
    "    # Do recall this code is just being used for the case we want regions, not blocks\n",
    "    if all_frames:\n",
    "        results = test_model_all(test_input, test_label, model, criterion, device, \n",
    "                       pretrained_decoder, model_to_test, statistical_testing, \n",
    "                       display_plots, save_plots, model_name=model_name + add_name, metric=metric, mean_flag=True,\n",
    "#                       zones=\"quadrants\",\n",
    "                       zones=zones\n",
    "#                       zones = \"center_bg\"\n",
    "                       )\n",
    "        if metric == \"tv\":\n",
    "            mean_loss = results['test_performance']['mean_tv_D']\n",
    "        elif metric == \"ssim\":\n",
    "            mean_loss = results['test_performance']['mean_ssim_D']\n",
    "\n",
    "        return None\n",
    "    else:\n",
    "        test_model(test_input, test_label, model, criterion, device, \n",
    "                   pretrained_decoder, model_to_test, statistical_testing, \n",
    "                   display_plots, save_plots, model_name=model_name + add_name)\n",
    "        #           metric=metric)\n",
    "        return None\n",
    "    \n",
    "\n",
    "def run_all_blocks_test():\n",
    "    # Run test with a specific block (e.g., block 14 - middle block)\n",
    "    test_new_decoder(\n",
    "        real=True,\n",
    "        model_name='decoder_4609_350',\n",
    "#        test_input=filtered_testset['fMRIs'],\n",
    "#        test_label=filtered_testset['videos'],\n",
    "        test_input=filtered_trainset['fMRIs'],\n",
    "        test_label=filtered_trainset['videos'],\n",
    "    #    model_name='decoder_all_4609_325',\n",
    "    #    test_input=filtered_trainset_new['fMRIs'],\n",
    "    #    test_label=filtered_trainset_new['videos'],\n",
    "#        block_id=14,  # Choose a block number between 1 and 27\n",
    "        all_frames=True,\n",
    "        save_plots=False,\n",
    "        add_name='_block_14',\n",
    "        change_mode='off',\n",
    "        #num_blocks=(3,3,3),\n",
    "        num_blocks=(2,2,2),\n",
    "        metric=\"tv\",\n",
    "        zones=4\n",
    "    )\n",
    "    \n",
    "# Call the function\n",
    "run_all_blocks_test()\n",
    "\n",
    "#tag blocks end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------------end of cell 4 (code above gives output with good brain bad reconstructions, code below gives bad brain good reconstructions)----------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_new_decoder(real=True, model_name='decoder_4609_1650', test_on_train=False, test_input=testset['fMRIs'], \n",
    "                     test_label=testset['videos'], add_name='', regions=[], block_id=None, save_plots=False, all_frames=False,\n",
    "                     change_mode='off', num_blocks=(3,3,3), metric=\"ssim\"):\n",
    "    '''\n",
    "    Tests the decoder with brain block analysis\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    real : bool\n",
    "        If True, tests on real brain activity; if False, tests on brain activity from encoder\n",
    "    model_name : str\n",
    "        Name of the model file to be used\n",
    "    test_on_train : bool\n",
    "        If True, tests on the training set\n",
    "    test_input : dict\n",
    "        Dictionary with fMRIs for testing (one subdictionary for each film)\n",
    "    test_label : dict\n",
    "        Dictionary with films (one subdictionary for each film)\n",
    "    add_name : str\n",
    "        String to add to the end of output name to avoid overwriting\n",
    "    regions : list\n",
    "        List of region IDs to turn off (legacy parameter, use block_id instead)\n",
    "    block_id : int\n",
    "        ID of the 3D block to turn off (1-27)\n",
    "    save_plots : bool\n",
    "        If True, saves plots\n",
    "    all_frames : bool\n",
    "        If True, runs test_model_all, otherwise runs test_model\n",
    "    change_mode : str\n",
    "        'off' or 'amplify'\n",
    "    '''\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as patches\n",
    "    \n",
    "    # Helper functions for brain blocks (included directly to avoid import issues)\n",
    "\n",
    "    \n",
    "    \n",
    "    print(\"Testing decoder\", model_name)\n",
    "    \n",
    "    # Load the model\n",
    "    model = Decoder(mask_size)\n",
    "    state_dict = torch.load(model_name)\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    # Testing parameters\n",
    "    criterion = D_Loss()\n",
    "    device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "    pretrained_decoder = None\n",
    "    model_to_test = 'decoder'\n",
    "    statistical_testing = False\n",
    "    display_plots = True\n",
    "    \n",
    "    # Handle special case for training data\n",
    "    if test_on_train:\n",
    "        num_samples = trainset[\"fMRIs\"].shape[0]\n",
    "        random_indices = np.random.choice(num_samples, size=30, replace=False)\n",
    "        testset2 = {\n",
    "            \"fMRIs\": {\n",
    "                \"test\": trainset[\"fMRIs\"][random_indices]\n",
    "            },\n",
    "            \"videos\": {\n",
    "                \"test\": trainset[\"videos\"][random_indices]\n",
    "            }\n",
    "        }\n",
    "        test_input = testset2['fMRIs']\n",
    "        test_label = testset2['videos']\n",
    "    \n",
    "    # Check if we're using a brain block\n",
    "    if block_id is not None:\n",
    "        print(f\"Testing with brain block {block_id}\")\n",
    "        \n",
    "        # Load the 3D brain data\n",
    "        regions_3d = load_and_reshape_data('region_ids_4609+.npy')\n",
    "\n",
    "\n",
    "\n",
    "        # Find the highest z-coordinate with non-zero values\n",
    "#        z_non_zero = []\n",
    "#        for z in range(regions_3d.shape[2]):\n",
    "#            if np.any(regions_3d[:, :, z] > 0):\n",
    "#                z_non_zero.append(z)\n",
    "\n",
    "#        if z_non_zero:\n",
    "#            print(f\"Z-coordinates with non-zero values: min={min(z_non_zero)}, max={max(z_non_zero)}\")\n",
    "#        else:\n",
    "#            print(\"No non-zero values found in any z-slice\")\n",
    "        # result was that min=26, max=58\n",
    "            \n",
    "        # Cut to the tightest rectangular prism around the brain\n",
    "        (x_min, x_max), (y_min, y_max), (z_min, z_max) = find_bounds(regions_3d)\n",
    "        brain_data = regions_3d[x_min:x_max+1, y_min:y_max+1, z_min:z_max+1]\n",
    "#        brain_data = regions_3d\n",
    "        print(f\"Original shape: {regions_3d.shape}, Brain shape: {brain_data.shape}\")\n",
    "\n",
    "        # Divide into blocks\n",
    "        blocks = divide_brain_into_blocks(brain_data, num_blocks)\n",
    "\n",
    "#        uncut_blocks=convert_blocks_to_uncut_space(blocks, x_min, y_min, z_min)\n",
    "\n",
    "#        block_indices = get_block_indices_1d(regions_3d, uncut_blocks[block_id])\n",
    "\n",
    "        print(\"blocks =\", blocks)\n",
    "\n",
    "        print()\n",
    "        \n",
    "        # Visualize the blocks with the specified block highlighted (using the layer-wise visualization)\n",
    "        #visualize_brain_blocks_layer_wise(regions_3d, blocks, selected_block=block_id)\n",
    "\n",
    "        #visualize_brain_blocks_layer_wise(brain_data, blocks, num_blocks=num_blocks, selected_block=block_id)\n",
    "        visualize_blocks(brain_data, blocks, num_blocks=num_blocks, selected_block=block_id)\n",
    "\n",
    "        #brain_data is just for getting coordinates for the blocks, then we turn them off in the fmri original data\n",
    "\n",
    "        \n",
    "        # Check if the block ID is valid\n",
    "        if block_id not in blocks:\n",
    "            print(f\"Error: Block ID {block_id} not found in blocks dictionary\")\n",
    "            return None\n",
    "        \n",
    "        # Get the regions in the specified block\n",
    "#        boundaries = blocks[block_id]\n",
    "#        regions_in_block = get_regions_in_block(regions_3d, boundaries)\n",
    "        \n",
    "#        print(f\"Block {block_id} contains {len(regions_in_block)} unique regions\")\n",
    "        \n",
    "        # Turn off the specified block in all input videos\n",
    "        modified_input = {}\n",
    "\n",
    "        mask4609 = np.load('mask_schaefer1000_4609.npy')\n",
    "\n",
    "        # Flatten the mask\n",
    "        flat_mask = mask4609.flatten()\n",
    "\n",
    "        print(\"brain_data.shape =\", brain_data.shape)\n",
    "        for video_name in test_input.keys():\n",
    "            print(f\"Turning off block {block_id} for video {video_name}\")\n",
    "            \n",
    "            # Use the existing turn_off_regions function for the regions in this block\n",
    "            if change_mode == 'off':\n",
    "#                modified_data = turn_off_regions(test_input[video_name], regions_in_block)\n",
    "#                modified_data = turn_off_block(brain_data, blocks, block_id, test_input[video_name])\n",
    "                modified_data = turn_off_block_new(test_input[video_name], flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "#                                turn_off_block_new(fmri_2d, flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "            else:\n",
    "                modified_data = turn_off_block_new(test_input[video_name], flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "#                modified_data = turn_off_block(brain_data, blocks, block_id, test_input[video_name])\n",
    "#                modified_data = turn_off_regions(test_input[video_name], regions_in_block, \n",
    "#                                               mode='amplify', amplify_factor=4)\n",
    "            \n",
    "            modified_input[video_name] = modified_data\n",
    "            \n",
    "        # Use the modified input for testing\n",
    "        test_input = modified_input\n",
    "\n",
    "        \n",
    "    # Original code for regions list\n",
    "    elif regions:\n",
    "        # Specific regions case\n",
    "        fmri_regions_off = test_input.copy()\n",
    "        \n",
    "        for video_name in test_input.keys():\n",
    "            fmri_regions_off[video_name] = turn_off_regions(test_input[video_name], regions)\n",
    "            \n",
    "        test_input = fmri_regions_off\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"test input shape =\", print_dict_tree(test_input))\n",
    "    print(\"test label shape =\", print_dict_tree(test_label))\n",
    "\n",
    "    # Run the appropriate test model function\n",
    "    if all_frames:\n",
    "        results = test_model_all(test_input, test_label, model, criterion, device, \n",
    "                       pretrained_decoder, model_to_test, statistical_testing, \n",
    "                       display_plots, save_plots, model_name=model_name + add_name, metric=metric)\n",
    "        if metric == \"tv\":\n",
    "            mean_loss = results['test_performance']['mean_tv_D']\n",
    "        elif metric == \"ssim\":\n",
    "            mean_loss = results['test_performance']['mean_ssim_D']\n",
    "\n",
    "        return None\n",
    "    else:\n",
    "        test_model(test_input, test_label, model, criterion, device, \n",
    "                   pretrained_decoder, model_to_test, statistical_testing, \n",
    "                   display_plots, save_plots, model_name=model_name + add_name)\n",
    "        #           metric=metric)\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "def run_block_test():\n",
    "    # Run test with a specific block (e.g., block 14 - middle block)\n",
    "    test_new_decoder(\n",
    "        real=True,\n",
    "        model_name='decoder_4609_350',\n",
    "#        test_input=filtered_testset['fMRIs'],\n",
    "#        test_label=filtered_testset['videos'],\n",
    "        test_input=filtered_trainset['fMRIs'],\n",
    "        test_label=filtered_trainset['videos'],\n",
    "    #    model_name='decoder_all_4609_325',\n",
    "    #    test_input=filtered_trainset_new['fMRIs'],\n",
    "    #    test_label=filtered_trainset_new['videos'],\n",
    "        block_id=14,  # Choose a block number between 1 and 27\n",
    "        all_frames=True,\n",
    "        save_plots=False,\n",
    "        add_name='_block_14',\n",
    "        change_mode='off',\n",
    "        num_blocks=(3,3,3),\n",
    "        metric=\"tv\"\n",
    "    )\n",
    "    \n",
    "# Call the function\n",
    "#run_block_test()\n",
    "\n",
    "# Call the function\n",
    "# run_block_test()  # Uncomment to test a single block\n",
    "# run_all_blocks_test()  # Uncomment to test all blocks sequentially\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#tag debug\n",
    "\n",
    "\n",
    "def plot_all_predictions7(predictions, videos, performance_dict=None, display_plots=True, save_plots=False, \n",
    "                 save_path_prefix=None, model_name=\"\", device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                 metric=\"ssim\", mean_flag=False, zone_type=\"quadrants\", max_frames=None, baseline_predictions=None):\n",
    "    \"\"\"\n",
    "    Display comparison plots between original videos and predictions.\n",
    "    Shows: Original image, baseline reconstruction, perturbed reconstruction, and difference heatmap.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    predictions : dict\n",
    "        Dictionary of prediction arrays (perturbed reconstructions)\n",
    "    videos : dict\n",
    "        Dictionary of ground truth video arrays\n",
    "    performance_dict : dict, optional\n",
    "        Dictionary to store performance metrics\n",
    "    display_plots : bool\n",
    "        Whether to display the plots\n",
    "    save_plots : bool\n",
    "        Whether to save the plots\n",
    "    save_path_prefix : str, optional\n",
    "        Path prefix for saving plots\n",
    "    model_name : str\n",
    "        Name of the model for saving plots\n",
    "    device : str\n",
    "        Device to use for computations\n",
    "    metric : str\n",
    "        Metric to use for evaluation: \"ssim\" or \"tv\" (Total Variation)\n",
    "    mean_flag : bool\n",
    "        Whether to return mean metrics or not\n",
    "    zone_type : str or int\n",
    "        Type of zones: \n",
    "        - \"quadrants\" for 2×2 grid\n",
    "        - \"center_bg\" for center and background\n",
    "        - integer n for n×n grid (e.g., 4 creates a 4×4 grid with 16 zones)\n",
    "    max_frames : int, optional\n",
    "        Maximum number of frames to plot. If None, all frames will be plotted.\n",
    "    baseline_predictions : dict, optional\n",
    "        Dictionary of baseline prediction arrays (without perturbation)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import torch\n",
    "    import os\n",
    "    from matplotlib.patches import Rectangle\n",
    "    from matplotlib.colors import LinearSegmentedColormap, Normalize\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    if save_plots and save_path_prefix:\n",
    "        os.makedirs(save_path_prefix, exist_ok=True)\n",
    "\n",
    "    # Debug information about inputs\n",
    "    print(\"\\n=== DEBUG INFO ===\")\n",
    "    print(f\"Predictions dictionary contains {len(predictions)} keys: {list(predictions.keys())}\")\n",
    "    print(f\"Videos dictionary contains {len(videos)} keys: {list(videos.keys())}\")\n",
    "    print(f\"Using metric: {metric}\")\n",
    "    print(f\"Baseline predictions provided: {baseline_predictions is not None}\")\n",
    "    \n",
    "    if isinstance(zone_type, int):\n",
    "        print(f\"Using {zone_type}×{zone_type} grid zones ({zone_type*zone_type} total zones)\")\n",
    "    else:\n",
    "        print(f\"Using zone type: {zone_type}\")\n",
    "    \n",
    "    # Find the overlapping keys between predictions and videos\n",
    "    common_keys = [key for key in predictions.keys() if key in videos]\n",
    "    print(f\"Common keys in both dictionaries: {common_keys}\")\n",
    "    \n",
    "    # Create key mapping between predictions and videos\n",
    "    if not common_keys and len(videos) > 0:\n",
    "        print(\"No common keys found. Trying to match prediction keys to video keys.\")\n",
    "        ref_video_key = list(videos.keys())[0]\n",
    "        print(f\"Using {ref_video_key} as reference video for all predictions\")\n",
    "        key_mapping = {pred_key: ref_video_key for pred_key in predictions.keys()}\n",
    "    else:\n",
    "        key_mapping = {}\n",
    "        for pred_key in predictions.keys():\n",
    "            if pred_key in videos:\n",
    "                key_mapping[pred_key] = pred_key\n",
    "            else:\n",
    "                matched = False\n",
    "                for video_key in videos.keys():\n",
    "                    if video_key in pred_key:\n",
    "                        key_mapping[pred_key] = video_key\n",
    "                        matched = True\n",
    "                        break\n",
    "                if not matched and len(videos) > 0:\n",
    "                    key_mapping[pred_key] = list(videos.keys())[0]\n",
    "    \n",
    "    print(f\"Key mapping from prediction keys to video keys: {key_mapping}\")\n",
    "    \n",
    "    # Helper function to split frame into zones\n",
    "    def split_into_zones(frame, zone_type=\"quadrants\", center_ratio=0.5):\n",
    "        \"\"\"\n",
    "        Split a frame into zones.\n",
    "        \"\"\"\n",
    "        if isinstance(frame, torch.Tensor):\n",
    "            C, H, W = frame.shape\n",
    "        else:\n",
    "            C, H, W = frame.shape\n",
    "            \n",
    "        zones = {}\n",
    "        \n",
    "        if zone_type == \"quadrants\":\n",
    "            # Split into 4 quadrants (2×2 grid)\n",
    "            h_mid = H // 2\n",
    "            w_mid = W // 2\n",
    "            \n",
    "            zones[\"top_left\"] = (slice(None), slice(0, h_mid), slice(0, w_mid))\n",
    "            zones[\"top_right\"] = (slice(None), slice(0, h_mid), slice(w_mid, W))\n",
    "            zones[\"bottom_left\"] = (slice(None), slice(h_mid, H), slice(0, w_mid))\n",
    "            zones[\"bottom_right\"] = (slice(None), slice(h_mid, H), slice(w_mid, W))\n",
    "            \n",
    "        elif zone_type == \"center_bg\":\n",
    "            # Split into center and background\n",
    "            h_center = int(H * center_ratio)\n",
    "            w_center = int(W * center_ratio)\n",
    "            \n",
    "            h_start = (H - h_center) // 2\n",
    "            h_end = h_start + h_center\n",
    "            w_start = (W - w_center) // 2\n",
    "            w_end = w_start + w_center\n",
    "            \n",
    "            zones[\"center\"] = (slice(None), slice(h_start, h_end), slice(w_start, w_end))\n",
    "            \n",
    "            # Background is everything except the center\n",
    "            center_mask = np.zeros((H, W), dtype=bool)\n",
    "            center_mask[h_start:h_end, w_start:w_end] = True\n",
    "            \n",
    "            zones[\"background\"] = {\"mask\": ~center_mask, \n",
    "                                   \"bounds\": (h_start, h_end, w_start, w_end)}\n",
    "            \n",
    "        elif isinstance(zone_type, int) and zone_type > 0:\n",
    "            # Create an n×n grid where n = zone_type\n",
    "            n = zone_type\n",
    "            \n",
    "            # Calculate heights of each section\n",
    "            h_sections = [i * H // n for i in range(n+1)]\n",
    "            w_sections = [i * W // n for i in range(n+1)]\n",
    "            \n",
    "            # Create zones for each grid cell\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    zone_name = f\"grid_{i}_{j}\"  # Row_Column naming\n",
    "                    zones[zone_name] = (\n",
    "                        slice(None),\n",
    "                        slice(h_sections[i], h_sections[i+1]),\n",
    "                        slice(w_sections[j], w_sections[j+1])\n",
    "                    )\n",
    "                    \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown zone type: {zone_type}\")\n",
    "            \n",
    "        return zones\n",
    "    \n",
    "    # Helper function to calculate zone metrics\n",
    "    def calculate_zone_metrics(orig_frame, pred_frame, baseline_frame=None, zones=None, metric=\"ssim\", device=device):\n",
    "        \"\"\"\n",
    "        Calculate metrics for each zone.\n",
    "        If baseline_frame is provided, calculate the difference: baseline_metrics - pred_metrics\n",
    "        \"\"\"\n",
    "        from pytorch_msssim import ssim\n",
    "        \n",
    "        # If zones not provided, calculate them\n",
    "        if zones is None:\n",
    "            zones = split_into_zones(orig_frame, zone_type=zone_type)\n",
    "        \n",
    "        zone_metrics = {}\n",
    "        \n",
    "        # Convert to torch tensors if needed\n",
    "        if not isinstance(orig_frame, torch.Tensor):\n",
    "            orig_tensor = torch.from_numpy(orig_frame).unsqueeze(0)\n",
    "        else:\n",
    "            orig_tensor = orig_frame.unsqueeze(0)\n",
    "            \n",
    "        if not isinstance(pred_frame, torch.Tensor):\n",
    "            pred_tensor = torch.from_numpy(pred_frame).unsqueeze(0)\n",
    "        else:\n",
    "            pred_tensor = pred_frame.unsqueeze(0)\n",
    "        \n",
    "        # Process baseline frame if provided    \n",
    "        if baseline_frame is not None:\n",
    "            if not isinstance(baseline_frame, torch.Tensor):\n",
    "                baseline_tensor = torch.from_numpy(baseline_frame).unsqueeze(0)\n",
    "            else:\n",
    "                baseline_tensor = baseline_frame.unsqueeze(0)\n",
    "        \n",
    "        # Calculate metrics for each zone\n",
    "        for zone_name, zone_slice in zones.items():\n",
    "            # Special handling for background in center_bg mode\n",
    "            if isinstance(zone_slice, dict):  # Background in center_bg mode\n",
    "                mask = zone_slice[\"mask\"]\n",
    "                \n",
    "                orig_zone = orig_tensor.clone()\n",
    "                pred_zone = pred_tensor.clone()\n",
    "                \n",
    "                # Apply mask to all channels\n",
    "                for c in range(orig_zone.shape[1]):  # For each channel\n",
    "                    orig_zone[0, c][~mask] = 0\n",
    "                    pred_zone[0, c][~mask] = 0\n",
    "                \n",
    "                # Calculate metric for prediction\n",
    "                if metric == \"ssim\":\n",
    "                    pred_metric = ssim(orig_zone, pred_zone, data_range=1, size_average=True).item()\n",
    "                else:\n",
    "                    # TV Loss calculation for masked region\n",
    "                    tv_loss = torch.abs(pred_zone[:,:,1:,:] - pred_zone[:,:,:-1,:]).sum() + \\\n",
    "                              torch.abs(pred_zone[:,:,:,1:] - pred_zone[:,:,:,:-1]).sum()\n",
    "                    # Normalize by number of pixels in the zone\n",
    "                    pred_metric = tv_loss.item() / mask.sum()\n",
    "                \n",
    "                # If baseline provided, calculate baseline metric and difference\n",
    "                if baseline_frame is not None:\n",
    "                    baseline_zone = baseline_tensor.clone()\n",
    "                    for c in range(baseline_zone.shape[1]):\n",
    "                        baseline_zone[0, c][~mask] = 0\n",
    "                        \n",
    "                    if metric == \"ssim\":\n",
    "                        base_metric = ssim(orig_zone, baseline_zone, data_range=1, size_average=True).item()\n",
    "                        # For SSIM, higher is better, so baseline - perturbed shows how much we lost\n",
    "                        # (negative value means perturbation improved SSIM)\n",
    "                        zone_metrics[zone_name] = base_metric - pred_metric\n",
    "                    else:\n",
    "                        # TV Loss\n",
    "                        tv_loss = torch.abs(baseline_zone[:,:,1:,:] - baseline_zone[:,:,:-1,:]).sum() + \\\n",
    "                                 torch.abs(baseline_zone[:,:,:,1:] - baseline_zone[:,:,:,:-1]).sum()\n",
    "                        base_metric = tv_loss.item() / mask.sum()\n",
    "                        # For TV loss, lower is better, so perturbed - baseline shows how much we lost\n",
    "                        # (positive value means perturbation worsened TV loss)\n",
    "                        zone_metrics[zone_name] = pred_metric - base_metric\n",
    "                else:\n",
    "                    # No baseline, just use the prediction metric\n",
    "                    zone_metrics[zone_name] = pred_metric\n",
    "                \n",
    "            else:  # Normal zones\n",
    "                # Get the zone data\n",
    "                orig_zone = orig_tensor[0][zone_slice].unsqueeze(0)\n",
    "                pred_zone = pred_tensor[0][zone_slice].unsqueeze(0)\n",
    "                \n",
    "                # Calculate metric for prediction\n",
    "                if metric == \"ssim\":\n",
    "                    pred_metric = ssim(orig_zone, pred_zone, data_range=1, size_average=True).item()\n",
    "                else:\n",
    "                    # TV Loss calculation\n",
    "                    tv_loss = torch.abs(pred_zone[:,:,1:,:] - pred_zone[:,:,:-1,:]).sum() + \\\n",
    "                              torch.abs(pred_zone[:,:,:,1:] - pred_zone[:,:,:,:-1]).sum()\n",
    "                    # Normalize by number of pixels in the zone\n",
    "                    pred_metric = tv_loss.item() / (orig_zone.shape[2] * orig_zone.shape[3])\n",
    "                \n",
    "                # If baseline provided, calculate baseline metric and difference\n",
    "                if baseline_frame is not None:\n",
    "                    baseline_zone = baseline_tensor[0][zone_slice].unsqueeze(0)\n",
    "                    \n",
    "                    if metric == \"ssim\":\n",
    "                        base_metric = ssim(orig_zone, baseline_zone, data_range=1, size_average=True).item()\n",
    "                        # For SSIM, higher is better, so baseline - perturbed shows how much we lost\n",
    "                        zone_metrics[zone_name] = base_metric - pred_metric\n",
    "                    else:\n",
    "                        # TV Loss\n",
    "                        tv_loss = torch.abs(baseline_zone[:,:,1:,:] - baseline_zone[:,:,:-1,:]).sum() + \\\n",
    "                                 torch.abs(baseline_zone[:,:,:,1:] - baseline_zone[:,:,:,:-1]).sum()\n",
    "                        base_metric = tv_loss.item() / (baseline_zone.shape[2] * baseline_zone.shape[3])\n",
    "                        # For TV loss, lower is better, so perturbed - baseline shows how much we lost\n",
    "                        # (positive value means perturbation worsened TV loss)\n",
    "                        zone_metrics[zone_name] = pred_metric - base_metric\n",
    "                else:\n",
    "                    # No baseline, just use the prediction metric\n",
    "                    zone_metrics[zone_name] = pred_metric\n",
    "        \n",
    "        return zone_metrics\n",
    "    \n",
    "    # Helper function for normalizing images for display\n",
    "    def normalize(img):\n",
    "        \"\"\"Normalize image for display\"\"\"\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img = img.detach().cpu().numpy()\n",
    "        \n",
    "        img = img.copy()\n",
    "        if img.min() < 0:\n",
    "            img = (img + 1) / 2  # [-1, 1] -> [0, 1]\n",
    "        return np.clip(img, 0, 1)\n",
    "    \n",
    "    # Initialize metrics\n",
    "    all_zone_metrics = {}  # Will store metrics for each prediction key\n",
    "    \n",
    "    # Get appropriate metric name\n",
    "    if baseline_predictions is not None:\n",
    "        metric_description = \"Difference from Baseline\" \n",
    "        if metric == \"ssim\":\n",
    "            metric_name = \"SSIM Difference\"\n",
    "        else:\n",
    "            metric_name = \"TV Loss Difference\"\n",
    "    else:\n",
    "        metric_name = \"SSIM\" if metric == \"ssim\" else \"TV Loss\"\n",
    "        metric_description = metric_name\n",
    "    \n",
    "    # Create a TV loss calculator if needed\n",
    "    if metric == \"tv\":\n",
    "        tv_calculator = TotalVariation().to(device)\n",
    "    \n",
    "    # ===== PART 1: Calculate zone metrics for each prediction =====\n",
    "    for pred_key, video_key in key_mapping.items():\n",
    "        prediction = predictions[pred_key]\n",
    "        video = videos[video_key][..., 15]  # Middle frame\n",
    "        \n",
    "        # Get baseline prediction if available\n",
    "        baseline_pred = None\n",
    "        if baseline_predictions is not None:\n",
    "            # Find the appropriate key in baseline predictions\n",
    "            baseline_keys = list(baseline_predictions.keys())\n",
    "            if pred_key in baseline_predictions:\n",
    "                baseline_pred = baseline_predictions[pred_key]\n",
    "            elif len(baseline_keys) > 0:\n",
    "                # If exact key not found, use first available baseline key\n",
    "                baseline_pred = baseline_predictions[baseline_keys[0]]\n",
    "                print(f\"Using {baseline_keys[0]} as baseline for {pred_key}\")\n",
    "        \n",
    "        # Check shapes\n",
    "        print(f\"Prediction {pred_key} shape: {prediction.shape}\")\n",
    "        print(f\"Video {video_key} shape: {video.shape}\")\n",
    "        if baseline_pred is not None:\n",
    "            print(f\"Baseline prediction shape: {baseline_pred.shape}\")\n",
    "        \n",
    "        # Ensure prediction and video have compatible shapes\n",
    "        if prediction.shape[0] != video.shape[0]:\n",
    "            print(f\"Warning: Shape mismatch for {pred_key} vs {video_key}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # If baseline exists, ensure it has compatible shape\n",
    "        if baseline_pred is not None and baseline_pred.shape[0] != prediction.shape[0]:\n",
    "            print(f\"Warning: Baseline shape {baseline_pred.shape} doesn't match prediction shape {prediction.shape}. Ignoring baseline.\")\n",
    "            baseline_pred = None\n",
    "        \n",
    "        N = video.shape[0]\n",
    "        \n",
    "        # Store metrics for all frames in this prediction\n",
    "        pred_metrics = []\n",
    "        \n",
    "        # Calculate metrics for each frame\n",
    "        for i in range(N):\n",
    "            # Get zones for this frame\n",
    "            zones = split_into_zones(video[i], zone_type=zone_type)\n",
    "            \n",
    "            # Calculate metrics for each zone\n",
    "            try:\n",
    "                # If baseline exists, calculate difference metrics\n",
    "                if baseline_pred is not None:\n",
    "                    zone_metrics = calculate_zone_metrics(\n",
    "                        video[i], prediction[i], baseline_frame=baseline_pred[i], zones=zones, metric=metric\n",
    "                    )\n",
    "                else:\n",
    "                    zone_metrics = calculate_zone_metrics(\n",
    "                        video[i], prediction[i], zones=zones, metric=metric\n",
    "                    )\n",
    "                pred_metrics.append(zone_metrics)\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating zone metrics for {pred_key}, frame {i}: {e}\")\n",
    "                # Create empty metrics\n",
    "                if zone_type == \"quadrants\":\n",
    "                    pred_metrics.append({\n",
    "                        \"top_left\": 0, \"top_right\": 0, \n",
    "                        \"bottom_left\": 0, \"bottom_right\": 0\n",
    "                    })\n",
    "                elif zone_type == \"center_bg\":\n",
    "                    pred_metrics.append({\"center\": 0, \"background\": 0})\n",
    "                elif isinstance(zone_type, int):\n",
    "                    empty_metrics = {}\n",
    "                    for ii in range(zone_type):\n",
    "                        for jj in range(zone_type):\n",
    "                            empty_metrics[f\"grid_{ii}_{jj}\"] = 0\n",
    "                    pred_metrics.append(empty_metrics)\n",
    "        \n",
    "        # Store metrics for this prediction\n",
    "        all_zone_metrics[pred_key] = pred_metrics\n",
    "        \n",
    "        # Print average metrics for this prediction\n",
    "        print(f\"\\nAverage {metric_description} for {pred_key} by zone:\")\n",
    "        \n",
    "        # Calculate and print mean metrics across frames for each zone\n",
    "        if len(pred_metrics) > 0:\n",
    "            zone_names = list(pred_metrics[0].keys())\n",
    "            \n",
    "            for zone in zone_names:\n",
    "                zone_values = [metrics[zone] for metrics in pred_metrics]\n",
    "                mean_zone = np.mean(zone_values)\n",
    "                print(f\"  - {zone}: {mean_zone:.4f}\")\n",
    "    \n",
    "    # ===== PART 2: Plot the original image, baseline, reconstruction, and heatmap side by side =====\n",
    "    if display_plots and len(key_mapping) > 0:\n",
    "        # Get a reference video key and shape\n",
    "        ref_video_key = list(videos.keys())[0]\n",
    "        ref_video = videos[ref_video_key][..., 15]\n",
    "        N = ref_video.shape[0]\n",
    "        \n",
    "        # Determine the frames to plot\n",
    "        if max_frames is not None and max_frames < N:\n",
    "            # Evenly sample frames if max_frames is specified\n",
    "            indices = np.linspace(0, N-1, max_frames, dtype=int)\n",
    "        else:\n",
    "            # Plot all frames\n",
    "            indices = np.arange(N)\n",
    "        \n",
    "        # Determine number of panels based on whether baseline is available\n",
    "        if baseline_predictions is not None:\n",
    "            num_panels = 4  # Original, Baseline, Perturbed, Difference\n",
    "            print(f\"\\nPlotting {len(indices)} frames with Original, Baseline, Perturbed, and Difference\")\n",
    "        else:\n",
    "            num_panels = 3  # Original, Reconstruction, Heatmap\n",
    "            print(f\"\\nPlotting {len(indices)} frames with Original, Reconstruction, and Heatmap\")\n",
    "        \n",
    "        # REORDERING: Create an ordered list of prediction keys with \"original_combined\" first\n",
    "        ordered_keys = []\n",
    "        for key in key_mapping.keys():\n",
    "            if key != \"original_combined\":\n",
    "                ordered_keys.append(key)\n",
    "        \n",
    "        # If \"original_combined\" exists, insert it at the beginning of the list\n",
    "        if \"original_combined\" in key_mapping:\n",
    "            ordered_keys.insert(0, \"original_combined\")\n",
    "        \n",
    "        # For each frame index\n",
    "        for frame_idx in indices:\n",
    "            # Plot original reference frame\n",
    "            ref_frame = ref_video[frame_idx]\n",
    "            \n",
    "            # For each prediction\n",
    "            for pred_key in ordered_keys:\n",
    "                try:\n",
    "                    video_key = key_mapping[pred_key]\n",
    "                    perturbed_frame = predictions[pred_key][frame_idx]\n",
    "                    \n",
    "                    # Get baseline frame if available\n",
    "                    baseline_frame = None\n",
    "                    if baseline_predictions is not None:\n",
    "                        if pred_key in baseline_predictions:\n",
    "                            baseline_frame = baseline_predictions[pred_key][frame_idx]\n",
    "                        elif len(baseline_predictions) > 0:\n",
    "                            # Use first available baseline prediction\n",
    "                            first_key = list(baseline_predictions.keys())[0]\n",
    "                            baseline_frame = baseline_predictions[first_key][frame_idx]\n",
    "                    \n",
    "                    # Get zone metrics for this prediction\n",
    "                    zone_metrics = all_zone_metrics[pred_key][frame_idx]\n",
    "                    \n",
    "                    # Determine if we're showing differences or absolute values\n",
    "                    is_difference = baseline_frame is not None\n",
    "                    \n",
    "                    # Create a figure with the appropriate number of subplots\n",
    "                    fig, axes = plt.subplots(1, num_panels, figsize=(5 * num_panels, 5))\n",
    "                    \n",
    "                    # 1. Original Frame (leftmost)\n",
    "                    axes[0].imshow(np.transpose(normalize(ref_frame), (1, 2, 0)))\n",
    "                    axes[0].set_title(f\"Original Frame {frame_idx}\")\n",
    "                    axes[0].axis('off')\n",
    "                    \n",
    "                    # Panel index for reconstruction and heatmap depends on whether baseline exists\n",
    "                    recon_idx = 2 if is_difference else 1\n",
    "                    heatmap_idx = 3 if is_difference else 2\n",
    "                    \n",
    "                    # 2. Baseline Reconstruction (if available)\n",
    "                    if is_difference:\n",
    "                        axes[1].imshow(np.transpose(normalize(baseline_frame), (1, 2, 0)))\n",
    "                        axes[1].set_title(f\"Baseline Reconstruction\")\n",
    "                        axes[1].axis('off')\n",
    "                    \n",
    "                    # 3. Perturbed Reconstruction \n",
    "                    axes[recon_idx].imshow(np.transpose(normalize(perturbed_frame), (1, 2, 0)))\n",
    "                    if is_difference:\n",
    "                        axes[recon_idx].set_title(f\"Perturbed Reconstruction\")\n",
    "                    else:\n",
    "                        axes[recon_idx].set_title(f\"{pred_key} (Frame {frame_idx})\")\n",
    "                    axes[recon_idx].axis('off')\n",
    "                    \n",
    "                    # 4. Heatmap of metrics (rightmost)\n",
    "                    # Determine colormap based on if we're showing differences\n",
    "                    cmap_name = 'coolwarm' if is_difference else 'viridis'\n",
    "                    \n",
    "                    # Also determine normalization based on if we're showing differences\n",
    "                    if is_difference:\n",
    "                        # For differences, use symmetric normalization around zero\n",
    "                        values = list(zone_metrics.values())\n",
    "                        max_abs = max(abs(min(values)), abs(max(values))) if values else 1.0\n",
    "                        norm = Normalize(vmin=-max_abs, vmax=max_abs)\n",
    "                    else:\n",
    "                        # For absolute values, use standard normalization\n",
    "                        norm = None  # Let matplotlib handle it\n",
    "                    \n",
    "                    if isinstance(zone_type, int):\n",
    "                        # For n×n grid, create a grid to display metrics\n",
    "                        grid_values = np.zeros((zone_type, zone_type))\n",
    "                        \n",
    "                        for i in range(zone_type):\n",
    "                            for j in range(zone_type):\n",
    "                                zone_name = f\"grid_{i}_{j}\"\n",
    "                                grid_values[i, j] = zone_metrics.get(zone_name, 0)\n",
    "                        \n",
    "                        # Show the heatmap\n",
    "                        im = axes[heatmap_idx].imshow(grid_values, cmap=cmap_name, interpolation='nearest', norm=norm)\n",
    "                        \n",
    "                        # Add text labels with adjustable font size\n",
    "                        fontsize = max(6, min(10, 16 - zone_type))  # Scale font size based on grid density\n",
    "                        for i in range(zone_type):\n",
    "                            for j in range(zone_type):\n",
    "                                # Format the value based on magnitude\n",
    "                                val = grid_values[i, j]\n",
    "                                if abs(val) >= 0.01:\n",
    "                                    text = f\"{val:.3f}\"\n",
    "                                else:\n",
    "                                    text = f\"{val:.1e}\"\n",
    "                                    \n",
    "                                axes[heatmap_idx].text(j, i, text,\n",
    "                                           ha=\"center\", va=\"center\", color=\"white\",\n",
    "                                           fontsize=fontsize, fontweight='bold')\n",
    "                        \n",
    "                        # Add colorbar\n",
    "                        cbar = plt.colorbar(im, ax=axes[heatmap_idx])\n",
    "                        cbar.set_label(metric_name)\n",
    "                        \n",
    "                        axes[heatmap_idx].set_title(f\"Zone {metric_description}\")\n",
    "                        \n",
    "                    elif zone_type == \"quadrants\":\n",
    "                        # For quadrants, create a 2×2 heatmap\n",
    "                        quadrant_values = np.zeros((2, 2))\n",
    "                        quadrant_values[0, 0] = zone_metrics.get(\"top_left\", 0)\n",
    "                        quadrant_values[0, 1] = zone_metrics.get(\"top_right\", 0)\n",
    "                        quadrant_values[1, 0] = zone_metrics.get(\"bottom_left\", 0)\n",
    "                        quadrant_values[1, 1] = zone_metrics.get(\"bottom_right\", 0)\n",
    "                        \n",
    "                        # Show the heatmap\n",
    "                        im = axes[heatmap_idx].imshow(quadrant_values, cmap=cmap_name, interpolation='nearest', norm=norm)\n",
    "                        \n",
    "                        # Add text labels\n",
    "                        for i, j in [(0,0), (0,1), (1,0), (1,1)]:\n",
    "                            val = quadrant_values[i, j]\n",
    "                            if abs(val) >= 0.01:\n",
    "                                text = f\"{val:.3f}\"\n",
    "                            else:\n",
    "                                text = f\"{val:.1e}\"\n",
    "                            axes[heatmap_idx].text(j, i, text, ha=\"center\", va=\"center\", color=\"white\", fontsize=10)\n",
    "                        \n",
    "                        # Add colorbar\n",
    "                        cbar = plt.colorbar(im, ax=axes[heatmap_idx])\n",
    "                        cbar.set_label(metric_name)\n",
    "                        \n",
    "                        axes[heatmap_idx].set_title(f\"Quadrant {metric_description}\")\n",
    "                        \n",
    "                    elif zone_type == \"center_bg\":\n",
    "                        # For center/background, special visualization\n",
    "                        center_val = zone_metrics.get(\"center\", 0)\n",
    "                        bg_val = zone_metrics.get(\"background\", 0)\n",
    "                        \n",
    "                        # Create a mask-based visualization\n",
    "                        mask = np.zeros((3, 3), dtype=bool)\n",
    "                        mask[1, 1] = True  # Center is True, background is False\n",
    "                        \n",
    "                        # Create values array where center has one value, background another\n",
    "                        values = np.ones((3, 3)) * bg_val\n",
    "                        values[1, 1] = center_val\n",
    "                        \n",
    "                        # Show the heatmap\n",
    "                        im = axes[heatmap_idx].imshow(values, cmap=cmap_name, interpolation='nearest', norm=norm)\n",
    "                        \n",
    "                        # Format values for display\n",
    "                        if abs(center_val) >= 0.01:\n",
    "                            center_text = f\"Center\\n{center_val:.3f}\"\n",
    "                        else:\n",
    "                            center_text = f\"Center\\n{center_val:.1e}\"\n",
    "                            \n",
    "                        if abs(bg_val) >= 0.01:\n",
    "                            bg_text = f\"BG\\n{bg_val:.3f}\"\n",
    "                        else:\n",
    "                            bg_text = f\"BG\\n{bg_val:.1e}\"\n",
    "                        \n",
    "                        # Add text labels\n",
    "                        axes[heatmap_idx].text(1, 1, center_text, ha=\"center\", va=\"center\", color=\"white\", fontsize=10)\n",
    "                        axes[heatmap_idx].text(0, 0, bg_text, ha=\"center\", va=\"center\", color=\"white\", fontsize=10)\n",
    "                        \n",
    "                        # Add colorbar\n",
    "                        cbar = plt.colorbar(im, ax=axes[heatmap_idx])\n",
    "                        cbar.set_label(metric_name)\n",
    "                        \n",
    "                        axes[heatmap_idx].set_title(f\"Center/Background {metric_description}\")\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    \n",
    "                    # Save figure if requested\n",
    "                    if save_plots and save_path_prefix:\n",
    "                        zone_type_str = zone_type if isinstance(zone_type, str) else f\"grid{zone_type}x{zone_type}\"\n",
    "                        type_str = \"diff\" if is_difference else \"abs\"\n",
    "                        fig_path = f\"{save_path_prefix}{pred_key}_frame{frame_idx}_{metric}_{zone_type_str}_{type_str}.png\"\n",
    "                        plt.savefig(fig_path, bbox_inches='tight', dpi=300)\n",
    "                    \n",
    "                    plt.show()\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error creating visualization for {pred_key} (Frame {frame_idx}): {e}\")\n",
    "    \n",
    "    # Calculate overall mean metric\n",
    "    overall_mean = 0\n",
    "    if len(all_zone_metrics) > 0:\n",
    "        # Average across all predictions and all zones\n",
    "        all_values = []\n",
    "        for pred_metrics in all_zone_metrics.values():\n",
    "            for metrics in pred_metrics:\n",
    "                all_values.extend(list(metrics.values()))\n",
    "        \n",
    "        if all_values:\n",
    "            overall_mean = np.mean(all_values)\n",
    "    \n",
    "    # Update performance dictionary if provided\n",
    "    if performance_dict is not None:\n",
    "        try:\n",
    "            # Calculate overall metrics across all zones\n",
    "            for pred_key, pred_metrics in all_zone_metrics.items():\n",
    "                if len(pred_metrics) > 0:\n",
    "                    zone_names = list(pred_metrics[0].keys())\n",
    "                    \n",
    "                    for zone in zone_names:\n",
    "                        zone_values = [metrics[zone] for metrics in pred_metrics]\n",
    "                        zone_mean = np.mean(zone_values)\n",
    "                        zone_median = np.median(zone_values)\n",
    "                        \n",
    "                        # Add to performance dict\n",
    "                        if baseline_predictions is not None:\n",
    "                            # This is a difference metric\n",
    "                            if metric == \"ssim\":\n",
    "                                performance_dict[f'diff_ssim_{zone}_D'] = zone_mean\n",
    "                                performance_dict[f'median_diff_ssim_{zone}_D'] = zone_median\n",
    "                            else:\n",
    "                                performance_dict[f'diff_tv_{zone}_D'] = zone_mean\n",
    "                                performance_dict[f'median_diff_tv_{zone}_D'] = zone_median\n",
    "                        else:\n",
    "                            # This is an absolute metric\n",
    "                            if metric == \"ssim\":\n",
    "                                performance_dict[f'mean_ssim_{zone}_D'] = zone_mean\n",
    "                                performance_dict[f'median_ssim_{zone}_D'] = zone_median\n",
    "                            else:\n",
    "                                performance_dict[f'mean_tv_{zone}_D'] = zone_mean\n",
    "                                performance_dict[f'median_tv_{zone}_D'] = zone_median\n",
    "            \n",
    "            # Add overall mean metric\n",
    "            if baseline_predictions is not None:\n",
    "                # This is a difference metric\n",
    "                if metric == \"ssim\":\n",
    "                    performance_dict['diff_ssim_D'] = overall_mean\n",
    "                else:\n",
    "                    performance_dict['diff_tv_D'] = overall_mean\n",
    "            else:\n",
    "                # This is an absolute metric\n",
    "                if metric == \"ssim\":\n",
    "                    performance_dict['mean_ssim_D'] = overall_mean\n",
    "                else:\n",
    "                    performance_dict['mean_tv_D'] = overall_mean\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error updating performance dictionary: {e}\")\n",
    "    \n",
    "    if mean_flag:\n",
    "        return overall_mean\n",
    "    \n",
    "    return performance_dict\n",
    "\n",
    "\n",
    "\n",
    "def test_model_all(inputs_dict, labels_dict, model, criterion, device, pretrained_decoder=None, model_to_test=None, \n",
    "               statistical_testing=False, display_plots=True, save_plots=False, model_name=\"\", metric=\"ssim\", \n",
    "               mean_flag=False, zones=None, baseline_predictions=None):\n",
    "    \"\"\"\n",
    "    Test the pretrained model on the provided dataset.\n",
    "\n",
    "    Arguments:\n",
    "        inputs_dict (dict): Dictionary of input data. Keys are movie names or slice identifiers. \n",
    "                           If model_to_test is 'encoder' or 'encoder_decoder', then elements have a shape of (TR, 3, 112, 112, 32). \n",
    "                           Else, shape of (TR, mask_size).\n",
    "        labels_dict (dict): Dictionary of labels. Keys are movie names. \n",
    "                           If model_to_test is 'encoder' or 'encoder_decoder', then elements have a shape of (TR, mask_size). \n",
    "                           Else, shape of (TR, 3, 112, 112, 32).\n",
    "        model (nn.Module): The pretrained neural network model to be tested.\n",
    "        criterion (nn.Module): Loss function for testing.\n",
    "        device (torch.device): Device to test the model on (CPU or GPU).\n",
    "        pretrained_decoder (str, optional): Path to a pretrained decoder model. Default is None.\n",
    "        model_to_test (str): Specifies which part of the model to test. Options are 'encoder', 'decoder', or 'encoder_decoder'.\n",
    "        statistical_testing (bool, optional): Whether to perform statistical testing. Default is False.\n",
    "        display_plots (bool, optional): Whether to display plots. Default is True.\n",
    "        save_plots (bool, optional): Whether to save plots. Default is False.\n",
    "        model_name (str, optional): Name of the model for saving plots. Default is \"\".\n",
    "        zones (str or int, optional): Zones to consider for testing. Default is \"quadrants\", can also be \"center_bg\".\n",
    "                                      If it is an integer, the function will analyze a number of zones = that integer squared.\n",
    "                                      For example, if zones = 4, the function will analyze 16 zones (4x4).\n",
    "        baseline_predictions (dict, optional): Dictionary of baseline predictions for comparison.\n",
    "\n",
    "    Returns:\n",
    "        results (dict): Dictionary containing test results including model predictions and losses.\n",
    "    \"\"\"\n",
    "    print('Start testing:')\n",
    "    tic = time.time()\n",
    "\n",
    "    # Create outputs directory if it doesn't exist\n",
    "    if save_plots:\n",
    "        import os\n",
    "        os.makedirs('outputs', exist_ok=True)\n",
    "\n",
    "    model_type = ['encoder', 'decoder', 'encoder_decoder']\n",
    "    if model_to_test not in model_type:\n",
    "        print(f'model_to_test: {model_to_test} not recognized. Must be one of {model_type}')\n",
    "        return None, None\n",
    "\n",
    "    # Get list of input keys (movie names or slice identifiers)\n",
    "    videos = list(inputs_dict.keys())\n",
    "    inputs_shape = list(inputs_dict[videos[0]].shape)\n",
    "    inputs_shape[0] = 'TR'\n",
    "    print(f'### Testing {model_to_test} on inputs of shape {inputs_shape} over {len(videos)} videos/slices ###')\n",
    "    \n",
    "    if baseline_predictions is not None:\n",
    "        print(f'### Using baseline predictions for comparison ###')\n",
    "\n",
    "    criterion = criterion.to(device)\n",
    "    # Set model in testing phase\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Load and set pretrained decoder if specified\n",
    "    if pretrained_decoder:\n",
    "        decoder = Decoder(labels_dict[next(iter(labels_dict))].shape[1])  # Assuming shape is consistent across labels\n",
    "        state_dict = torch.load(pretrained_decoder)\n",
    "        decoder.load_state_dict(state_dict)\n",
    "        decoder.to(device)\n",
    "        for param in decoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        decoder.eval()\n",
    "\n",
    "        print(f'Also using pretrained decoder {pretrained_decoder}')\n",
    "\n",
    "    if model_to_test != 'encoder_decoder' and pretrained_decoder is None:\n",
    "        results = {\n",
    "            model_to_test + '_predictions': {},\n",
    "            'total_losses': {}\n",
    "        }\n",
    "    else:\n",
    "        results = {\n",
    "            'encoder_predictions': {},\n",
    "            'decoder_predictions': {},\n",
    "            'total_losses': {}\n",
    "        }\n",
    "\n",
    "        decoder_saliency = np.zeros(labels_dict[list(labels_dict.keys())[0]].shape[1])\n",
    "\n",
    "    results['test_performance'] = {}\n",
    "    \n",
    "    # Process each item in the inputs and labels dictionaries\n",
    "    for key in inputs_dict.keys():\n",
    "        input_tensor = torch.from_numpy(inputs_dict[key].astype('float32'))\n",
    "        \n",
    "        # Get the corresponding label - if it's a slice name, extract the original movie name\n",
    "        if key in labels_dict:\n",
    "            label_key = key\n",
    "        else:\n",
    "            # Extract the movie name from the key (assumed to be after the last underscore)\n",
    "            # For keys like \"slice_0_Payload\", this will extract \"Payload\"\n",
    "            if '_' in key:\n",
    "                extracted_movie = key.split('_')[-1]\n",
    "                if extracted_movie in labels_dict:\n",
    "                    label_key = extracted_movie\n",
    "                    print(f\"Input key '{key}' not found in labels. Extracted and using '{label_key}' for labels.\")\n",
    "                else:\n",
    "                    # If extracted name not found, use first available label\n",
    "                    label_key = list(labels_dict.keys())[0]\n",
    "                    print(f\"Input key '{key}' and extracted movie '{extracted_movie}' not found in labels. Using '{label_key}' for labels.\")\n",
    "            else:\n",
    "                # If no underscore in key, use first available label\n",
    "                label_key = list(labels_dict.keys())[0]\n",
    "                print(f\"Input key '{key}' not found in labels and no movie name could be extracted. Using '{label_key}' for labels.\")\n",
    "        \n",
    "        label_tensor = torch.from_numpy(labels_dict[label_key].astype('float32'))\n",
    "\n",
    "        # Debug info about tensors but without using print_dict_tree\n",
    "        print(f\"input_tensor shape: {input_tensor.shape}, dtype: {input_tensor.dtype}\")\n",
    "        print(f\"label_tensor shape: {label_tensor.shape}, dtype: {label_tensor.dtype}\")\n",
    "        \n",
    "        test_set = torch.utils.data.TensorDataset(input_tensor, label_tensor)\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test_set,\n",
    "            batch_size=16,\n",
    "            shuffle=False,\n",
    "            pin_memory=torch.cuda.is_available(),\n",
    "            num_workers=4\n",
    "        )\n",
    "\n",
    "        model_outputs, decoder_outputs, total_losses = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for input, label in test_loader:\n",
    "                input, label = input.to(device), label.to(device)\n",
    "            \n",
    "                decoder_output = None\n",
    "                if model_to_test == 'encoder_decoder':\n",
    "                    model_output, decoder_output = model(input.float())\n",
    "                elif pretrained_decoder:\n",
    "                    model_output = model(input.float()).to(device)\n",
    "                    decoder_output = decoder(model_output.float())\n",
    "                else:\n",
    "                    model_output = model(input.float())\n",
    "                        \n",
    "                model_outputs.append(model_output.detach().cpu())\n",
    "                if decoder_output is not None:\n",
    "                    decoder_outputs.append(decoder_output.detach().cpu())\n",
    "            \n",
    "                # Apply the appropriate criterion based on the presence of decoder outputs\n",
    "                if model_to_test == 'decoder':\n",
    "                    *loss_metrics, total_loss, metrics_names = criterion(model_output, label[..., 15])          #--> middle frame\n",
    "                elif decoder_output is None:\n",
    "                    *loss_metrics, total_loss, metrics_names = criterion(model_output, label)\n",
    "                else:\n",
    "                    *loss_metrics, total_loss, metrics_names = criterion(model_output, label, decoder_output, input[..., 15])\n",
    "                \n",
    "                total_losses.append(total_loss.item())\n",
    "\n",
    "        # Store the outputs in results\n",
    "        if model_to_test != 'encoder_decoder' and pretrained_decoder is None:\n",
    "            results[model_to_test + '_predictions'][key] = torch.cat(model_outputs, dim=0).numpy()\n",
    "        else:\n",
    "            results['encoder_predictions'][key] = torch.cat(model_outputs, dim=0).numpy()\n",
    "            results['decoder_predictions'][key] = torch.cat(decoder_outputs, dim=0).numpy()\n",
    "        \n",
    "        results['total_losses'][key] = np.asarray(total_losses)\n",
    "\n",
    "        if model_to_test != 'decoder':\n",
    "            encoded = results['encoder_predictions'][key]\n",
    "            labels = labels_dict[label_key] if key not in labels_dict else labels_dict[key]\n",
    "            plot_metrics(labels, encoded, key, plot_TR=False, performance_dict=None, \n",
    "                        display_plots=display_plots,\n",
    "                        save_plots=save_plots,\n",
    "                        save_path=f'outputs/{key}_{model_name}.png' if save_plots else None)\n",
    "\n",
    "    if model_to_test != 'decoder':\n",
    "        all_encoded = results['encoder_predictions']\n",
    "        all_labels = labels_dict\n",
    "        # Using the last processed key for display\n",
    "        results['test_performance'] = plot_metrics(labels, encoded, key, plot_TR=False, performance_dict=None, \n",
    "                        display_plots=display_plots,\n",
    "                        save_plots=save_plots,\n",
    "                        save_path=f'outputs/{key}_{model_name}.png' if save_plots else None)\n",
    "\n",
    "        if statistical_testing:\n",
    "            all_labels, all_predictions = [], []\n",
    "            for key in labels_dict.keys():\n",
    "                if key in results['encoder_predictions']:\n",
    "                    all_predictions.append(results['encoder_predictions'][key])\n",
    "                    all_labels.append(labels_dict[key])\n",
    "            all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "            all_labels = np.concatenate(all_labels, axis=0)\n",
    "            one_sample_permutation_test(all_labels, all_predictions)\n",
    "\n",
    "    if model_to_test != 'encoder' or pretrained_decoder is not None:\n",
    "        if model_to_test == 'decoder':\n",
    "            print(\"\\n\\n\\n ALRIGHT ZONES =\", zones, \"\\n\\n\\n\")\n",
    "            \n",
    "            # Check if we have baseline predictions to use\n",
    "            if baseline_predictions is not None:\n",
    "                # Use the modified plot_all_predictions7 with baseline comparison\n",
    "                results['test_performance'] = plot_all_predictions7(\n",
    "                    results['decoder_predictions'], \n",
    "                    labels_dict, \n",
    "                    results['test_performance'], \n",
    "                    display_plots,\n",
    "                    save_plots=save_plots,\n",
    "                    save_path_prefix='outputs/' if save_plots else None,\n",
    "                    model_name=model_name, \n",
    "                    metric=metric, \n",
    "                    mean_flag=mean_flag,\n",
    "                    zone_type=zones,\n",
    "                    baseline_predictions=baseline_predictions\n",
    "                )\n",
    "            else:\n",
    "                # Use the regular plot_all_predictions7 without baseline\n",
    "                if zones is None:\n",
    "                    results['test_performance'] = plot_all_predictions5(\n",
    "                        results['decoder_predictions'], \n",
    "                        labels_dict, \n",
    "                        results['test_performance'], \n",
    "                        display_plots,\n",
    "                        save_plots=save_plots,\n",
    "                        save_path_prefix='outputs/' if save_plots else None,\n",
    "                        model_name=model_name, \n",
    "                        metric=metric, \n",
    "                        mean_flag=mean_flag\n",
    "                    )\n",
    "                else:\n",
    "                    results['test_performance'] = plot_all_predictions7(\n",
    "                        results['decoder_predictions'], \n",
    "                        labels_dict, \n",
    "                        results['test_performance'], \n",
    "                        display_plots,\n",
    "                        save_plots=save_plots,\n",
    "                        save_path_prefix='outputs/' if save_plots else None,\n",
    "                        model_name=model_name, \n",
    "                        metric=metric, \n",
    "                        mean_flag=mean_flag,\n",
    "                        zone_type=zones\n",
    "                    )\n",
    "\n",
    "        else:\n",
    "            # For encoder or encoder_decoder, use inputs_dict for ground truth\n",
    "            if baseline_predictions is not None:\n",
    "                results['test_performance'] = plot_all_predictions7(\n",
    "                    results['decoder_predictions'], \n",
    "                    inputs_dict, \n",
    "                    results['test_performance'], \n",
    "                    display_plots,\n",
    "                    save_plots=save_plots,\n",
    "                    save_path_prefix='outputs/' if save_plots else None,\n",
    "                    model_name=model_name, \n",
    "                    metric=metric, \n",
    "                    baseline_predictions=baseline_predictions\n",
    "                )\n",
    "            else:\n",
    "                results['test_performance'] = plot_all_predictions5(\n",
    "                    results['decoder_predictions'], \n",
    "                    inputs_dict, \n",
    "                    results['test_performance'], \n",
    "                    display_plots,\n",
    "                    save_plots=save_plots,\n",
    "                    save_path_prefix='outputs/' if save_plots else None,\n",
    "                    model_name=model_name, \n",
    "                    metric=metric\n",
    "                )\n",
    "    print(\"using new function\")\n",
    "        \n",
    "    if model_to_test == 'encoder_decoder':\n",
    "        with torch.enable_grad():\n",
    "            for key in inputs_dict.keys():\n",
    "                predicted_fMRIs = torch.from_numpy(results['encoder_predictions'][key])\n",
    "                # Get corresponding input for ground truth\n",
    "                if key in inputs_dict:\n",
    "                    input_key = key\n",
    "                else:\n",
    "                    # Use first input if key not found\n",
    "                    input_key = list(inputs_dict.keys())[0]\n",
    "                \n",
    "                ground_truth_frames = torch.from_numpy(inputs_dict[input_key][..., 15])\n",
    "                for i in range(predicted_fMRIs.shape[0]):\n",
    "                    decoder_saliency += compute_saliency(model.decoder, predicted_fMRIs[i:i+1], ground_truth_frames[i:i+1], device)\n",
    "\n",
    "        if display_plots:\n",
    "            plot_saliency_distribution(decoder_saliency)\n",
    "        results['decoder_saliency'] = decoder_saliency\n",
    "\n",
    "    print(\"Testing completed. Total time: {:.2f} minutes\".format((time.time() - tic) / 60))\n",
    "    print('---')\n",
    "    return results\n",
    "\n",
    "def visualize_blocks_3(data_3d, blocks, losses, num_blocks=(3, 3, 3), figsize=None, colormap='viridis', \n",
    "                   title_prefix=\"Brain Divided into\", is_difference=False):\n",
    "    \"\"\"\n",
    "    Visualize brain blocks using maximum intensity projection for each z-layer\n",
    "    Shows axial views for each layer along the z-dimension and displays loss values or differences\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_3d : numpy.ndarray\n",
    "        3D brain data\n",
    "    blocks : dict\n",
    "        Dictionary mapping block IDs to block boundaries\n",
    "    losses : array-like\n",
    "        Array of loss values or difference values, one per block (index 0 corresponds to block 1)\n",
    "    num_blocks : tuple\n",
    "        Number of blocks along each dimension (x, y, z)\n",
    "    figsize : tuple, optional\n",
    "        Figure size, if None will be calculated based on z-dimension blocks\n",
    "    colormap : str\n",
    "        Matplotlib colormap name to use for loss values\n",
    "        'viridis' good for absolute values, 'coolwarm' good for differences\n",
    "    title_prefix : str\n",
    "        Prefix for the figure title\n",
    "    is_difference : bool\n",
    "        If True, values are treated as differences from baseline\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as patches\n",
    "    import matplotlib.colors as colors\n",
    "    \n",
    "    # Unpack the number of blocks in each dimension\n",
    "    nx, ny, nz = num_blocks\n",
    "    \n",
    "    # Convert losses to numpy array if it isn't already\n",
    "    losses = np.array(losses)\n",
    "    \n",
    "    # Print the actual loss values for debugging\n",
    "    print(\"Loss/difference values for each block:\")\n",
    "    for i, val in enumerate(losses):\n",
    "        print(f\"  Block {i+1}: {val:.5f}\")\n",
    "    \n",
    "    # Verify number of loss values matches number of blocks\n",
    "    total_blocks = nx * ny * nz\n",
    "    if len(losses) != total_blocks:\n",
    "        raise ValueError(f\"Expected {total_blocks} loss values, but got {len(losses)}\")\n",
    "    \n",
    "    # Find the block with the highest absolute loss/difference\n",
    "    max_abs_loss_idx = np.argmax(np.abs(losses))\n",
    "    # Convert to 1-based indexing for block ID\n",
    "    selected_block = max_abs_loss_idx + 1\n",
    "    max_abs_loss_value = losses[max_abs_loss_idx]\n",
    "    \n",
    "    if is_difference:\n",
    "        print(f\"Block {selected_block} has the highest absolute difference from baseline: {max_abs_loss_value:.5f}\")\n",
    "    else:\n",
    "        print(f\"Block {selected_block} has the highest absolute loss: {max_abs_loss_value:.5f}\")\n",
    "    \n",
    "    # If figsize is not specified, calculate it based on number of z layers\n",
    "    if figsize is None:\n",
    "        figsize = (6 * nz, 6)\n",
    "    \n",
    "    # Create the figure with the appropriate number of subplots (one per z-layer)\n",
    "    fig, axes = plt.subplots(1, nz, figsize=figsize)\n",
    "    if nz == 1:\n",
    "        axes = [axes]  # Make sure axes is always a list for consistency\n",
    "    \n",
    "    title_text = f\"{title_prefix} {nx}x{ny}x{nz} Blocks\"\n",
    "    if is_difference:\n",
    "        title_text += \" with Differences from Baseline\"\n",
    "    else:\n",
    "        title_text += \" with Loss Values\"\n",
    "        \n",
    "    fig.suptitle(title_text, fontsize=16)\n",
    "    \n",
    "    # Get block division boundaries\n",
    "    x_divisions = []\n",
    "    y_divisions = []\n",
    "    z_divisions = []\n",
    "    \n",
    "    for block_id, ((x_min, x_max), (y_min, y_max), (z_min, z_max)) in blocks.items():\n",
    "        x_divisions.extend([x_min, x_max])\n",
    "        y_divisions.extend([y_min, y_max])\n",
    "        z_divisions.extend([z_min, z_max])\n",
    "    \n",
    "    # Get unique boundary values\n",
    "    x_divisions = sorted(list(set(x_divisions)))\n",
    "    y_divisions = sorted(list(set(y_divisions)))\n",
    "    z_divisions = sorted(list(set(z_divisions)))\n",
    "    \n",
    "    # Print the division boundaries\n",
    "    print(\"X divisions:\", x_divisions)\n",
    "    print(\"Y divisions:\", y_divisions)\n",
    "    print(\"Z divisions:\", z_divisions)\n",
    "    \n",
    "    # Create a colormap normalization based on min/max loss values\n",
    "    if is_difference and colormap == 'coolwarm':\n",
    "        # For differences, we want a symmetric colormap centered at zero\n",
    "        max_abs = max(abs(np.min(losses)), abs(np.max(losses)))\n",
    "        norm = colors.Normalize(vmin=-max_abs, vmax=max_abs)\n",
    "    else:\n",
    "        # For absolute values or when not specifically using coolwarm for differences\n",
    "        norm = colors.Normalize(vmin=np.min(losses), vmax=np.max(losses))\n",
    "        \n",
    "    cmap = plt.cm.get_cmap(colormap)\n",
    "    \n",
    "    # Process each z-layer\n",
    "    for z_idx in range(nz):\n",
    "        # Get z-boundaries for this layer\n",
    "        z_min = z_divisions[z_idx]\n",
    "        z_max = z_divisions[z_idx + 1]\n",
    "        \n",
    "        # Create layer name with actual z-range\n",
    "        layer_name = f\"Layer {z_idx} (z={z_min}-{z_max-1})\"\n",
    "        \n",
    "        # Extract the data for this z-layer\n",
    "        layer_data = data_3d[:, :, z_min:z_max]\n",
    "        \n",
    "        # Create maximum intensity projection along z-axis for just this layer\n",
    "        layer_projection = np.max(layer_data > 0, axis=2).astype(float)\n",
    "        print(f\"Max layer_projection for layer {z_idx}=\", np.max(layer_projection))\n",
    "        \n",
    "        # Create a brain mask - identifies where brain tissue exists\n",
    "        brain_mask = layer_projection > 0\n",
    "        \n",
    "        # Plot black background\n",
    "        axes[z_idx].imshow(np.zeros_like(layer_projection), cmap='gray', origin='lower')\n",
    "        axes[z_idx].set_title(layer_name)\n",
    "        \n",
    "        # Add colored blocks and loss values for this layer\n",
    "        for y_idx in range(ny):\n",
    "            for x_idx in range(nx):\n",
    "                # Calculate block ID (1-based index) using the formula:\n",
    "                # block_id = 1 + x_idx + y_idx * nx + z_idx * nx * ny\n",
    "                block_id = 1 + x_idx + y_idx * nx + z_idx * nx * ny\n",
    "                \n",
    "                # Get loss value for this block (subtract 1 for 0-based indexing)\n",
    "                if block_id <= len(losses):\n",
    "                    loss_value = losses[block_id - 1]\n",
    "                else:\n",
    "                    print(f\"Warning: Block ID {block_id} exceeds losses array length {len(losses)}\")\n",
    "                    loss_value = 0\n",
    "                \n",
    "                # Get x, y boundaries for this block\n",
    "                x_min, x_max = x_divisions[x_idx], x_divisions[x_idx + 1]\n",
    "                y_min, y_max = y_divisions[y_idx], y_divisions[y_idx + 1]\n",
    "                \n",
    "                # Calculate center of block in data coordinates\n",
    "                x_center = (x_min + x_max) / 2\n",
    "                y_center = (y_min + y_max) / 2\n",
    "                \n",
    "                # Get color from colormap based on loss value\n",
    "                block_color = cmap(norm(loss_value))\n",
    "                \n",
    "                # Create a mask for this block\n",
    "                block_mask = np.zeros_like(layer_projection, dtype=bool)\n",
    "                block_mask[x_min:x_max, y_min:y_max] = True\n",
    "                \n",
    "                # Combine with brain mask to only color brain regions\n",
    "                block_brain_mask = block_mask & brain_mask\n",
    "                \n",
    "                # If there are brain voxels in this block, add the colored overlay\n",
    "                if np.any(block_brain_mask):\n",
    "                    # Create a colored overlay image for this block\n",
    "                    colored_overlay = np.zeros((*layer_projection.shape, 4))  # RGBA\n",
    "                    colored_overlay[block_brain_mask, :] = block_color\n",
    "                    \n",
    "                    # Add the colored overlay to the plot\n",
    "                    axes[z_idx].imshow(colored_overlay, origin='lower', interpolation='nearest')\n",
    "                \n",
    "                # Format the displayed value\n",
    "                if is_difference:\n",
    "                    # For differences, show sign and format based on magnitude\n",
    "                    if abs(loss_value) >= 0.01:\n",
    "                        value_str = f\"{loss_value:.4f}\"\n",
    "                    else:\n",
    "                        value_str = f\"{loss_value:.2e}\"\n",
    "                else:\n",
    "                    # For absolute values\n",
    "                    value_str = f\"{loss_value:.4f}\"\n",
    "                \n",
    "                # Add block ID and loss value label with a bounding box\n",
    "                text_box = dict(facecolor='black', alpha=0.7, boxstyle='round')\n",
    "                \n",
    "                # Place the text in the center of the block\n",
    "                axes[z_idx].text(y_center, x_center, f\"{block_id}\\n{value_str}\", \n",
    "                               ha=\"center\", va=\"center\", color='white', fontweight='bold',\n",
    "                               fontsize=10, bbox=text_box)\n",
    "                \n",
    "                # Highlight the block with the highest absolute loss/difference\n",
    "                if block_id == selected_block:\n",
    "                    highlight_rect = patches.Rectangle(\n",
    "                        (y_min, x_min), y_max-y_min, x_max-x_min,\n",
    "                        fill=False, edgecolor='red', linewidth=2\n",
    "                    )\n",
    "                    axes[z_idx].add_patch(highlight_rect)\n",
    "    \n",
    "    # Add a colorbar to show the mapping between loss values and colors\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    \n",
    "    # Create a separate axis for the colorbar below the brain images\n",
    "    cax = fig.add_axes([0.15, 0.05, 0.7, 0.02])  # [left, bottom, width, height]\n",
    "    cbar = fig.colorbar(sm, cax=cax, orientation='horizontal')\n",
    "    \n",
    "    if is_difference:\n",
    "        cbar.set_label('Difference from Baseline')\n",
    "    else:\n",
    "        cbar.set_label('Loss Value')\n",
    "    \n",
    "    # Adjust layout to make room for colorbar\n",
    "    plt.tight_layout(rect=[0, 0.1, 1, 0.95])\n",
    "    plt.show()\n",
    "    \n",
    "    # Save figure if requested\n",
    "    if hasattr(plt, 'savefig'):\n",
    "        suffix = \"differences\" if is_difference else \"losses\"\n",
    "        plt.savefig(f'brain_blocks_{nx}x{ny}x{nz}_{suffix}_colormap.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return blocks\n",
    "\n",
    "\n",
    "\n",
    "def calculate_baseline_losses(model_name='decoder_4609_350', test_input=None, test_label=None, \n",
    "                           all_frames=True, save_plots=False, metric=\"tv\", zones=4):\n",
    "    \"\"\"\n",
    "    Calculate baseline reconstruction losses without any perturbation\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_name : str\n",
    "        Name of the model file to be used\n",
    "    test_input : dict\n",
    "        Dictionary with fMRIs for testing\n",
    "    test_label : dict\n",
    "        Dictionary with films\n",
    "    all_frames : bool\n",
    "        If True, runs test_model_all, otherwise runs test_model\n",
    "    save_plots : bool\n",
    "        If True, saves plots\n",
    "    metric : str\n",
    "        Metric to use for evaluation: \"ssim\" or \"tv\" (Total Variation)\n",
    "    zones : str or int\n",
    "        Zone configuration for analysis\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with baseline losses for each zone\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    print(\"Calculating baseline losses with no perturbation\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = Decoder(mask_size)\n",
    "    state_dict = torch.load(model_name)\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    # Testing parameters\n",
    "    criterion = D_Loss()\n",
    "    device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "    pretrained_decoder = None\n",
    "    model_to_test = 'decoder'\n",
    "    statistical_testing = False\n",
    "    display_plots = True\n",
    "    \n",
    "    # Run test_model_all without perturbation to get baseline performance\n",
    "    if all_frames:\n",
    "        baseline_results = test_model_all(\n",
    "            test_input, \n",
    "            test_label, \n",
    "            model, \n",
    "            criterion, \n",
    "            device, \n",
    "            pretrained_decoder, \n",
    "            model_to_test, \n",
    "            statistical_testing, \n",
    "            display_plots, \n",
    "            save_plots, \n",
    "            model_name=model_name + '_baseline', \n",
    "            metric=metric, \n",
    "            mean_flag=False,\n",
    "            zones=zones\n",
    "        )\n",
    "        print(\"Baseline test completed\")\n",
    "        return baseline_results['test_performance']\n",
    "    else:\n",
    "        test_model(\n",
    "            test_input, \n",
    "            test_label, \n",
    "            model, \n",
    "            criterion, \n",
    "            device, \n",
    "            pretrained_decoder, \n",
    "            model_to_test, \n",
    "            statistical_testing, \n",
    "            display_plots, \n",
    "            save_plots, \n",
    "            model_name=model_name + '_baseline'\n",
    "        )\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "def test_new_decoder(real=True, model_name='decoder_4609_1650', test_on_train=False, test_input=testset['fMRIs'], \n",
    "                     test_label=testset['videos'], add_name='', regions=[], block_id=None, save_plots=False, all_frames=False,\n",
    "                     change_mode='off', num_blocks=None, metric=\"ssim\", zones=None, compare_to_baseline=True):\n",
    "    '''\n",
    "    Tests the decoder with brain block analysis\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    real : bool\n",
    "        If True, tests on real brain activity; if False, tests on brain activity from encoder\n",
    "    model_name : str\n",
    "        Name of the model file to be used\n",
    "    test_on_train : bool\n",
    "        If True, tests on the training set\n",
    "    test_input : dict\n",
    "        Dictionary with fMRIs for testing (one subdictionary for each film)\n",
    "    test_label : dict\n",
    "        Dictionary with films (one subdictionary for each film)\n",
    "    add_name : str\n",
    "        String to add to the end of output name to avoid overwriting\n",
    "    regions : list\n",
    "        List of region IDs to turn off (legacy parameter, use block_id instead)\n",
    "    block_id : int\n",
    "        ID of the 3D block to turn off (1-27)\n",
    "    save_plots : bool\n",
    "        If True, saves plots\n",
    "    all_frames : bool\n",
    "        If True, runs test_model_all, otherwise runs test_model\n",
    "    change_mode : str\n",
    "        'off' or 'amplify'\n",
    "    zones (str or int, optional): Zones to consider for testing. Default is \"quadrants\", can also be \"center_bg\".\n",
    "                                  If it is an integer, the function will analyze a number of zones = that integer squared.\n",
    "                                  For example, if zones = 4, the function will analyze 16 zones (4x4).\n",
    "    compare_to_baseline : bool\n",
    "        If True, compute baseline performance without perturbation and report differences\n",
    "\n",
    "    '''\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as patches\n",
    "    import pickle\n",
    "    import os\n",
    "\n",
    "    print(\"zones = \", zones, \"\\n\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = Decoder(mask_size)\n",
    "    state_dict = torch.load(model_name)\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    # Testing parameters\n",
    "    criterion = D_Loss()\n",
    "    device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "    pretrained_decoder = None\n",
    "    model_to_test = 'decoder'\n",
    "    statistical_testing = False\n",
    "    display_plots = True\n",
    "    \n",
    "    # Handle special case for training data\n",
    "    if test_on_train:\n",
    "        num_samples = trainset[\"fMRIs\"].shape[0]\n",
    "        random_indices = np.random.choice(num_samples, size=30, replace=False)\n",
    "        testset2 = {\n",
    "            \"fMRIs\": {\n",
    "                \"test\": trainset[\"fMRIs\"][random_indices]\n",
    "            },\n",
    "            \"videos\": {\n",
    "                \"test\": trainset[\"videos\"][random_indices]\n",
    "            }\n",
    "        }\n",
    "        test_input = testset2['fMRIs']\n",
    "        test_label = testset2['videos']\n",
    "    \n",
    "    # Check if we're using a brain block\n",
    "    if num_blocks is not None:\n",
    "        # First, compute the baseline performance if requested\n",
    "        baseline_performance = None\n",
    "        if compare_to_baseline:\n",
    "            print(\"Computing baseline performance with no perturbation...\")\n",
    "            if all_frames:\n",
    "                baseline_results = test_model_all(\n",
    "                    test_input, \n",
    "                    test_label, \n",
    "                    model, \n",
    "                    criterion, \n",
    "                    device, \n",
    "                    pretrained_decoder, \n",
    "                    model_to_test, \n",
    "                    statistical_testing, \n",
    "                    display_plots, \n",
    "                    save_plots, \n",
    "                    model_name=model_name + '_baseline', \n",
    "                    metric=metric,\n",
    "                    mean_flag=False,\n",
    "                    zones=zones\n",
    "                )\n",
    "                baseline_performance = baseline_results['test_performance']\n",
    "                \n",
    "                # Save baseline performance\n",
    "                baseline_file = f'baseline_{model_name}_{metric}_zones{zones}.pkl'\n",
    "                with open(baseline_file, 'wb') as f:\n",
    "                    pickle.dump(baseline_performance, f)\n",
    "                print(f\"Baseline performance saved to {baseline_file}\")\n",
    "                \n",
    "                print(\"Baseline performance:\")\n",
    "                for k, v in baseline_performance.items():\n",
    "                    if isinstance(v, (int, float)):\n",
    "                        print(f\"  {k}: {v:.5f}\")\n",
    "            else:\n",
    "                # For now, assume baseline is not needed for non-all_frames mode\n",
    "                pass\n",
    "                \n",
    "        # Load the 3D brain data\n",
    "        regions_3d = load_and_reshape_data('region_ids_4609+.npy')\n",
    "\n",
    "        # Cut to the tightest rectangular prism around the brain\n",
    "        (x_min, x_max), (y_min, y_max), (z_min, z_max) = find_bounds(regions_3d)\n",
    "        brain_data = regions_3d[x_min:x_max+1, y_min:y_max+1, z_min:z_max+1]\n",
    "        print(f\"Original shape: {regions_3d.shape}, Brain shape: {brain_data.shape}\")\n",
    "\n",
    "        # Divide into blocks\n",
    "        blocks = divide_brain_into_blocks(brain_data, num_blocks)\n",
    "        \n",
    "        # Flatten the mask\n",
    "        mask4609 = np.load('mask_schaefer1000_4609.npy')\n",
    "        flat_mask = mask4609.flatten()\n",
    "\n",
    "        if block_id is not None:  # If some block is specified\n",
    "            for video_name in test_input.keys():\n",
    "                print(f\"Turning off block {block_id} for video {video_name}\")\n",
    "\n",
    "                visualize_blocks(brain_data, blocks, num_blocks=num_blocks, selected_block=block_id)\n",
    "                \n",
    "                # Use the existing turn_off_regions function for the regions in this block\n",
    "                if change_mode == 'off':\n",
    "                    modified_data = turn_off_block_new(test_input[video_name], flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "                else:\n",
    "                    modified_data = turn_off_block_new(test_input[video_name], flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "                \n",
    "                modified_input[video_name] = modified_data\n",
    "                \n",
    "            # Use the modified input for testing\n",
    "            test_input = modified_input\n",
    "\n",
    "            if all_frames:\n",
    "                results = test_model_all(\n",
    "                    test_input, \n",
    "                    test_label, \n",
    "                    model, \n",
    "                    criterion, \n",
    "                    device, \n",
    "                    pretrained_decoder, \n",
    "                    model_to_test, \n",
    "                    statistical_testing, \n",
    "                    display_plots, \n",
    "                    save_plots, \n",
    "                    model_name=model_name + add_name, \n",
    "                    metric=metric\n",
    "                )\n",
    "                \n",
    "                # Compare with baseline if available\n",
    "                if baseline_performance is not None:\n",
    "                    print(\"\\nComparison with baseline:\")\n",
    "                    block_performance = results['test_performance']\n",
    "                    \n",
    "                    # Get the main metric based on metric type\n",
    "                    main_metric_key = f'mean_{metric}_D'\n",
    "                    if main_metric_key in baseline_performance and main_metric_key in block_performance:\n",
    "                        baseline_val = baseline_performance[main_metric_key]\n",
    "                        block_val = block_performance[main_metric_key]\n",
    "                        diff = block_val - baseline_val\n",
    "                        \n",
    "                        print(f\"  {main_metric_key}: {block_val:.5f} (baseline: {baseline_val:.5f}, diff: {diff:.5f})\")\n",
    "                    \n",
    "                    # Compare zone-specific metrics\n",
    "                    for k in baseline_performance.keys():\n",
    "                        if k.startswith('mean_') and k != main_metric_key and k in block_performance:\n",
    "                            baseline_val = baseline_performance[k]\n",
    "                            block_val = block_performance[k]\n",
    "                            diff = block_val - baseline_val\n",
    "                            print(f\"  {k}: {block_val:.5f} (baseline: {baseline_val:.5f}, diff: {diff:.5f})\")\n",
    "                            \n",
    "                return results\n",
    "            else:\n",
    "                test_model(\n",
    "                    test_input, \n",
    "                    test_label, \n",
    "                    model, \n",
    "                    criterion, \n",
    "                    device, \n",
    "                    pretrained_decoder, \n",
    "                    model_to_test, \n",
    "                    statistical_testing, \n",
    "                    display_plots, \n",
    "                    save_plots, \n",
    "                    model_name=model_name + add_name\n",
    "                )\n",
    "                return None\n",
    "\n",
    "        elif block_id is None:  # Loop through all blocks\n",
    "            losses = []\n",
    "            loss_diffs = []  # Store differences from baseline\n",
    "            \n",
    "            # Create a dictionary to store detailed results for each block\n",
    "            block_results = {}\n",
    "            \n",
    "            # Get baseline metric key based on metric type\n",
    "            main_metric_key = f'mean_{metric}_D'\n",
    "            \n",
    "            # Loop through all blocks\n",
    "            for block_id in range(1, num_blocks[0] * num_blocks[1] * num_blocks[2] + 1):\n",
    "                print(f\"\\nProcessing block {block_id}...\")\n",
    "                modified_input = {}\n",
    "                \n",
    "                for video_name in test_input.keys():\n",
    "                    # Turn off this block in the input data\n",
    "                    if change_mode == 'off':\n",
    "                        ffa_mask = np.load('enhanced_union_FFA.npy')\n",
    "                        brain_mask = np.load('mask_schaefer1000_4609.npy')\n",
    "\n",
    "                        # Find which voxels to zero out (intersection of brain mask and FFA mask)\n",
    "                        intersection = (brain_mask > 0) & (ffa_mask > 0)\n",
    "                        brain_indices = np.where(brain_mask.flatten())[0]\n",
    "                        ffa_indices = np.where(intersection.flatten())[0]\n",
    "                        voxels_to_zero = np.where(np.isin(brain_indices, ffa_indices))[0]\n",
    "\n",
    "                        # Create modified data\n",
    "                        modified_data = test_input[video_name].copy()\n",
    "                        print(\"\\n\\nmodified_data shape =\", modified_data.shape, \"\\n\\n\")\n",
    "                        modified_data[:, voxels_to_zero] = 0\n",
    "#                    modified_data = turn_off_block_new(test_input[video_name], flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "\n",
    "#                        modified_data = turn_off_block_new(test_input[video_name], flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "                    else:\n",
    "                        ffa_mask = np.load('enhanced_union_FFA.npy')\n",
    "                        brain_mask = np.load('mask_schaefer1000_4609.npy')\n",
    "\n",
    "                        # Find which voxels to zero out (intersection of brain mask and FFA mask)\n",
    "                        intersection = (brain_mask > 0) & (ffa_mask > 0)\n",
    "                        brain_indices = np.where(brain_mask.flatten())[0]\n",
    "                        ffa_indices = np.where(intersection.flatten())[0]\n",
    "                        voxels_to_zero = np.where(np.isin(brain_indices, ffa_indices))[0]\n",
    "\n",
    "                        # Create modified data\n",
    "                        modified_data = test_input[video_name].copy()\n",
    "                        print(\"\\n\\nmodified_data shape =\", modified_data.shape, \"\\n\\n\")\n",
    "                        modified_data[:, voxels_to_zero] = 0\n",
    "#                    modified_data = turn_off_block_new(test_input[video_name], flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "\n",
    "#                        modified_data = turn_off_block_new(test_input[video_name], flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "                    \n",
    "                    modified_input[video_name] = modified_data\n",
    "                    \n",
    "                # Test with this block turned off\n",
    "                if all_frames:\n",
    "                    results = test_model_all(\n",
    "                        modified_input, \n",
    "                        test_label, \n",
    "                        model, \n",
    "                        criterion, \n",
    "                        device, \n",
    "                        pretrained_decoder, \n",
    "                        model_to_test, \n",
    "                        statistical_testing, \n",
    "                        display_plots, \n",
    "                        save_plots, \n",
    "                        model_name=model_name + f'_block_{block_id}', \n",
    "                        metric=metric, \n",
    "                        mean_flag=False,  # Return full performance dict \n",
    "                        zones=zones\n",
    "                    )\n",
    "                    \n",
    "                    # Store the block's performance\n",
    "                    block_performance = results['test_performance']\n",
    "                    block_results[block_id] = block_performance\n",
    "                    \n",
    "                    # Get the main loss value\n",
    "                    if metric == \"tv\":\n",
    "                        mean_loss = block_performance.get(main_metric_key, 0)\n",
    "                    elif metric == \"ssim\":\n",
    "                        mean_loss = block_performance.get(main_metric_key, 0)\n",
    "                    \n",
    "                    print(f\"Block {block_id}, mean loss = {mean_loss:.5f}\")\n",
    "                    losses.append(mean_loss)\n",
    "                    \n",
    "                    # Calculate difference from baseline if available\n",
    "                    if baseline_performance is not None and main_metric_key in baseline_performance:\n",
    "                        baseline_val = baseline_performance[main_metric_key]\n",
    "                        diff = mean_loss - baseline_val\n",
    "                        loss_diffs.append(diff)\n",
    "                        print(f\"  Difference from baseline: {diff:.5f}\")\n",
    "                    else:\n",
    "                        loss_diffs.append(0)  # Default if baseline not available\n",
    "                    \n",
    "                else:\n",
    "                    test_model(\n",
    "                        modified_input, \n",
    "                        test_label, \n",
    "                        model, \n",
    "                        criterion, \n",
    "                        device, \n",
    "                        pretrained_decoder, \n",
    "                        model_to_test, \n",
    "                        statistical_testing, \n",
    "                        display_plots, \n",
    "                        save_plots, \n",
    "                        model_name=model_name + f'_block_{block_id}'\n",
    "                    )\n",
    "            \n",
    "            # Find the block with the biggest impact\n",
    "            if compare_to_baseline and baseline_performance is not None:\n",
    "                lossiest = np.argmax(np.abs(loss_diffs))\n",
    "                impact_val = loss_diffs[lossiest]\n",
    "            else:\n",
    "                lossiest = np.argmax(losses)\n",
    "                impact_val = losses[lossiest]\n",
    "                \n",
    "            lossiest_block = lossiest + 1  # Convert to 1-based indexing\n",
    "            print(f\"\\nBlock with the biggest impact: {lossiest_block} (value: {impact_val:.5f})\")\n",
    "                \n",
    "            # Visualize with appropriate values\n",
    "            if compare_to_baseline and baseline_performance is not None:\n",
    "                print(\"Visualizing differences from baseline...\")\n",
    "                visualize_blocks_3(\n",
    "                    brain_data,\n",
    "                    blocks,\n",
    "                    loss_diffs,  # Use differences from baseline\n",
    "                    num_blocks=num_blocks,\n",
    "                    colormap='coolwarm'  # Better for showing positive/negative differences\n",
    "                )\n",
    "            else:\n",
    "                print(\"Visualizing absolute loss values...\")\n",
    "                visualize_blocks_3(\n",
    "                    brain_data,\n",
    "                    blocks,\n",
    "                    losses,\n",
    "                    num_blocks=num_blocks,\n",
    "                    colormap='viridis'  # For absolute values\n",
    "                )\n",
    "            \n",
    "            # Save results\n",
    "            results_data = {\n",
    "                'losses': losses,\n",
    "                'baseline_performance': baseline_performance,\n",
    "                'loss_differences': loss_diffs if baseline_performance is not None else None,\n",
    "                'block_with_biggest_impact': lossiest_block,\n",
    "                'block_results': block_results\n",
    "            }\n",
    "            \n",
    "            results_file = f'block_analysis_{model_name}_{metric}_zones{zones}.pkl'\n",
    "            with open(results_file, 'wb') as f:\n",
    "                pickle.dump(results_data, f)\n",
    "            print(f\"Results saved to {results_file}\")\n",
    "            \n",
    "            return results_data\n",
    "\n",
    "    # Original code for regions list\n",
    "    elif regions:\n",
    "        # Specific regions case\n",
    "        fmri_regions_off = test_input.copy()\n",
    "        \n",
    "        for video_name in test_input.keys():\n",
    "            fmri_regions_off[video_name] = turn_off_regions(test_input[video_name], regions)\n",
    "            \n",
    "        test_input = fmri_regions_off\n",
    "    \n",
    "    print(\"test input shape =\", print_dict_tree(test_input))\n",
    "    print(\"test label shape =\", print_dict_tree(test_label))\n",
    "\n",
    "    # Run the appropriate test model function\n",
    "    # Do recall this code is just being used for the case we want regions, not blocks\n",
    "    if all_frames:\n",
    "        results = test_model_all(\n",
    "            test_input, \n",
    "            test_label, \n",
    "            model, \n",
    "            criterion, \n",
    "            device, \n",
    "            pretrained_decoder, \n",
    "            model_to_test, \n",
    "            statistical_testing, \n",
    "            display_plots, \n",
    "            save_plots, \n",
    "            model_name=model_name + add_name, \n",
    "            metric=metric, \n",
    "            mean_flag=True,\n",
    "            zones=zones\n",
    "        )\n",
    "        return results\n",
    "    else:\n",
    "        test_model(\n",
    "            test_input, \n",
    "            test_label, \n",
    "            model, \n",
    "            criterion, \n",
    "            device, \n",
    "            pretrained_decoder, \n",
    "            model_to_test, \n",
    "            statistical_testing, \n",
    "            display_plots, \n",
    "            save_plots, \n",
    "            model_name=model_name + add_name\n",
    "        )\n",
    "        return None\n",
    "\n",
    "'''\n",
    "def run_all_blocks_test():\n",
    "    \"\"\"\n",
    "    Run test with all blocks analysis, comparing to baseline performance\n",
    "    \"\"\"\n",
    "    # Call the test_new_decoder function with baseline comparison\n",
    "    results = test_new_decoder(\n",
    "        real=True,\n",
    "        model_name='decoder_4609_350',\n",
    "        test_input=filtered_trainset['fMRIs'],\n",
    "        test_label=filtered_trainset['videos'],\n",
    "        all_frames=True,\n",
    "        save_plots=False,\n",
    "        add_name='_block_analysis',\n",
    "        change_mode='off',\n",
    "        num_blocks=(2, 2, 2),\n",
    "        metric=\"tv\",\n",
    "        zones=4,\n",
    "        compare_to_baseline=True  # Enable baseline comparison\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Call the function to run the analysis\n",
    "results = run_all_blocks_test()\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_all_blocks_test():\n",
    "    \"\"\"\n",
    "    Run test with all blocks analysis, comparing to baseline performance\n",
    "    Shows difference in loss between perturbed and baseline reconstructions for each frame\n",
    "    \"\"\"\n",
    "    # Step 1: Calculate baseline reconstructions (no perturbation)\n",
    "    print(\"=== STEP 1: Calculating baseline reconstructions (no perturbation) ===\")\n",
    "    \n",
    "    model_name = 'decoder_4609_350'\n",
    "    test_input = filtered_trainset['fMRIs']\n",
    "    test_label = filtered_trainset['videos']\n",
    "    num_blocks = (1, 1, 2)\n",
    "    metric = \"tv\"\n",
    "    zones = 4\n",
    "    save_plots = False\n",
    "    \n",
    "    # Load the model\n",
    "    model = Decoder(mask_size)\n",
    "    state_dict = torch.load(model_name)\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    # Testing parameters\n",
    "    criterion = D_Loss()\n",
    "    device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "    pretrained_decoder = None\n",
    "    model_to_test = 'decoder'\n",
    "    statistical_testing = False\n",
    "    display_plots = True\n",
    "    \n",
    "    # Generate baseline predictions\n",
    "    baseline_results = test_model_all(\n",
    "        test_input, \n",
    "        test_label, \n",
    "        model, \n",
    "        criterion, \n",
    "        device, \n",
    "        pretrained_decoder, \n",
    "        model_to_test, \n",
    "        statistical_testing, \n",
    "        display_plots=False,  # Don't display plots for baseline\n",
    "        save_plots=False,\n",
    "        model_name=model_name + '_baseline', \n",
    "        metric=metric, \n",
    "        mean_flag=False,\n",
    "        zones=zones\n",
    "    )\n",
    "    \n",
    "    # Save baseline performance metrics and predictions\n",
    "    baseline_performance = baseline_results['test_performance']\n",
    "    baseline_predictions = baseline_results['decoder_predictions']\n",
    "    \n",
    "    print(\"Baseline performance metrics:\")\n",
    "    for k, v in baseline_performance.items():\n",
    "        if isinstance(v, (int, float)):\n",
    "            print(f\"  {k}: {v:.5f}\")\n",
    "    \n",
    "    # Step 2: Run the perturbation analysis for each block\n",
    "    print(\"\\n=== STEP 2: Running perturbation analysis for each block ===\")\n",
    "    \n",
    "    # Load 3D brain data and prepare blocks\n",
    "    regions_3d = load_and_reshape_data('region_ids_4609+.npy')\n",
    "    (x_min, x_max), (y_min, y_max), (z_min, z_max) = find_bounds(regions_3d)\n",
    "    brain_data = regions_3d[x_min:x_max+1, y_min:y_max+1, z_min:z_max+1]\n",
    "    print(f\"Original shape: {regions_3d.shape}, Brain shape: {brain_data.shape}\")\n",
    "    \n",
    "    # Divide into blocks\n",
    "    blocks = divide_brain_into_blocks(brain_data, num_blocks)\n",
    "    \n",
    "    # Prepare mask for block manipulation\n",
    "    mask4609 = np.load('mask_schaefer1000_4609.npy')\n",
    "    flat_mask = mask4609.flatten()\n",
    "    \n",
    "    # Container for results\n",
    "    block_losses = []\n",
    "    loss_differences = []\n",
    "    block_results = {}\n",
    "    \n",
    "    # Main metric key based on chosen metric\n",
    "    main_metric_key = f'mean_{metric}_D'\n",
    "    \n",
    "    # Loop through all blocks\n",
    "    total_blocks = num_blocks[0] * num_blocks[1] * num_blocks[2]\n",
    "    for block_id in range(1, total_blocks + 1):\n",
    "        print(f\"\\nProcessing block {block_id}/{total_blocks}\")\n",
    "        \n",
    "        # Create modified input with current block turned off\n",
    "        modified_input = {}\n",
    "        for video_name in test_input.keys():\n",
    "            if block_id == 1:\n",
    "                print(\"\\n\\nDOING FFA NOW\\n\\n\")\n",
    "                ffa_mask = np.load('enhanced_union_FFA.npy')\n",
    "            else:\n",
    "                print(\"\\n\\nDOING PPA NOW\\n\\n\")\n",
    "                ffa_mask = np.load('resampled_ppa.npy')\n",
    "            #modified_data = turn_off_block_new(\n",
    "            #    test_input[video_name], \n",
    "            #    flat_mask, \n",
    "            #    block_id, \n",
    "            #    blocks, \n",
    "            #    x_min, \n",
    "            #    y_min, \n",
    "            #    z_min\n",
    "            #)\n",
    "            \n",
    "            brain_mask = np.load('mask_schaefer1000_4609.npy')\n",
    "\n",
    "            # Find which voxels to zero out (intersection of brain mask and FFA mask)\n",
    "            intersection = (brain_mask > 0) & (ffa_mask > 0)\n",
    "            brain_indices = np.where(brain_mask.flatten())[0]\n",
    "            ffa_indices = np.where(intersection.flatten())[0]\n",
    "            voxels_to_zero = np.where(np.isin(brain_indices, ffa_indices))[0]\n",
    "            print(f\"Zeroing out {len(voxels_to_zero)} voxels out of 4609 total ({100*len(voxels_to_zero)/4609:.1f}%)\")\n",
    "\n",
    "            # Create modified data\n",
    "            modified_data = test_input[video_name].copy()\n",
    "            print(\"\\n\\nmodified_data shape =\", modified_data.shape, \"\\n\\n\")\n",
    "            modified_data[:, voxels_to_zero] = 0\n",
    "#                    modified_data = turn_off_block_new(test_input[video_name], flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "\n",
    "#                        modified_data = turn_off_block_new(test_input[video_name], flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "        \n",
    "            modified_input[video_name] = modified_data\n",
    "#            modified_input[video_name] = modified_data\n",
    "        \n",
    "        # Run test with this block turned off, passing baseline predictions for comparison\n",
    "        block_results = test_model_all(\n",
    "            modified_input, \n",
    "            test_label, \n",
    "            model, \n",
    "            criterion, \n",
    "            device, \n",
    "            pretrained_decoder, \n",
    "            model_to_test, \n",
    "            statistical_testing, \n",
    "            display_plots=True,  # Show plots with difference visualization\n",
    "            save_plots=save_plots, \n",
    "            model_name=model_name + f'_block_{block_id}', \n",
    "            metric=metric, \n",
    "            mean_flag=False,\n",
    "            zones=zones,\n",
    "            baseline_predictions=baseline_predictions  # Pass baseline predictions for frame-level comparison\n",
    "        )\n",
    "        \n",
    "        # Get the main metric value\n",
    "        block_performance = block_results['test_performance']\n",
    "        if main_metric_key in block_performance:\n",
    "            mean_loss = block_performance[main_metric_key]\n",
    "        else:\n",
    "            # If the key isn't found, try to find a similar key\n",
    "            metric_keys = [k for k in block_performance.keys() if metric in k.lower() and 'mean' in k.lower()]\n",
    "            mean_loss = block_performance[metric_keys[0]] if metric_keys else 0\n",
    "            \n",
    "        print(f\"Block {block_id} - Mean loss: {mean_loss:.5f}\")\n",
    "        block_losses.append(mean_loss)\n",
    "        \n",
    "        # Calculate difference from baseline\n",
    "        if main_metric_key in baseline_performance:\n",
    "            baseline_val = baseline_performance[main_metric_key]\n",
    "            diff = mean_loss - baseline_val\n",
    "            loss_differences.append(diff)\n",
    "            print(f\"  Difference from baseline: {diff:.5f}\")\n",
    "        else:\n",
    "            loss_differences.append(0)\n",
    "    \n",
    "    # Step 3: Visualize block-level results\n",
    "    print(\"\\n=== STEP 3: Visualizing block-level impact analysis ===\")\n",
    "    \n",
    "    # Find block with biggest impact\n",
    "    max_diff_idx = np.argmax(np.abs(loss_differences))\n",
    "    max_diff_block = max_diff_idx + 1\n",
    "    max_diff_value = loss_differences[max_diff_idx]\n",
    "    \n",
    "    print(f\"Block with biggest impact: {max_diff_block} (difference: {max_diff_value:.5f})\")\n",
    "    \n",
    "    # Visualize loss differences across blocks\n",
    "    visualize_blocks_3(\n",
    "        brain_data,\n",
    "        blocks,\n",
    "        loss_differences,  # Use differences from baseline\n",
    "        num_blocks=num_blocks,\n",
    "        colormap='coolwarm',  # Better for showing positive/negative differences\n",
    "        is_difference=True  # Indicate we're showing differences\n",
    "    )\n",
    "    \n",
    "    # Save all results\n",
    "    results_data = {\n",
    "        'baseline_performance': baseline_performance,\n",
    "        'block_losses': block_losses,\n",
    "        'loss_differences': loss_differences,\n",
    "        'max_impact_block': max_diff_block,\n",
    "        'max_impact_value': max_diff_value\n",
    "    }\n",
    "    \n",
    "    # Save to file\n",
    "    import pickle\n",
    "    results_file = f'block_analysis_{model_name}_{metric}_zones{zones}.pkl'\n",
    "    with open(results_file, 'wb') as f:\n",
    "        pickle.dump(results_data, f)\n",
    "    print(f\"Results saved to {results_file}\")\n",
    "    \n",
    "    return results_data\n",
    "\n",
    "# Call the function to run the analysis\n",
    "results = run_all_blocks_test()\n",
    "\n",
    "\n",
    "#i didnt include visualize blocks on this one\n",
    "def run_all_blocks_test_debug():\n",
    "    \"\"\"\n",
    "    Run test with all blocks analysis with extensive debugging\n",
    "    to find why all blocks have the same difference value\n",
    "    \"\"\"\n",
    "    # Step 1: Calculate baseline reconstructions (no perturbation)\n",
    "    print(\"=== STEP 1: Calculating baseline reconstructions (no perturbation) ===\")\n",
    "    \n",
    "    model_name = 'decoder_4609_350'\n",
    "    test_input = filtered_trainset['fMRIs']\n",
    "    test_label = filtered_trainset['videos']\n",
    "    num_blocks = (2, 2, 2)\n",
    "    metric = \"tv\"\n",
    "    zones = 4\n",
    "    save_plots = False\n",
    "    \n",
    "    # Load the model\n",
    "    model = Decoder(mask_size)\n",
    "    state_dict = torch.load(model_name)\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    # Testing parameters\n",
    "    criterion = D_Loss()\n",
    "    device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "    pretrained_decoder = None\n",
    "    model_to_test = 'decoder'\n",
    "    statistical_testing = False\n",
    "    display_plots = True\n",
    "    \n",
    "    # Generate baseline predictions\n",
    "    baseline_results = test_model_all(\n",
    "        test_input, \n",
    "        test_label, \n",
    "        model, \n",
    "        criterion, \n",
    "        device, \n",
    "        pretrained_decoder, \n",
    "        model_to_test, \n",
    "        statistical_testing, \n",
    "        display_plots=False,  # Don't display plots for baseline\n",
    "        save_plots=False,\n",
    "        model_name=model_name + '_baseline', \n",
    "        metric=metric, \n",
    "        mean_flag=False,\n",
    "        zones=zones\n",
    "    )\n",
    "    \n",
    "    # Save baseline performance metrics and predictions\n",
    "    baseline_performance = baseline_results['test_performance']\n",
    "    baseline_predictions = baseline_results['decoder_predictions']\n",
    "    \n",
    "    print(\"\\n==== DEBUG: Baseline performance metrics ====\")\n",
    "    for k, v in baseline_performance.items():\n",
    "        if isinstance(v, (int, float)):\n",
    "            print(f\"  {k}: {v}\")\n",
    "    \n",
    "    # Identify the main metric key we'll be using\n",
    "    if metric == \"tv\":\n",
    "        main_keys = [k for k in baseline_performance.keys() if 'tv' in k.lower() and 'mean' in k.lower()]\n",
    "    else:\n",
    "        main_keys = [k for k in baseline_performance.keys() if 'ssim' in k.lower() and 'mean' in k.lower()]\n",
    "    \n",
    "    print(f\"\\n==== DEBUG: Available metric keys: {main_keys} ====\")\n",
    "    \n",
    "    # Determine the main metric key to use\n",
    "    main_metric_key = f'mean_{metric}_D'\n",
    "    if main_metric_key not in baseline_performance:\n",
    "        if main_keys:\n",
    "            main_metric_key = main_keys[0]\n",
    "            print(f\"Main metric key '{main_metric_key}' not found. Using '{main_metric_key}' instead.\")\n",
    "        else:\n",
    "            print(f\"ERROR: No suitable metric keys found in baseline performance!\")\n",
    "            return None\n",
    "    \n",
    "    baseline_val = baseline_performance[main_metric_key]\n",
    "    print(f\"Using main metric key: {main_metric_key} with baseline value: {baseline_val}\")\n",
    "    \n",
    "    # Step 2: Run the perturbation analysis for each block\n",
    "    print(\"\\n=== STEP 2: Running perturbation analysis for each block ===\")\n",
    "    \n",
    "    # Load 3D brain data and prepare blocks\n",
    "    regions_3d = load_and_reshape_data('region_ids_4609+.npy')\n",
    "    (x_min, x_max), (y_min, y_max), (z_min, z_max) = find_bounds(regions_3d)\n",
    "    brain_data = regions_3d[x_min:x_max+1, y_min:y_max+1, z_min:z_max+1]\n",
    "    print(f\"Original shape: {regions_3d.shape}, Brain shape: {brain_data.shape}\")\n",
    "    \n",
    "    # Divide into blocks\n",
    "    blocks = divide_brain_into_blocks(brain_data, num_blocks)\n",
    "    \n",
    "    # Prepare mask for block manipulation\n",
    "    mask4609 = np.load('mask_schaefer1000_4609.npy')\n",
    "    flat_mask = mask4609.flatten()\n",
    "    \n",
    "    # Container for results\n",
    "    block_losses = []\n",
    "    loss_differences = []\n",
    "    block_results_dict = {}\n",
    "    \n",
    "    # Loop through a subset of blocks for debugging\n",
    "    total_blocks = num_blocks[0] * num_blocks[1] * num_blocks[2]\n",
    "    for block_id in range(1, total_blocks + 1):\n",
    "        print(f\"\\n==== PROCESSING BLOCK {block_id}/{total_blocks} ====\")\n",
    "        \n",
    "        # Create modified input with current block turned off\n",
    "        modified_input = {}\n",
    "        for video_name in test_input.keys():\n",
    "            modified_data = turn_off_block_new(\n",
    "                test_input[video_name], \n",
    "                flat_mask, \n",
    "                block_id, \n",
    "                blocks, \n",
    "                x_min, \n",
    "                y_min, \n",
    "                z_min\n",
    "            )\n",
    "            modified_input[video_name] = modified_data\n",
    "        \n",
    "        # Run test with this block turned off\n",
    "        block_results = test_model_all(\n",
    "            modified_input, \n",
    "            test_label, \n",
    "            model, \n",
    "            criterion, \n",
    "            device, \n",
    "            pretrained_decoder, \n",
    "            model_to_test, \n",
    "            statistical_testing, \n",
    "            display_plots=False,  # Don't show plots during debugging\n",
    "            save_plots=False, \n",
    "            model_name=model_name + f'_block_{block_id}', \n",
    "            metric=metric, \n",
    "            mean_flag=False,\n",
    "            zones=zones,\n",
    "            baseline_predictions=None  # Don't pass baseline during debug - we'll compute differences manually\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n==== DEBUG: Block {block_id} Results ====\")\n",
    "        block_performance = block_results['test_performance']\n",
    "        block_results_dict[block_id] = block_performance\n",
    "        \n",
    "        # Show all metrics in block performance\n",
    "        for k, v in block_performance.items():\n",
    "            if isinstance(v, (int, float)):\n",
    "                print(f\"  {k}: {v}\")\n",
    "        \n",
    "        # Calculate actual block mean loss value\n",
    "        if main_metric_key in block_performance:\n",
    "            mean_loss = block_performance[main_metric_key]\n",
    "        else:\n",
    "            print(f\"WARNING: Main metric key '{main_metric_key}' not found in block_performance!\")\n",
    "            # Try to find similar keys\n",
    "            if metric == \"tv\":\n",
    "                similar_keys = [k for k in block_performance.keys() if 'tv' in k.lower() and 'mean' in k.lower()]\n",
    "            else:\n",
    "                similar_keys = [k for k in block_performance.keys() if 'ssim' in k.lower() and 'mean' in k.lower()]\n",
    "                \n",
    "            if similar_keys:\n",
    "                mean_loss = block_performance[similar_keys[0]]\n",
    "                print(f\"Using alternative key: {similar_keys[0]}\")\n",
    "            else:\n",
    "                mean_loss = 0\n",
    "                print(\"No similar keys found! Using 0.\")\n",
    "        \n",
    "        # Manually calculate the difference\n",
    "        diff = mean_loss - baseline_val\n",
    "        \n",
    "        print(f\"BLOCK {block_id}:\")\n",
    "        print(f\"  Raw loss value: {mean_loss}\")\n",
    "        print(f\"  Baseline value: {baseline_val}\")\n",
    "        print(f\"  Difference: {diff}\")\n",
    "        \n",
    "        # Store the values\n",
    "        block_losses.append(mean_loss)\n",
    "        loss_differences.append(diff)\n",
    "    \n",
    "    # Print all the collected values\n",
    "    print(\"\\n==== FINAL DEBUG: All collected values ====\")\n",
    "    print(\"Block Losses:\")\n",
    "    for i, loss in enumerate(block_losses):\n",
    "        print(f\"  Block {i+1}: {loss}\")\n",
    "    \n",
    "    print(\"\\nDifferences from baseline:\")\n",
    "    for i, diff in enumerate(loss_differences):\n",
    "        print(f\"  Block {i+1}: {diff}\")\n",
    "    \n",
    "    # For testing, try a different approach to calculate differences\n",
    "    print(\"\\nRecalculating differences to double-check:\")\n",
    "    for i, loss in enumerate(block_losses):\n",
    "        recalc_diff = loss - baseline_val\n",
    "        print(f\"  Block {i+1}: Loss={loss}, Baseline={baseline_val}, Diff={recalc_diff}\")\n",
    "    \n",
    "    # Find block with biggest impact\n",
    "    max_diff_idx = np.argmax(np.abs(loss_differences))\n",
    "    max_diff_block = max_diff_idx + 1\n",
    "    max_diff_value = loss_differences[max_diff_idx]\n",
    "    \n",
    "    print(f\"\\nBlock with biggest impact: {max_diff_block} (difference: {max_diff_value})\")\n",
    "    \n",
    "    # Return the debug data for inspection\n",
    "    debug_data = {\n",
    "        'baseline_performance': baseline_performance,\n",
    "        'baseline_value': baseline_val,\n",
    "        'main_metric_key': main_metric_key,\n",
    "        'block_losses': block_losses,\n",
    "        'loss_differences': loss_differences,\n",
    "        'block_results': block_results_dict\n",
    "    }\n",
    "    \n",
    "    return debug_data\n",
    "\n",
    "# Run the debug function\n",
    "#debug_results = run_all_blocks_test_debug()\n",
    "\n",
    "#tag blocks with original and perturbed reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a764e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7b54c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c024f196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset structure:\n",
      "fMRIs\n",
      "  combined (shape: (12, 4609))\n",
      "videos\n",
      "  combined (shape: (12, 3, 112, 112, 32))\n",
      "Filtered dataset structure:\n",
      "fMRIs\n",
      "  combined (shape: (10, 4609))\n",
      "videos\n",
      "  combined (shape: (10, 3, 112, 112, 32))\n",
      "trainset fmris shape = (19915489,)\n",
      "trainset videos shape = (5203451904,)\n"
     ]
    }
   ],
   "source": [
    "# make dataset\n",
    "\n",
    "\n",
    "dataset_ID = 6661 # ID of a specific dataset. 6661 refer to preprocessed data with a mask of shape (4609,). 6660 refers to preprocessed data with a mask of shape (15364,)\n",
    "mask_size = 4609 # number of voxels in the preprocessed fMRI data. either 4609 or 15364\n",
    "trainset, valset, testset = get_dataset(dataset_ID, mask_size) # data are loaded into dictionaries\n",
    "\n",
    "\n",
    "def extract_frames(testset, specific_frames):\n",
    "    \"\"\"\n",
    "    Extract specific frames from testset and combine them into a single array.\n",
    "    \n",
    "    Parameters:\n",
    "    - testset: Dictionary with 'fMRIs' and 'videos' keys, each containing subdictionaries for each movie\n",
    "    - specific_frames: Dictionary mapping movie names to lists of frame indices to extract\n",
    "    \n",
    "    Returns:\n",
    "    - filtered_data: Dictionary with 'fMRIs' and 'videos' keys, each containing concatenated arrays of selected frames\n",
    "    \"\"\"\n",
    "    # Create lists to store selected frames\n",
    "    selected_fmris = []\n",
    "    selected_videos = []\n",
    "    \n",
    "    # Loop through each movie in specific_frames\n",
    "    for movie_name, frames in specific_frames.items():\n",
    "        # Check if the movie exists in testset\n",
    "        if movie_name not in testset['fMRIs'] or movie_name not in testset['videos']:\n",
    "            print(f\"Warning: {movie_name} not found in testset\")\n",
    "            continue\n",
    "        \n",
    "        # Get fMRI and video data for this movie\n",
    "        movie_fmri = testset['fMRIs'][movie_name]\n",
    "        movie_video = testset['videos'][movie_name]\n",
    "        \n",
    "        # Loop through each frame index\n",
    "        for frame in frames:\n",
    "            # Check if frame index is valid\n",
    "            if frame >= len(movie_fmri):\n",
    "                print(f\"Warning: Frame {frame} out of range for {movie_name} (max={len(movie_fmri)-1})\")\n",
    "                continue\n",
    "            \n",
    "            # Add frame to selected lists\n",
    "            selected_fmris.append(movie_fmri[frame])\n",
    "            selected_videos.append(movie_video[frame])\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    if selected_fmris:\n",
    "        fmris_array = np.array(selected_fmris)\n",
    "        videos_array = np.array(selected_videos)\n",
    "    else:\n",
    "        print(\"No valid frames found\")\n",
    "        return None\n",
    "    \n",
    "    # Create filtered dataset with all frames in a single array\n",
    "    filtered_data = {\n",
    "        'fMRIs': {'combined': fmris_array},\n",
    "        'videos': {'combined': videos_array}\n",
    "    }\n",
    "    \n",
    "    # Print the structure of the filtered dataset\n",
    "    print(\"Filtered dataset structure:\")\n",
    "    print(\"fMRIs\")\n",
    "    for movie, data in filtered_data['fMRIs'].items():\n",
    "        print(f\"  {movie} (shape: {data.shape})\")\n",
    "    print(\"videos\")\n",
    "    for movie, data in filtered_data['videos'].items():\n",
    "        print(f\"  {movie} (shape: {data.shape})\")\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def extract_frames_train(trainset, specific_frames_train):\n",
    "    \"\"\"\n",
    "    Extract specific frames from testset and combine them into a single array.\n",
    "    \n",
    "    Parameters:\n",
    "    - trainset: Dictionary with 'fMRIs' and 'videos' keys, each containing subdictionaries for each movie\n",
    "    - specific_frames: Dictionary mapping movie names to lists of frame indices to extract\n",
    "    \n",
    "    Returns:\n",
    "    - filtered_data: Dictionary with 'fMRIs' and 'videos' keys, each containing concatenated arrays of selected frames\n",
    "    \"\"\"\n",
    "    # Create lists to store selected frames\n",
    "    selected_fmris = []\n",
    "    selected_videos = []\n",
    "    \n",
    "    # Get fMRI and video data for this movie\n",
    "    movie_fmri = trainset['fMRIs']\n",
    "    movie_video = trainset['videos']\n",
    "    \n",
    "    # Loop through each frame index\n",
    "    for frame in specific_frames_train:\n",
    "        # Check if frame index is valid\n",
    "        if frame >= len(movie_fmri):\n",
    "            print(f\"Warning: Frame {frame} out of range (max={len(movie_fmri)-1})\")\n",
    "            continue\n",
    "        \n",
    "        # Add frame to selected lists\n",
    "        selected_fmris.append(movie_fmri[frame])\n",
    "        selected_videos.append(movie_video[frame])\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    if selected_fmris:\n",
    "        fmris_array = np.array(selected_fmris)\n",
    "        videos_array = np.array(selected_videos)\n",
    "    else:\n",
    "        print(\"No valid frames found\")\n",
    "        return None\n",
    "    \n",
    "    # Create filtered dataset with all frames in a single array\n",
    "    filtered_data = {\n",
    "        'fMRIs': {'combined': fmris_array},\n",
    "        'videos': {'combined': videos_array}\n",
    "    }\n",
    "    \n",
    "    # Print the structure of the filtered dataset\n",
    "    print(\"Filtered dataset structure:\")\n",
    "    print(\"fMRIs\")\n",
    "    for movie, data in filtered_data['fMRIs'].items():\n",
    "        print(f\"  {movie} (shape: {data.shape})\")\n",
    "    print(\"videos\")\n",
    "    for movie, data in filtered_data['videos'].items():\n",
    "        print(f\"  {movie} (shape: {data.shape})\")\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def extract_frames_train_new(specific_frames_train):\n",
    "    \"\"\"\n",
    "    Extract specific frames from trainset of new dataset and combine them into a single array.\n",
    "    \n",
    "    Parameters:\n",
    "    - testset: Dictionary with 'fMRIs' and 'videos' keys, each containing subdictionaries for each movie\n",
    "    - specific_frames: Dictionary mapping movie names to lists of frame indices to extract\n",
    "    \n",
    "    Returns:\n",
    "    - filtered_data: Dictionary with 'fMRIs' and 'videos' keys, each containing concatenated arrays of selected frames\n",
    "    \"\"\"\n",
    "    # Create lists to store selected frames\n",
    "    selected_fmris = []\n",
    "    selected_videos = []\n",
    "    \n",
    "    # Get fMRI and video data for this movie\n",
    "    #movie_fmri = trainset['fMRIs']\n",
    "    #movie_video = trainset['videos']\n",
    "\n",
    "    fmris = np.load('processed_data/sub-S32/train.npy')\n",
    "    videos = np.load('processed_data/videos/videos.npy')\n",
    "    \n",
    "    # Loop through each frame index\n",
    "    for frame in specific_frames_train:\n",
    "        # Check if frame index is valid\n",
    "        if frame >= len(fmris):\n",
    "            print(f\"Warning: Frame {frame} out of range (max={len(fmris)-1})\")\n",
    "            continue\n",
    "        \n",
    "        # Add frame to selected lists\n",
    "        selected_fmris.append(fmris[frame])\n",
    "        selected_videos.append(videos[frame])\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "#    if selected_fmris:\n",
    "#        fmris_array = np.array(selected_fmris)\n",
    "#        videos_array = np.array(selected_videos)\n",
    "#    else:\n",
    "#        print(\"No valid frames found\")\n",
    "#        return None\n",
    "    \n",
    "    # Create filtered dataset with all frames in a single array\n",
    "    filtered_data = {\n",
    "        'fMRIs': {'combined': selected_fmris},\n",
    "        'videos': {'combined': selected_videos}\n",
    "    }\n",
    "    \n",
    "    # Print the structure of the filtered dataset\n",
    "    print(\"Filtered dataset structure:\")\n",
    "    print(\"fMRIs\")\n",
    "    for movie, data in filtered_data['fMRIs'].items():\n",
    "        print(f\"  {movie} (shape: {len(data)})\")\n",
    "    print(\"videos\")\n",
    "    for movie, data in filtered_data['videos'].items():\n",
    "        print(f\"  {movie} (shape: {len(data)})\")\n",
    "    \n",
    "    print(filtered_data['videos'])\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "specific_frames = {\n",
    "    'AfterTheRain': [42],\n",
    "    'BetweenViewings': [111],\n",
    "    'Chatter': [21],\n",
    "    'FirstBite': [33],          #gotta change this one\n",
    "    'LessonLearned': [15, 36],\n",
    "    'Payload': [18, 30],\n",
    "    'Spaceman': [12],\n",
    "    'TearsOfSteel': [39],\n",
    "    'YouAgain': [300, 495]\n",
    "}\n",
    "\n",
    "specific_frames_train = [681, 248, 3008, 1561, 1821, 2639, 467, 3558, 2173, 2119]\n",
    "#frame 2119 from the trainset is a very nice frame with a face\n",
    "\n",
    "\n",
    "# Call the function to create the filtered dataset\n",
    "filtered_testset = extract_frames(testset, specific_frames)\n",
    "filtered_trainset = extract_frames_train(trainset, specific_frames_train)\n",
    "\n",
    "trainset2 = {}\n",
    "trainset2['fMRIs'] = np.memmap(f'encoder_dataset_{dataset_ID}/trainset/fMRIs.npy', dtype='float32', mode='r')\n",
    "trainset2['videos'] = np.memmap(f'encoder_dataset_{dataset_ID}/trainset/videos.npy', dtype='float32', mode='r')\n",
    "\n",
    "print(\"trainset fmris shape =\", trainset2['fMRIs'].shape)\n",
    "print(\"trainset videos shape =\", trainset2['videos'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77600519",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1284\u001b[0m\n\u001b[1;32m   1267\u001b[0m         test_model(\n\u001b[1;32m   1268\u001b[0m             test_input, \n\u001b[1;32m   1269\u001b[0m             test_label, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1278\u001b[0m             model_name\u001b[38;5;241m=\u001b[39mmodel_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_baseline\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1279\u001b[0m         )\n\u001b[1;32m   1280\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_new_decoder\u001b[39m(real\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder_4609_1650\u001b[39m\u001b[38;5;124m'\u001b[39m, test_on_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, test_input\u001b[38;5;241m=\u001b[39m\u001b[43mtestset\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfMRIs\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m   1285\u001b[0m                      test_label\u001b[38;5;241m=\u001b[39mtestset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideos\u001b[39m\u001b[38;5;124m'\u001b[39m], add_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regions\u001b[38;5;241m=\u001b[39m[], block_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, save_plots\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, all_frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1286\u001b[0m                      change_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m, num_blocks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssim\u001b[39m\u001b[38;5;124m\"\u001b[39m, zones\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, compare_to_baseline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1287\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;124;03m    Tests the decoder with brain block analysis\u001b[39;00m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \n\u001b[1;32m   1320\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'testset' is not defined"
     ]
    }
   ],
   "source": [
    "#tag debug\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3\"\n",
    "\n",
    "from dataset_new import *\n",
    "from models_new_2 import *\n",
    "from visualisation_new_2 import *\n",
    "from perturbation import *\n",
    "\n",
    "\n",
    "def plot_all_predictions7(predictions, videos, performance_dict=None, display_plots=True, save_plots=False, \n",
    "                 save_path_prefix=None, model_name=\"\", device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                 metric=\"ssim\", mean_flag=False, zone_type=\"quadrants\", max_frames=None, baseline_predictions=None):\n",
    "    \"\"\"\n",
    "    Display comparison plots between original videos and predictions.\n",
    "    Shows: Original image, baseline reconstruction, perturbed reconstruction, and difference heatmap.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    predictions : dict\n",
    "        Dictionary of prediction arrays (perturbed reconstructions)\n",
    "    videos : dict\n",
    "        Dictionary of ground truth video arrays\n",
    "    performance_dict : dict, optional\n",
    "        Dictionary to store performance metrics\n",
    "    display_plots : bool\n",
    "        Whether to display the plots\n",
    "    save_plots : bool\n",
    "        Whether to save the plots\n",
    "    save_path_prefix : str, optional\n",
    "        Path prefix for saving plots\n",
    "    model_name : str\n",
    "        Name of the model for saving plots\n",
    "    device : str\n",
    "        Device to use for computations\n",
    "    metric : str\n",
    "        Metric to use for evaluation: \"ssim\" or \"tv\" (Total Variation)\n",
    "    mean_flag : bool\n",
    "        Whether to return mean metrics or not\n",
    "    zone_type : str or int\n",
    "        Type of zones: \n",
    "        - \"quadrants\" for 2×2 grid\n",
    "        - \"center_bg\" for center and background\n",
    "        - integer n for n×n grid (e.g., 4 creates a 4×4 grid with 16 zones)\n",
    "    max_frames : int, optional\n",
    "        Maximum number of frames to plot. If None, all frames will be plotted.\n",
    "    baseline_predictions : dict, optional\n",
    "        Dictionary of baseline prediction arrays (without perturbation)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import torch\n",
    "    import os\n",
    "    from matplotlib.patches import Rectangle\n",
    "    from matplotlib.colors import LinearSegmentedColormap, Normalize\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    if save_plots and save_path_prefix:\n",
    "        os.makedirs(save_path_prefix, exist_ok=True)\n",
    "\n",
    "    # Debug information about inputs\n",
    "    print(\"\\n=== DEBUG INFO ===\")\n",
    "    print(f\"Predictions dictionary contains {len(predictions)} keys: {list(predictions.keys())}\")\n",
    "    print(f\"Videos dictionary contains {len(videos)} keys: {list(videos.keys())}\")\n",
    "    print(f\"Using metric: {metric}\")\n",
    "    print(f\"Baseline predictions provided: {baseline_predictions is not None}\")\n",
    "    \n",
    "    if isinstance(zone_type, int):\n",
    "        print(f\"Using {zone_type}×{zone_type} grid zones ({zone_type*zone_type} total zones)\")\n",
    "    else:\n",
    "        print(f\"Using zone type: {zone_type}\")\n",
    "    \n",
    "    # Find the overlapping keys between predictions and videos\n",
    "    common_keys = [key for key in predictions.keys() if key in videos]\n",
    "    print(f\"Common keys in both dictionaries: {common_keys}\")\n",
    "    \n",
    "    # Create key mapping between predictions and videos\n",
    "    if not common_keys and len(videos) > 0:\n",
    "        print(\"No common keys found. Trying to match prediction keys to video keys.\")\n",
    "        ref_video_key = list(videos.keys())[0]\n",
    "        print(f\"Using {ref_video_key} as reference video for all predictions\")\n",
    "        key_mapping = {pred_key: ref_video_key for pred_key in predictions.keys()}\n",
    "    else:\n",
    "        key_mapping = {}\n",
    "        for pred_key in predictions.keys():\n",
    "            if pred_key in videos:\n",
    "                key_mapping[pred_key] = pred_key\n",
    "            else:\n",
    "                matched = False\n",
    "                for video_key in videos.keys():\n",
    "                    if video_key in pred_key:\n",
    "                        key_mapping[pred_key] = video_key\n",
    "                        matched = True\n",
    "                        break\n",
    "                if not matched and len(videos) > 0:\n",
    "                    key_mapping[pred_key] = list(videos.keys())[0]\n",
    "    \n",
    "    print(f\"Key mapping from prediction keys to video keys: {key_mapping}\")\n",
    "    \n",
    "    # Helper function to split frame into zones\n",
    "    def split_into_zones(frame, zone_type=\"quadrants\", center_ratio=0.5):\n",
    "        \"\"\"\n",
    "        Split a frame into zones.\n",
    "        \"\"\"\n",
    "        if isinstance(frame, torch.Tensor):\n",
    "            C, H, W = frame.shape\n",
    "        else:\n",
    "            C, H, W = frame.shape\n",
    "            \n",
    "        zones = {}\n",
    "        \n",
    "        if zone_type == \"quadrants\":\n",
    "            # Split into 4 quadrants (2×2 grid)\n",
    "            h_mid = H // 2\n",
    "            w_mid = W // 2\n",
    "            \n",
    "            zones[\"top_left\"] = (slice(None), slice(0, h_mid), slice(0, w_mid))\n",
    "            zones[\"top_right\"] = (slice(None), slice(0, h_mid), slice(w_mid, W))\n",
    "            zones[\"bottom_left\"] = (slice(None), slice(h_mid, H), slice(0, w_mid))\n",
    "            zones[\"bottom_right\"] = (slice(None), slice(h_mid, H), slice(w_mid, W))\n",
    "            \n",
    "        elif zone_type == \"center_bg\":\n",
    "            # Split into center and background\n",
    "            h_center = int(H * center_ratio)\n",
    "            w_center = int(W * center_ratio)\n",
    "            \n",
    "            h_start = (H - h_center) // 2\n",
    "            h_end = h_start + h_center\n",
    "            w_start = (W - w_center) // 2\n",
    "            w_end = w_start + w_center\n",
    "            \n",
    "            zones[\"center\"] = (slice(None), slice(h_start, h_end), slice(w_start, w_end))\n",
    "            \n",
    "            # Background is everything except the center\n",
    "            center_mask = np.zeros((H, W), dtype=bool)\n",
    "            center_mask[h_start:h_end, w_start:w_end] = True\n",
    "            \n",
    "            zones[\"background\"] = {\"mask\": ~center_mask, \n",
    "                                   \"bounds\": (h_start, h_end, w_start, w_end)}\n",
    "            \n",
    "        elif isinstance(zone_type, int) and zone_type > 0:\n",
    "            # Create an n×n grid where n = zone_type\n",
    "            n = zone_type\n",
    "            \n",
    "            # Calculate heights of each section\n",
    "            h_sections = [i * H // n for i in range(n+1)]\n",
    "            w_sections = [i * W // n for i in range(n+1)]\n",
    "            \n",
    "            # Create zones for each grid cell\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    zone_name = f\"grid_{i}_{j}\"  # Row_Column naming\n",
    "                    zones[zone_name] = (\n",
    "                        slice(None),\n",
    "                        slice(h_sections[i], h_sections[i+1]),\n",
    "                        slice(w_sections[j], w_sections[j+1])\n",
    "                    )\n",
    "                    \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown zone type: {zone_type}\")\n",
    "            \n",
    "        return zones\n",
    "    \n",
    "    # Helper function to calculate zone metrics\n",
    "    def calculate_zone_metrics(orig_frame, pred_frame, baseline_frame=None, zones=None, metric=\"ssim\", device=device):\n",
    "        \"\"\"\n",
    "        Calculate metrics for each zone.\n",
    "        If baseline_frame is provided, calculate the difference: baseline_metrics - pred_metrics\n",
    "        \"\"\"\n",
    "        from pytorch_msssim import ssim\n",
    "        \n",
    "        # If zones not provided, calculate them\n",
    "        if zones is None:\n",
    "            zones = split_into_zones(orig_frame, zone_type=zone_type)\n",
    "        \n",
    "        zone_metrics = {}\n",
    "        \n",
    "        # Convert to torch tensors if needed\n",
    "        if not isinstance(orig_frame, torch.Tensor):\n",
    "            orig_tensor = torch.from_numpy(orig_frame).unsqueeze(0)\n",
    "        else:\n",
    "            orig_tensor = orig_frame.unsqueeze(0)\n",
    "            \n",
    "        if not isinstance(pred_frame, torch.Tensor):\n",
    "            pred_tensor = torch.from_numpy(pred_frame).unsqueeze(0)\n",
    "        else:\n",
    "            pred_tensor = pred_frame.unsqueeze(0)\n",
    "        \n",
    "        # Process baseline frame if provided    \n",
    "        if baseline_frame is not None:\n",
    "            if not isinstance(baseline_frame, torch.Tensor):\n",
    "                baseline_tensor = torch.from_numpy(baseline_frame).unsqueeze(0)\n",
    "            else:\n",
    "                baseline_tensor = baseline_frame.unsqueeze(0)\n",
    "        \n",
    "        # Calculate metrics for each zone\n",
    "        for zone_name, zone_slice in zones.items():\n",
    "            # Special handling for background in center_bg mode\n",
    "            if isinstance(zone_slice, dict):  # Background in center_bg mode\n",
    "                mask = zone_slice[\"mask\"]\n",
    "                \n",
    "                orig_zone = orig_tensor.clone()\n",
    "                pred_zone = pred_tensor.clone()\n",
    "                \n",
    "                # Apply mask to all channels\n",
    "                for c in range(orig_zone.shape[1]):  # For each channel\n",
    "                    orig_zone[0, c][~mask] = 0\n",
    "                    pred_zone[0, c][~mask] = 0\n",
    "                \n",
    "                # Calculate metric for prediction\n",
    "                if metric == \"ssim\":\n",
    "                    pred_metric = ssim(orig_zone, pred_zone, data_range=1, size_average=True).item()\n",
    "                else:\n",
    "                    # TV Loss calculation for masked region\n",
    "                    tv_loss = torch.abs(pred_zone[:,:,1:,:] - pred_zone[:,:,:-1,:]).sum() + \\\n",
    "                              torch.abs(pred_zone[:,:,:,1:] - pred_zone[:,:,:,:-1]).sum()\n",
    "                    # Normalize by number of pixels in the zone\n",
    "                    pred_metric = tv_loss.item() / mask.sum()\n",
    "                \n",
    "                # If baseline provided, calculate baseline metric and difference\n",
    "                if baseline_frame is not None:\n",
    "                    baseline_zone = baseline_tensor.clone()\n",
    "                    for c in range(baseline_zone.shape[1]):\n",
    "                        baseline_zone[0, c][~mask] = 0\n",
    "                        \n",
    "                    if metric == \"ssim\":\n",
    "                        base_metric = ssim(orig_zone, baseline_zone, data_range=1, size_average=True).item()\n",
    "                        # For SSIM, higher is better, so baseline - perturbed shows how much we lost\n",
    "                        # (negative value means perturbation improved SSIM)\n",
    "                        zone_metrics[zone_name] = base_metric - pred_metric\n",
    "                    else:\n",
    "                        # TV Loss\n",
    "                        tv_loss = torch.abs(baseline_zone[:,:,1:,:] - baseline_zone[:,:,:-1,:]).sum() + \\\n",
    "                                 torch.abs(baseline_zone[:,:,:,1:] - baseline_zone[:,:,:,:-1]).sum()\n",
    "                        base_metric = tv_loss.item() / mask.sum()\n",
    "                        # For TV loss, lower is better, so perturbed - baseline shows how much we lost\n",
    "                        # (positive value means perturbation worsened TV loss)\n",
    "                        zone_metrics[zone_name] = pred_metric - base_metric\n",
    "                else:\n",
    "                    # No baseline, just use the prediction metric\n",
    "                    zone_metrics[zone_name] = pred_metric\n",
    "                \n",
    "            else:  # Normal zones\n",
    "                # Get the zone data\n",
    "                orig_zone = orig_tensor[0][zone_slice].unsqueeze(0)\n",
    "                pred_zone = pred_tensor[0][zone_slice].unsqueeze(0)\n",
    "                \n",
    "                # Calculate metric for prediction\n",
    "                if metric == \"ssim\":\n",
    "                    pred_metric = ssim(orig_zone, pred_zone, data_range=1, size_average=True).item()\n",
    "                else:\n",
    "                    # TV Loss calculation\n",
    "                    tv_loss = torch.abs(pred_zone[:,:,1:,:] - pred_zone[:,:,:-1,:]).sum() + \\\n",
    "                              torch.abs(pred_zone[:,:,:,1:] - pred_zone[:,:,:,:-1]).sum()\n",
    "                    # Normalize by number of pixels in the zone\n",
    "                    pred_metric = tv_loss.item() / (orig_zone.shape[2] * orig_zone.shape[3])\n",
    "                \n",
    "                # If baseline provided, calculate baseline metric and difference\n",
    "                if baseline_frame is not None:\n",
    "                    baseline_zone = baseline_tensor[0][zone_slice].unsqueeze(0)\n",
    "                    \n",
    "                    if metric == \"ssim\":\n",
    "                        base_metric = ssim(orig_zone, baseline_zone, data_range=1, size_average=True).item()\n",
    "                        # For SSIM, higher is better, so baseline - perturbed shows how much we lost\n",
    "                        zone_metrics[zone_name] = base_metric - pred_metric\n",
    "                    else:\n",
    "                        # TV Loss\n",
    "                        tv_loss = torch.abs(baseline_zone[:,:,1:,:] - baseline_zone[:,:,:-1,:]).sum() + \\\n",
    "                                 torch.abs(baseline_zone[:,:,:,1:] - baseline_zone[:,:,:,:-1]).sum()\n",
    "                        base_metric = tv_loss.item() / (baseline_zone.shape[2] * baseline_zone.shape[3])\n",
    "                        # For TV loss, lower is better, so perturbed - baseline shows how much we lost\n",
    "                        # (positive value means perturbation worsened TV loss)\n",
    "                        zone_metrics[zone_name] = pred_metric - base_metric\n",
    "                else:\n",
    "                    # No baseline, just use the prediction metric\n",
    "                    zone_metrics[zone_name] = pred_metric\n",
    "        \n",
    "        return zone_metrics\n",
    "    \n",
    "    '''\n",
    "    # Helper function for normalizing images for display\n",
    "    def normalize(img):\n",
    "        \"\"\"Normalize image for display\"\"\"\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img = img.detach().cpu().numpy()\n",
    "        \n",
    "        img = img.copy()\n",
    "        if img.min() < 0:\n",
    "            img = (img + 1) / 2  # [-1, 1] -> [0, 1]\n",
    "        return np.clip(img, 0, 1)\n",
    "    '''\n",
    "\n",
    "    def normalize(img):\n",
    "        \"\"\"Normalize image for display\"\"\"\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img = img.detach().cpu().numpy()\n",
    "        \n",
    "        img = img.copy().astype(np.float32)\n",
    "        \n",
    "        # Use actual min/max instead of assuming [-1,1]\n",
    "        img_min, img_max = img.min(), img.max()\n",
    "        if img_max > img_min:\n",
    "            img = (img - img_min) / (img_max - img_min)\n",
    "        else:\n",
    "            img = np.zeros_like(img)\n",
    "        \n",
    "        return np.clip(img, 0, 1)\n",
    "    \n",
    "    # Initialize metrics\n",
    "    all_zone_metrics = {}  # Will store metrics for each prediction key\n",
    "    \n",
    "    # Get appropriate metric name\n",
    "    if baseline_predictions is not None:\n",
    "        metric_description = \"Difference from Baseline\" \n",
    "        if metric == \"ssim\":\n",
    "            metric_name = \"SSIM Difference\"\n",
    "        else:\n",
    "            metric_name = \"TV Loss Difference\"\n",
    "    else:\n",
    "        metric_name = \"SSIM\" if metric == \"ssim\" else \"TV Loss\"\n",
    "        metric_description = metric_name\n",
    "    \n",
    "    # Create a TV loss calculator if needed\n",
    "    if metric == \"tv\":\n",
    "        tv_calculator = TotalVariation().to(device)\n",
    "    \n",
    "    # ===== PART 1: Calculate zone metrics for each prediction =====\n",
    "    for pred_key, video_key in key_mapping.items():\n",
    "        prediction = predictions[pred_key]\n",
    "        video = videos[video_key][..., 15]  # Middle frame\n",
    "        \n",
    "        # Get baseline prediction if available\n",
    "        baseline_pred = None\n",
    "        if baseline_predictions is not None:\n",
    "            # Find the appropriate key in baseline predictions\n",
    "            baseline_keys = list(baseline_predictions.keys())\n",
    "            if pred_key in baseline_predictions:\n",
    "                baseline_pred = baseline_predictions[pred_key]\n",
    "            elif len(baseline_keys) > 0:\n",
    "                # If exact key not found, use first available baseline key\n",
    "                baseline_pred = baseline_predictions[baseline_keys[0]]\n",
    "                print(f\"Using {baseline_keys[0]} as baseline for {pred_key}\")\n",
    "        \n",
    "        # Check shapes\n",
    "        print(f\"Prediction {pred_key} shape: {prediction.shape}\")\n",
    "        print(f\"Video {video_key} shape: {video.shape}\")\n",
    "        if baseline_pred is not None:\n",
    "            print(f\"Baseline prediction shape: {baseline_pred.shape}\")\n",
    "        \n",
    "        # Ensure prediction and video have compatible shapes\n",
    "        if prediction.shape[0] != video.shape[0]:\n",
    "            print(f\"Warning: Shape mismatch for {pred_key} vs {video_key}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # If baseline exists, ensure it has compatible shape\n",
    "        if baseline_pred is not None and baseline_pred.shape[0] != prediction.shape[0]:\n",
    "            print(f\"Warning: Baseline shape {baseline_pred.shape} doesn't match prediction shape {prediction.shape}. Ignoring baseline.\")\n",
    "            baseline_pred = None\n",
    "        \n",
    "        N = video.shape[0]\n",
    "        \n",
    "        # Store metrics for all frames in this prediction\n",
    "        pred_metrics = []\n",
    "        \n",
    "        # Calculate metrics for each frame\n",
    "        for i in range(N):\n",
    "            # Get zones for this frame\n",
    "            zones = split_into_zones(video[i], zone_type=zone_type)\n",
    "            \n",
    "            # Calculate metrics for each zone\n",
    "            try:\n",
    "                # If baseline exists, calculate difference metrics\n",
    "                if baseline_pred is not None:\n",
    "                    zone_metrics = calculate_zone_metrics(\n",
    "                        video[i], prediction[i], baseline_frame=baseline_pred[i], zones=zones, metric=metric\n",
    "                    )\n",
    "                else:\n",
    "                    zone_metrics = calculate_zone_metrics(\n",
    "                        video[i], prediction[i], zones=zones, metric=metric\n",
    "                    )\n",
    "                pred_metrics.append(zone_metrics)\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating zone metrics for {pred_key}, frame {i}: {e}\")\n",
    "                # Create empty metrics\n",
    "                if zone_type == \"quadrants\":\n",
    "                    pred_metrics.append({\n",
    "                        \"top_left\": 0, \"top_right\": 0, \n",
    "                        \"bottom_left\": 0, \"bottom_right\": 0\n",
    "                    })\n",
    "                elif zone_type == \"center_bg\":\n",
    "                    pred_metrics.append({\"center\": 0, \"background\": 0})\n",
    "                elif isinstance(zone_type, int):\n",
    "                    empty_metrics = {}\n",
    "                    for ii in range(zone_type):\n",
    "                        for jj in range(zone_type):\n",
    "                            empty_metrics[f\"grid_{ii}_{jj}\"] = 0\n",
    "                    pred_metrics.append(empty_metrics)\n",
    "        \n",
    "        # Store metrics for this prediction\n",
    "        all_zone_metrics[pred_key] = pred_metrics\n",
    "        \n",
    "        # Print average metrics for this prediction\n",
    "        print(f\"\\nAverage {metric_description} for {pred_key} by zone:\")\n",
    "        \n",
    "        # Calculate and print mean metrics across frames for each zone\n",
    "        if len(pred_metrics) > 0:\n",
    "            zone_names = list(pred_metrics[0].keys())\n",
    "            \n",
    "            for zone in zone_names:\n",
    "                zone_values = [metrics[zone] for metrics in pred_metrics]\n",
    "                mean_zone = np.mean(zone_values)\n",
    "                print(f\"  - {zone}: {mean_zone:.4f}\")\n",
    "    \n",
    "    # ===== PART 2: Plot the original image, baseline, reconstruction, and heatmap side by side =====\n",
    "    if display_plots and len(key_mapping) > 0:\n",
    "        # Get a reference video key and shape\n",
    "        ref_video_key = list(videos.keys())[0]\n",
    "        ref_video = videos[ref_video_key][..., 15]\n",
    "        N = ref_video.shape[0]\n",
    "        \n",
    "        # Determine the frames to plot\n",
    "        if max_frames is not None and max_frames < N:\n",
    "            # Evenly sample frames if max_frames is specified\n",
    "            indices = np.linspace(0, N-1, max_frames, dtype=int)\n",
    "        else:\n",
    "            # Plot all frames\n",
    "            indices = np.arange(N)\n",
    "        \n",
    "        # Determine number of panels based on whether baseline is available\n",
    "        if baseline_predictions is not None:\n",
    "            num_panels = 4  # Original, Baseline, Perturbed, Difference\n",
    "            print(f\"\\nPlotting {len(indices)} frames with Original, Baseline, Perturbed, and Difference\")\n",
    "        else:\n",
    "            num_panels = 3  # Original, Reconstruction, Heatmap\n",
    "            print(f\"\\nPlotting {len(indices)} frames with Original, Reconstruction, and Heatmap\")\n",
    "        \n",
    "        # REORDERING: Create an ordered list of prediction keys with \"original_combined\" first\n",
    "        ordered_keys = []\n",
    "        for key in key_mapping.keys():\n",
    "            if key != \"original_combined\":\n",
    "                ordered_keys.append(key)\n",
    "        \n",
    "        # If \"original_combined\" exists, insert it at the beginning of the list\n",
    "        if \"original_combined\" in key_mapping:\n",
    "            ordered_keys.insert(0, \"original_combined\")\n",
    "        \n",
    "        # For each frame index\n",
    "        for frame_idx in indices:\n",
    "            # Plot original reference frame\n",
    "            ref_frame = ref_video[frame_idx]\n",
    "            \n",
    "            # For each prediction\n",
    "            for pred_key in ordered_keys:\n",
    "                try:\n",
    "                    video_key = key_mapping[pred_key]\n",
    "                    perturbed_frame = predictions[pred_key][frame_idx]\n",
    "                    \n",
    "                    # Get baseline frame if available\n",
    "                    baseline_frame = None\n",
    "                    if baseline_predictions is not None:\n",
    "                        if pred_key in baseline_predictions:\n",
    "                            baseline_frame = baseline_predictions[pred_key][frame_idx]\n",
    "                        elif len(baseline_predictions) > 0:\n",
    "                            # Use first available baseline prediction\n",
    "                            first_key = list(baseline_predictions.keys())[0]\n",
    "                            baseline_frame = baseline_predictions[first_key][frame_idx]\n",
    "                    \n",
    "                    # Get zone metrics for this prediction\n",
    "                    zone_metrics = all_zone_metrics[pred_key][frame_idx]\n",
    "                    \n",
    "                    # Determine if we're showing differences or absolute values\n",
    "                    is_difference = baseline_frame is not None\n",
    "                    \n",
    "                    # Create a figure with the appropriate number of subplots\n",
    "                    fig, axes = plt.subplots(1, num_panels, figsize=(5 * num_panels, 5))\n",
    "                    \n",
    "                    # 1. Original Frame (leftmost)\n",
    "                    axes[0].imshow(np.transpose(normalize(ref_frame), (1, 2, 0)))\n",
    "                    axes[0].set_title(f\"Original Frame {frame_idx}\")\n",
    "                    axes[0].axis('off')\n",
    "                    \n",
    "                    # Panel index for reconstruction and heatmap depends on whether baseline exists\n",
    "                    recon_idx = 2 if is_difference else 1\n",
    "                    heatmap_idx = 3 if is_difference else 2\n",
    "                    \n",
    "                    # 2. Baseline Reconstruction (if available)\n",
    "                    if is_difference:\n",
    "                        axes[1].imshow(np.transpose(normalize(baseline_frame), (1, 2, 0)))\n",
    "                        axes[1].set_title(f\"Baseline Reconstruction\")\n",
    "                        axes[1].axis('off')\n",
    "                    \n",
    "                    # 3. Perturbed Reconstruction \n",
    "                    axes[recon_idx].imshow(np.transpose(normalize(perturbed_frame), (1, 2, 0)))\n",
    "                    if is_difference:\n",
    "                        axes[recon_idx].set_title(f\"Perturbed Reconstruction\")\n",
    "                    else:\n",
    "                        axes[recon_idx].set_title(f\"{pred_key} (Frame {frame_idx})\")\n",
    "                    axes[recon_idx].axis('off')\n",
    "                    \n",
    "                    # 4. Heatmap of metrics (rightmost)\n",
    "                    # Determine colormap based on if we're showing differences\n",
    "                    cmap_name = 'coolwarm' if is_difference else 'viridis'\n",
    "                    \n",
    "                    # Also determine normalization based on if we're showing differences\n",
    "                    if is_difference:\n",
    "                        # For differences, use symmetric normalization around zero\n",
    "                        values = list(zone_metrics.values())\n",
    "                        max_abs = max(abs(min(values)), abs(max(values))) if values else 1.0\n",
    "                        norm = Normalize(vmin=-max_abs, vmax=max_abs)\n",
    "                    else:\n",
    "                        # For absolute values, use standard normalization\n",
    "                        norm = None  # Let matplotlib handle it\n",
    "                    \n",
    "                    if isinstance(zone_type, int):\n",
    "                        # For n×n grid, create a grid to display metrics\n",
    "                        grid_values = np.zeros((zone_type, zone_type))\n",
    "                        \n",
    "                        for i in range(zone_type):\n",
    "                            for j in range(zone_type):\n",
    "                                zone_name = f\"grid_{i}_{j}\"\n",
    "                                grid_values[i, j] = zone_metrics.get(zone_name, 0)\n",
    "                        \n",
    "                        # Show the heatmap\n",
    "                        im = axes[heatmap_idx].imshow(grid_values, cmap=cmap_name, interpolation='nearest', norm=norm)\n",
    "                        \n",
    "                        # Add text labels with adjustable font size\n",
    "                        fontsize = max(6, min(10, 16 - zone_type))  # Scale font size based on grid density\n",
    "                        for i in range(zone_type):\n",
    "                            for j in range(zone_type):\n",
    "                                # Format the value based on magnitude\n",
    "                                val = grid_values[i, j]\n",
    "                                if abs(val) >= 0.01:\n",
    "                                    text = f\"{val:.3f}\"\n",
    "                                else:\n",
    "                                    text = f\"{val:.1e}\"\n",
    "                                    \n",
    "                                axes[heatmap_idx].text(j, i, text,\n",
    "                                           ha=\"center\", va=\"center\", color=\"white\",\n",
    "                                           fontsize=fontsize, fontweight='bold')\n",
    "                        \n",
    "                        # Add colorbar\n",
    "                        cbar = plt.colorbar(im, ax=axes[heatmap_idx])\n",
    "                        cbar.set_label(metric_name)\n",
    "                        \n",
    "                        axes[heatmap_idx].set_title(f\"Zone {metric_description}\")\n",
    "                        \n",
    "                    elif zone_type == \"quadrants\":\n",
    "                        # For quadrants, create a 2×2 heatmap\n",
    "                        quadrant_values = np.zeros((2, 2))\n",
    "                        quadrant_values[0, 0] = zone_metrics.get(\"top_left\", 0)\n",
    "                        quadrant_values[0, 1] = zone_metrics.get(\"top_right\", 0)\n",
    "                        quadrant_values[1, 0] = zone_metrics.get(\"bottom_left\", 0)\n",
    "                        quadrant_values[1, 1] = zone_metrics.get(\"bottom_right\", 0)\n",
    "                        \n",
    "                        # Show the heatmap\n",
    "                        im = axes[heatmap_idx].imshow(quadrant_values, cmap=cmap_name, interpolation='nearest', norm=norm)\n",
    "                        \n",
    "                        # Add text labels\n",
    "                        for i, j in [(0,0), (0,1), (1,0), (1,1)]:\n",
    "                            val = quadrant_values[i, j]\n",
    "                            if abs(val) >= 0.01:\n",
    "                                text = f\"{val:.3f}\"\n",
    "                            else:\n",
    "                                text = f\"{val:.1e}\"\n",
    "                            axes[heatmap_idx].text(j, i, text, ha=\"center\", va=\"center\", color=\"white\", fontsize=10)\n",
    "                        \n",
    "                        # Add colorbar\n",
    "                        cbar = plt.colorbar(im, ax=axes[heatmap_idx])\n",
    "                        cbar.set_label(metric_name)\n",
    "                        \n",
    "                        axes[heatmap_idx].set_title(f\"Quadrant {metric_description}\")\n",
    "                        \n",
    "                    elif zone_type == \"center_bg\":\n",
    "                        # For center/background, special visualization\n",
    "                        center_val = zone_metrics.get(\"center\", 0)\n",
    "                        bg_val = zone_metrics.get(\"background\", 0)\n",
    "                        \n",
    "                        # Create a mask-based visualization\n",
    "                        mask = np.zeros((3, 3), dtype=bool)\n",
    "                        mask[1, 1] = True  # Center is True, background is False\n",
    "                        \n",
    "                        # Create values array where center has one value, background another\n",
    "                        values = np.ones((3, 3)) * bg_val\n",
    "                        values[1, 1] = center_val\n",
    "                        \n",
    "                        # Show the heatmap\n",
    "                        im = axes[heatmap_idx].imshow(values, cmap=cmap_name, interpolation='nearest', norm=norm)\n",
    "                        \n",
    "                        # Format values for display\n",
    "                        if abs(center_val) >= 0.01:\n",
    "                            center_text = f\"Center\\n{center_val:.3f}\"\n",
    "                        else:\n",
    "                            center_text = f\"Center\\n{center_val:.1e}\"\n",
    "                            \n",
    "                        if abs(bg_val) >= 0.01:\n",
    "                            bg_text = f\"BG\\n{bg_val:.3f}\"\n",
    "                        else:\n",
    "                            bg_text = f\"BG\\n{bg_val:.1e}\"\n",
    "                        \n",
    "                        # Add text labels\n",
    "                        axes[heatmap_idx].text(1, 1, center_text, ha=\"center\", va=\"center\", color=\"white\", fontsize=10)\n",
    "                        axes[heatmap_idx].text(0, 0, bg_text, ha=\"center\", va=\"center\", color=\"white\", fontsize=10)\n",
    "                        \n",
    "                        # Add colorbar\n",
    "                        cbar = plt.colorbar(im, ax=axes[heatmap_idx])\n",
    "                        cbar.set_label(metric_name)\n",
    "                        \n",
    "                        axes[heatmap_idx].set_title(f\"Center/Background {metric_description}\")\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    \n",
    "                    # Save figure if requested\n",
    "                    if save_plots and save_path_prefix:\n",
    "                        zone_type_str = zone_type if isinstance(zone_type, str) else f\"grid{zone_type}x{zone_type}\"\n",
    "                        type_str = \"diff\" if is_difference else \"abs\"\n",
    "                        fig_path = f\"{save_path_prefix}{pred_key}_frame{frame_idx}_{metric}_{zone_type_str}_{type_str}.png\"\n",
    "                        plt.savefig(fig_path, bbox_inches='tight', dpi=300)\n",
    "                    \n",
    "                    plt.show()\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error creating visualization for {pred_key} (Frame {frame_idx}): {e}\")\n",
    "    \n",
    "    # Calculate overall mean metric\n",
    "    overall_mean = 0\n",
    "    if len(all_zone_metrics) > 0:\n",
    "        # Average across all predictions and all zones\n",
    "        all_values = []\n",
    "        for pred_metrics in all_zone_metrics.values():\n",
    "            for metrics in pred_metrics:\n",
    "                all_values.extend(list(metrics.values()))\n",
    "        \n",
    "        if all_values:\n",
    "            overall_mean = np.mean(all_values)\n",
    "    \n",
    "    # Update performance dictionary if provided\n",
    "    if performance_dict is not None:\n",
    "        try:\n",
    "            # Calculate overall metrics across all zones\n",
    "            for pred_key, pred_metrics in all_zone_metrics.items():\n",
    "                if len(pred_metrics) > 0:\n",
    "                    zone_names = list(pred_metrics[0].keys())\n",
    "                    \n",
    "                    for zone in zone_names:\n",
    "                        zone_values = [metrics[zone] for metrics in pred_metrics]\n",
    "                        zone_mean = np.mean(zone_values)\n",
    "                        zone_median = np.median(zone_values)\n",
    "                        \n",
    "                        # Add to performance dict\n",
    "                        if baseline_predictions is not None:\n",
    "                            # This is a difference metric\n",
    "                            if metric == \"ssim\":\n",
    "                                performance_dict[f'diff_ssim_{zone}_D'] = zone_mean\n",
    "                                performance_dict[f'median_diff_ssim_{zone}_D'] = zone_median\n",
    "                            else:\n",
    "                                performance_dict[f'diff_tv_{zone}_D'] = zone_mean\n",
    "                                performance_dict[f'median_diff_tv_{zone}_D'] = zone_median\n",
    "                        else:\n",
    "                            # This is an absolute metric\n",
    "                            if metric == \"ssim\":\n",
    "                                performance_dict[f'mean_ssim_{zone}_D'] = zone_mean\n",
    "                                performance_dict[f'median_ssim_{zone}_D'] = zone_median\n",
    "                            else:\n",
    "                                performance_dict[f'mean_tv_{zone}_D'] = zone_mean\n",
    "                                performance_dict[f'median_tv_{zone}_D'] = zone_median\n",
    "            \n",
    "            # Add overall mean metric\n",
    "            if baseline_predictions is not None:\n",
    "                # This is a difference metric\n",
    "                if metric == \"ssim\":\n",
    "                    performance_dict['diff_ssim_D'] = overall_mean\n",
    "                else:\n",
    "                    performance_dict['diff_tv_D'] = overall_mean\n",
    "            else:\n",
    "                # This is an absolute metric\n",
    "                if metric == \"ssim\":\n",
    "                    performance_dict['mean_ssim_D'] = overall_mean\n",
    "                else:\n",
    "                    performance_dict['mean_tv_D'] = overall_mean\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error updating performance dictionary: {e}\")\n",
    "    \n",
    "    if mean_flag:\n",
    "        return overall_mean\n",
    "    \n",
    "    return performance_dict\n",
    "\n",
    "\n",
    "\n",
    "def test_model_all(inputs_dict, labels_dict, model, criterion, device, pretrained_decoder=None, model_to_test=None, \n",
    "               statistical_testing=False, display_plots=True, save_plots=False, model_name=\"\", metric=\"ssim\", \n",
    "               mean_flag=False, zones=None, baseline_predictions=None):\n",
    "    \"\"\"\n",
    "    Test the pretrained model on the provided dataset.\n",
    "\n",
    "    Arguments:\n",
    "        inputs_dict (dict): Dictionary of input data. Keys are movie names or slice identifiers. \n",
    "                           If model_to_test is 'encoder' or 'encoder_decoder', then elements have a shape of (TR, 3, 112, 112, 32). \n",
    "                           Else, shape of (TR, mask_size).\n",
    "        labels_dict (dict): Dictionary of labels. Keys are movie names. \n",
    "                           If model_to_test is 'encoder' or 'encoder_decoder', then elements have a shape of (TR, mask_size). \n",
    "                           Else, shape of (TR, 3, 112, 112, 32).\n",
    "        model (nn.Module): The pretrained neural network model to be tested.\n",
    "        criterion (nn.Module): Loss function for testing.\n",
    "        device (torch.device): Device to test the model on (CPU or GPU).\n",
    "        pretrained_decoder (str, optional): Path to a pretrained decoder model. Default is None.\n",
    "        model_to_test (str): Specifies which part of the model to test. Options are 'encoder', 'decoder', or 'encoder_decoder'.\n",
    "        statistical_testing (bool, optional): Whether to perform statistical testing. Default is False.\n",
    "        display_plots (bool, optional): Whether to display plots. Default is True.\n",
    "        save_plots (bool, optional): Whether to save plots. Default is False.\n",
    "        model_name (str, optional): Name of the model for saving plots. Default is \"\".\n",
    "        zones (str or int, optional): Zones to consider for testing. Default is \"quadrants\", can also be \"center_bg\".\n",
    "                                      If it is an integer, the function will analyze a number of zones = that integer squared.\n",
    "                                      For example, if zones = 4, the function will analyze 16 zones (4x4).\n",
    "        baseline_predictions (dict, optional): Dictionary of baseline predictions for comparison.\n",
    "\n",
    "    Returns:\n",
    "        results (dict): Dictionary containing test results including model predictions and losses.\n",
    "    \"\"\"\n",
    "    print('Start testing:')\n",
    "    tic = time.time()\n",
    "\n",
    "    # Create outputs directory if it doesn't exist\n",
    "    if save_plots:\n",
    "        import os\n",
    "        os.makedirs('outputs', exist_ok=True)\n",
    "\n",
    "    model_type = ['encoder', 'decoder', 'encoder_decoder']\n",
    "    if model_to_test not in model_type:\n",
    "        print(f'model_to_test: {model_to_test} not recognized. Must be one of {model_type}')\n",
    "        return None, None\n",
    "\n",
    "    # Get list of input keys (movie names or slice identifiers)\n",
    "    videos = list(inputs_dict.keys())\n",
    "    inputs_shape = list(inputs_dict[videos[0]].shape)\n",
    "    inputs_shape[0] = 'TR'\n",
    "    print(f'### Testing {model_to_test} on inputs of shape {inputs_shape} over {len(videos)} videos/slices ###')\n",
    "    \n",
    "    if baseline_predictions is not None:\n",
    "        print(f'### Using baseline predictions for comparison ###')\n",
    "\n",
    "    criterion = criterion.to(device)\n",
    "    # Set model in testing phase\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Load and set pretrained decoder if specified\n",
    "    if pretrained_decoder:\n",
    "        decoder = Decoder(labels_dict[next(iter(labels_dict))].shape[1])  # Assuming shape is consistent across labels\n",
    "        state_dict = torch.load(pretrained_decoder)\n",
    "        decoder.load_state_dict(state_dict)\n",
    "        decoder.to(device)\n",
    "        for param in decoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        decoder.eval()\n",
    "\n",
    "        print(f'Also using pretrained decoder {pretrained_decoder}')\n",
    "\n",
    "    if model_to_test != 'encoder_decoder' and pretrained_decoder is None:\n",
    "        results = {\n",
    "            model_to_test + '_predictions': {},\n",
    "            'total_losses': {}\n",
    "        }\n",
    "    else:\n",
    "        results = {\n",
    "            'encoder_predictions': {},\n",
    "            'decoder_predictions': {},\n",
    "            'total_losses': {}\n",
    "        }\n",
    "\n",
    "        decoder_saliency = np.zeros(labels_dict[list(labels_dict.keys())[0]].shape[1])\n",
    "\n",
    "    results['test_performance'] = {}\n",
    "    \n",
    "    # Process each item in the inputs and labels dictionaries\n",
    "    for key in inputs_dict.keys():\n",
    "        input_tensor = torch.from_numpy(inputs_dict[key].astype('float32'))\n",
    "        \n",
    "        # Get the corresponding label - if it's a slice name, extract the original movie name\n",
    "        if key in labels_dict:\n",
    "            label_key = key\n",
    "        else:\n",
    "            # Extract the movie name from the key (assumed to be after the last underscore)\n",
    "            # For keys like \"slice_0_Payload\", this will extract \"Payload\"\n",
    "            if '_' in key:\n",
    "                extracted_movie = key.split('_')[-1]\n",
    "                if extracted_movie in labels_dict:\n",
    "                    label_key = extracted_movie\n",
    "                    print(f\"Input key '{key}' not found in labels. Extracted and using '{label_key}' for labels.\")\n",
    "                else:\n",
    "                    # If extracted name not found, use first available label\n",
    "                    label_key = list(labels_dict.keys())[0]\n",
    "                    print(f\"Input key '{key}' and extracted movie '{extracted_movie}' not found in labels. Using '{label_key}' for labels.\")\n",
    "            else:\n",
    "                # If no underscore in key, use first available label\n",
    "                label_key = list(labels_dict.keys())[0]\n",
    "                print(f\"Input key '{key}' not found in labels and no movie name could be extracted. Using '{label_key}' for labels.\")\n",
    "        \n",
    "        label_tensor = torch.from_numpy(labels_dict[label_key].astype('float32'))\n",
    "\n",
    "        # Debug info about tensors but without using print_dict_tree\n",
    "        print(f\"input_tensor shape: {input_tensor.shape}, dtype: {input_tensor.dtype}\")\n",
    "        print(f\"label_tensor shape: {label_tensor.shape}, dtype: {label_tensor.dtype}\")\n",
    "        \n",
    "        test_set = torch.utils.data.TensorDataset(input_tensor, label_tensor)\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test_set,\n",
    "            batch_size=16,\n",
    "            shuffle=False,\n",
    "            pin_memory=torch.cuda.is_available(),\n",
    "            num_workers=4\n",
    "        )\n",
    "\n",
    "        model_outputs, decoder_outputs, total_losses = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for input, label in test_loader:\n",
    "                input, label = input.to(device), label.to(device)\n",
    "            \n",
    "                decoder_output = None\n",
    "                if model_to_test == 'encoder_decoder':\n",
    "                    model_output, decoder_output = model(input.float())\n",
    "                elif pretrained_decoder:\n",
    "                    model_output = model(input.float()).to(device)\n",
    "                    decoder_output = decoder(model_output.float())\n",
    "                else:\n",
    "                    model_output = model(input.float())\n",
    "                        \n",
    "                model_outputs.append(model_output.detach().cpu())\n",
    "                if decoder_output is not None:\n",
    "                    decoder_outputs.append(decoder_output.detach().cpu())\n",
    "            \n",
    "                # Apply the appropriate criterion based on the presence of decoder outputs\n",
    "                if model_to_test == 'decoder':\n",
    "                    *loss_metrics, total_loss, metrics_names = criterion(model_output, label[..., 15])          #--> middle frame\n",
    "                elif decoder_output is None:\n",
    "                    *loss_metrics, total_loss, metrics_names = criterion(model_output, label)\n",
    "                else:\n",
    "                    *loss_metrics, total_loss, metrics_names = criterion(model_output, label, decoder_output, input[..., 15])\n",
    "                \n",
    "                total_losses.append(total_loss.item())\n",
    "\n",
    "        # Store the outputs in results\n",
    "        if model_to_test != 'encoder_decoder' and pretrained_decoder is None:\n",
    "            results[model_to_test + '_predictions'][key] = torch.cat(model_outputs, dim=0).numpy()\n",
    "        else:\n",
    "            results['encoder_predictions'][key] = torch.cat(model_outputs, dim=0).numpy()\n",
    "            results['decoder_predictions'][key] = torch.cat(decoder_outputs, dim=0).numpy()\n",
    "        \n",
    "        results['total_losses'][key] = np.asarray(total_losses)\n",
    "\n",
    "        if model_to_test != 'decoder':\n",
    "            encoded = results['encoder_predictions'][key]\n",
    "            labels = labels_dict[label_key] if key not in labels_dict else labels_dict[key]\n",
    "            plot_metrics(labels, encoded, key, plot_TR=False, performance_dict=None, \n",
    "                        display_plots=display_plots,\n",
    "                        save_plots=save_plots,\n",
    "                        save_path=f'outputs/{key}_{model_name}.png' if save_plots else None)\n",
    "\n",
    "    if model_to_test != 'decoder':\n",
    "        all_encoded = results['encoder_predictions']\n",
    "        all_labels = labels_dict\n",
    "        # Using the last processed key for display\n",
    "        results['test_performance'] = plot_metrics(labels, encoded, key, plot_TR=False, performance_dict=None, \n",
    "                        display_plots=display_plots,\n",
    "                        save_plots=save_plots,\n",
    "                        save_path=f'outputs/{key}_{model_name}.png' if save_plots else None)\n",
    "\n",
    "        if statistical_testing:\n",
    "            all_labels, all_predictions = [], []\n",
    "            for key in labels_dict.keys():\n",
    "                if key in results['encoder_predictions']:\n",
    "                    all_predictions.append(results['encoder_predictions'][key])\n",
    "                    all_labels.append(labels_dict[key])\n",
    "            all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "            all_labels = np.concatenate(all_labels, axis=0)\n",
    "            one_sample_permutation_test(all_labels, all_predictions)\n",
    "\n",
    "    if model_to_test != 'encoder' or pretrained_decoder is not None:\n",
    "        if model_to_test == 'decoder':\n",
    "            print(\"\\n\\n\\n ALRIGHT ZONES =\", zones, \"\\n\\n\\n\")\n",
    "            \n",
    "            # Check if we have baseline predictions to use\n",
    "            if baseline_predictions is not None:\n",
    "                # Use the modified plot_all_predictions7 with baseline comparison\n",
    "                results['test_performance'] = plot_all_predictions7(\n",
    "                    results['decoder_predictions'], \n",
    "                    labels_dict, \n",
    "                    results['test_performance'], \n",
    "                    display_plots,\n",
    "                    save_plots=save_plots,\n",
    "                    save_path_prefix='outputs/' if save_plots else None,\n",
    "                    model_name=model_name, \n",
    "                    metric=metric, \n",
    "                    mean_flag=mean_flag,\n",
    "                    zone_type=zones,\n",
    "                    baseline_predictions=baseline_predictions\n",
    "                )\n",
    "            else:\n",
    "                # Use the regular plot_all_predictions7 without baseline\n",
    "                if zones is None:\n",
    "                    results['test_performance'] = plot_all_predictions5(\n",
    "                        results['decoder_predictions'], \n",
    "                        labels_dict, \n",
    "                        results['test_performance'], \n",
    "                        display_plots,\n",
    "                        save_plots=save_plots,\n",
    "                        save_path_prefix='outputs/' if save_plots else None,\n",
    "                        model_name=model_name, \n",
    "                        metric=metric, \n",
    "                        mean_flag=mean_flag\n",
    "                    )\n",
    "                else:\n",
    "                    results['test_performance'] = plot_all_predictions7(\n",
    "                        results['decoder_predictions'], \n",
    "                        labels_dict, \n",
    "                        results['test_performance'], \n",
    "                        display_plots,\n",
    "                        save_plots=save_plots,\n",
    "                        save_path_prefix='outputs/' if save_plots else None,\n",
    "                        model_name=model_name, \n",
    "                        metric=metric, \n",
    "                        mean_flag=mean_flag,\n",
    "                        zone_type=zones\n",
    "                    )\n",
    "\n",
    "        else:\n",
    "            # For encoder or encoder_decoder, use inputs_dict for ground truth\n",
    "            if baseline_predictions is not None:\n",
    "                results['test_performance'] = plot_all_predictions7(\n",
    "                    results['decoder_predictions'], \n",
    "                    inputs_dict, \n",
    "                    results['test_performance'], \n",
    "                    display_plots,\n",
    "                    save_plots=save_plots,\n",
    "                    save_path_prefix='outputs/' if save_plots else None,\n",
    "                    model_name=model_name, \n",
    "                    metric=metric, \n",
    "                    baseline_predictions=baseline_predictions\n",
    "                )\n",
    "            else:\n",
    "                results['test_performance'] = plot_all_predictions5(\n",
    "                    results['decoder_predictions'], \n",
    "                    inputs_dict, \n",
    "                    results['test_performance'], \n",
    "                    display_plots,\n",
    "                    save_plots=save_plots,\n",
    "                    save_path_prefix='outputs/' if save_plots else None,\n",
    "                    model_name=model_name, \n",
    "                    metric=metric\n",
    "                )\n",
    "    print(\"using new function\")\n",
    "        \n",
    "    if model_to_test == 'encoder_decoder':\n",
    "        with torch.enable_grad():\n",
    "            for key in inputs_dict.keys():\n",
    "                predicted_fMRIs = torch.from_numpy(results['encoder_predictions'][key])\n",
    "                # Get corresponding input for ground truth\n",
    "                if key in inputs_dict:\n",
    "                    input_key = key\n",
    "                else:\n",
    "                    # Use first input if key not found\n",
    "                    input_key = list(inputs_dict.keys())[0]\n",
    "                \n",
    "                ground_truth_frames = torch.from_numpy(inputs_dict[input_key][..., 15])\n",
    "                for i in range(predicted_fMRIs.shape[0]):\n",
    "                    decoder_saliency += compute_saliency(model.decoder, predicted_fMRIs[i:i+1], ground_truth_frames[i:i+1], device)\n",
    "\n",
    "        if display_plots:\n",
    "            plot_saliency_distribution(decoder_saliency)\n",
    "        results['decoder_saliency'] = decoder_saliency\n",
    "\n",
    "    print(\"Testing completed. Total time: {:.2f} minutes\".format((time.time() - tic) / 60))\n",
    "    print('---')\n",
    "    return results\n",
    "\n",
    "def visualize_blocks_3(data_3d, blocks, losses, num_blocks=(3, 3, 3), figsize=None, colormap='viridis', \n",
    "                   title_prefix=\"Brain Divided into\", is_difference=False):\n",
    "    \"\"\"\n",
    "    Visualize brain blocks using maximum intensity projection for each z-layer\n",
    "    Shows axial views for each layer along the z-dimension and displays loss values or differences\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_3d : numpy.ndarray\n",
    "        3D brain data\n",
    "    blocks : dict\n",
    "        Dictionary mapping block IDs to block boundaries\n",
    "    losses : array-like\n",
    "        Array of loss values or difference values, one per block (index 0 corresponds to block 1)\n",
    "    num_blocks : tuple\n",
    "        Number of blocks along each dimension (x, y, z)\n",
    "    figsize : tuple, optional\n",
    "        Figure size, if None will be calculated based on z-dimension blocks\n",
    "    colormap : str\n",
    "        Matplotlib colormap name to use for loss values\n",
    "        'viridis' good for absolute values, 'coolwarm' good for differences\n",
    "    title_prefix : str\n",
    "        Prefix for the figure title\n",
    "    is_difference : bool\n",
    "        If True, values are treated as differences from baseline\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as patches\n",
    "    import matplotlib.colors as colors\n",
    "    \n",
    "    # Unpack the number of blocks in each dimension\n",
    "    nx, ny, nz = num_blocks\n",
    "    \n",
    "    # Convert losses to numpy array if it isn't already\n",
    "    losses = np.array(losses)\n",
    "    \n",
    "    # Print the actual loss values for debugging\n",
    "    print(\"Loss/difference values for each block:\")\n",
    "    for i, val in enumerate(losses):\n",
    "        print(f\"  Block {i+1}: {val:.5f}\")\n",
    "    \n",
    "    # Verify number of loss values matches number of blocks\n",
    "    total_blocks = nx * ny * nz\n",
    "    if len(losses) != total_blocks:\n",
    "        raise ValueError(f\"Expected {total_blocks} loss values, but got {len(losses)}\")\n",
    "    \n",
    "    # Find the block with the highest absolute loss/difference\n",
    "    max_abs_loss_idx = np.argmax(np.abs(losses))\n",
    "    # Convert to 1-based indexing for block ID\n",
    "    selected_block = max_abs_loss_idx + 1\n",
    "    max_abs_loss_value = losses[max_abs_loss_idx]\n",
    "    \n",
    "    if is_difference:\n",
    "        print(f\"Block {selected_block} has the highest absolute difference from baseline: {max_abs_loss_value:.5f}\")\n",
    "    else:\n",
    "        print(f\"Block {selected_block} has the highest absolute loss: {max_abs_loss_value:.5f}\")\n",
    "    \n",
    "    # If figsize is not specified, calculate it based on number of z layers\n",
    "    if figsize is None:\n",
    "        figsize = (6 * nz, 6)\n",
    "    \n",
    "    # Create the figure with the appropriate number of subplots (one per z-layer)\n",
    "    fig, axes = plt.subplots(1, nz, figsize=figsize)\n",
    "    if nz == 1:\n",
    "        axes = [axes]  # Make sure axes is always a list for consistency\n",
    "    \n",
    "    title_text = f\"{title_prefix} {nx}x{ny}x{nz} Blocks\"\n",
    "    if is_difference:\n",
    "        title_text += \" with Differences from Baseline\"\n",
    "    else:\n",
    "        title_text += \" with Loss Values\"\n",
    "        \n",
    "    fig.suptitle(title_text, fontsize=16)\n",
    "    \n",
    "    # Get block division boundaries\n",
    "    x_divisions = []\n",
    "    y_divisions = []\n",
    "    z_divisions = []\n",
    "    \n",
    "    for block_id, ((x_min, x_max), (y_min, y_max), (z_min, z_max)) in blocks.items():\n",
    "        x_divisions.extend([x_min, x_max])\n",
    "        y_divisions.extend([y_min, y_max])\n",
    "        z_divisions.extend([z_min, z_max])\n",
    "    \n",
    "    # Get unique boundary values\n",
    "    x_divisions = sorted(list(set(x_divisions)))\n",
    "    y_divisions = sorted(list(set(y_divisions)))\n",
    "    z_divisions = sorted(list(set(z_divisions)))\n",
    "    \n",
    "    # Print the division boundaries\n",
    "    print(\"X divisions:\", x_divisions)\n",
    "    print(\"Y divisions:\", y_divisions)\n",
    "    print(\"Z divisions:\", z_divisions)\n",
    "    \n",
    "    # Create a colormap normalization based on min/max loss values\n",
    "    if is_difference and colormap == 'coolwarm':\n",
    "        # For differences, we want a symmetric colormap centered at zero\n",
    "        max_abs = max(abs(np.min(losses)), abs(np.max(losses)))\n",
    "        norm = colors.Normalize(vmin=-max_abs, vmax=max_abs)\n",
    "    else:\n",
    "        # For absolute values or when not specifically using coolwarm for differences\n",
    "        norm = colors.Normalize(vmin=np.min(losses), vmax=np.max(losses))\n",
    "        \n",
    "    cmap = plt.cm.get_cmap(colormap)\n",
    "    \n",
    "    # Process each z-layer\n",
    "    for z_idx in range(nz):\n",
    "        # Get z-boundaries for this layer\n",
    "        z_min = z_divisions[z_idx]\n",
    "        z_max = z_divisions[z_idx + 1]\n",
    "        \n",
    "        # Create layer name with actual z-range\n",
    "        layer_name = f\"Layer {z_idx} (z={z_min}-{z_max-1})\"\n",
    "        \n",
    "        # Extract the data for this z-layer\n",
    "        layer_data = data_3d[:, :, z_min:z_max]\n",
    "        \n",
    "        # Create maximum intensity projection along z-axis for just this layer\n",
    "        layer_projection = np.max(layer_data > 0, axis=2).astype(float)\n",
    "        print(f\"Max layer_projection for layer {z_idx}=\", np.max(layer_projection))\n",
    "        \n",
    "        # Create a brain mask - identifies where brain tissue exists\n",
    "        brain_mask = layer_projection > 0\n",
    "        \n",
    "        # Plot black background\n",
    "        axes[z_idx].imshow(np.zeros_like(layer_projection), cmap='gray', origin='lower')\n",
    "        axes[z_idx].set_title(layer_name)\n",
    "        \n",
    "        # Add colored blocks and loss values for this layer\n",
    "        for y_idx in range(ny):\n",
    "            for x_idx in range(nx):\n",
    "                # Calculate block ID (1-based index) using the formula:\n",
    "                # block_id = 1 + x_idx + y_idx * nx + z_idx * nx * ny\n",
    "                block_id = 1 + x_idx + y_idx * nx + z_idx * nx * ny\n",
    "                \n",
    "                # Get loss value for this block (subtract 1 for 0-based indexing)\n",
    "                if block_id <= len(losses):\n",
    "                    loss_value = losses[block_id - 1]\n",
    "                else:\n",
    "                    print(f\"Warning: Block ID {block_id} exceeds losses array length {len(losses)}\")\n",
    "                    loss_value = 0\n",
    "                \n",
    "                # Get x, y boundaries for this block\n",
    "                x_min, x_max = x_divisions[x_idx], x_divisions[x_idx + 1]\n",
    "                y_min, y_max = y_divisions[y_idx], y_divisions[y_idx + 1]\n",
    "                \n",
    "                # Calculate center of block in data coordinates\n",
    "                x_center = (x_min + x_max) / 2\n",
    "                y_center = (y_min + y_max) / 2\n",
    "                \n",
    "                # Get color from colormap based on loss value\n",
    "                block_color = cmap(norm(loss_value))\n",
    "                \n",
    "                # Create a mask for this block\n",
    "                block_mask = np.zeros_like(layer_projection, dtype=bool)\n",
    "                block_mask[x_min:x_max, y_min:y_max] = True\n",
    "                \n",
    "                # Combine with brain mask to only color brain regions\n",
    "                block_brain_mask = block_mask & brain_mask\n",
    "                \n",
    "                # If there are brain voxels in this block, add the colored overlay\n",
    "                if np.any(block_brain_mask):\n",
    "                    # Create a colored overlay image for this block\n",
    "                    colored_overlay = np.zeros((*layer_projection.shape, 4))  # RGBA\n",
    "                    colored_overlay[block_brain_mask, :] = block_color\n",
    "                    \n",
    "                    # Add the colored overlay to the plot\n",
    "                    axes[z_idx].imshow(colored_overlay, origin='lower', interpolation='nearest')\n",
    "                \n",
    "                # Format the displayed value\n",
    "                if is_difference:\n",
    "                    # For differences, show sign and format based on magnitude\n",
    "                    if abs(loss_value) >= 0.01:\n",
    "                        value_str = f\"{loss_value:.4f}\"\n",
    "                    else:\n",
    "                        value_str = f\"{loss_value:.2e}\"\n",
    "                else:\n",
    "                    # For absolute values\n",
    "                    value_str = f\"{loss_value:.4f}\"\n",
    "                \n",
    "                # Add block ID and loss value label with a bounding box\n",
    "                text_box = dict(facecolor='black', alpha=0.7, boxstyle='round')\n",
    "                \n",
    "                # Place the text in the center of the block\n",
    "                axes[z_idx].text(y_center, x_center, f\"{block_id}\\n{value_str}\", \n",
    "                               ha=\"center\", va=\"center\", color='white', fontweight='bold',\n",
    "                               fontsize=10, bbox=text_box)\n",
    "                \n",
    "                # Highlight the block with the highest absolute loss/difference\n",
    "                if block_id == selected_block:\n",
    "                    highlight_rect = patches.Rectangle(\n",
    "                        (y_min, x_min), y_max-y_min, x_max-x_min,\n",
    "                        fill=False, edgecolor='red', linewidth=2\n",
    "                    )\n",
    "                    axes[z_idx].add_patch(highlight_rect)\n",
    "    \n",
    "    # Add a colorbar to show the mapping between loss values and colors\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    \n",
    "    # Create a separate axis for the colorbar below the brain images\n",
    "    cax = fig.add_axes([0.15, 0.05, 0.7, 0.02])  # [left, bottom, width, height]\n",
    "    cbar = fig.colorbar(sm, cax=cax, orientation='horizontal')\n",
    "    \n",
    "    if is_difference:\n",
    "        cbar.set_label('Difference from Baseline')\n",
    "    else:\n",
    "        cbar.set_label('Loss Value')\n",
    "    \n",
    "    # Adjust layout to make room for colorbar\n",
    "    plt.tight_layout(rect=[0, 0.1, 1, 0.95])\n",
    "    plt.show()\n",
    "    \n",
    "    # Save figure if requested\n",
    "    if hasattr(plt, 'savefig'):\n",
    "        suffix = \"differences\" if is_difference else \"losses\"\n",
    "        plt.savefig(f'brain_blocks_{nx}x{ny}x{nz}_{suffix}_colormap.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return blocks\n",
    "\n",
    "\n",
    "\n",
    "def calculate_baseline_losses(model_name='decoder_4609_350', test_input=None, test_label=None, \n",
    "                           all_frames=True, save_plots=False, metric=\"tv\", zones=4):\n",
    "    \"\"\"\n",
    "    Calculate baseline reconstruction losses without any perturbation\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_name : str\n",
    "        Name of the model file to be used\n",
    "    test_input : dict\n",
    "        Dictionary with fMRIs for testing\n",
    "    test_label : dict\n",
    "        Dictionary with films\n",
    "    all_frames : bool\n",
    "        If True, runs test_model_all, otherwise runs test_model\n",
    "    save_plots : bool\n",
    "        If True, saves plots\n",
    "    metric : str\n",
    "        Metric to use for evaluation: \"ssim\" or \"tv\" (Total Variation)\n",
    "    zones : str or int\n",
    "        Zone configuration for analysis\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with baseline losses for each zone\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    print(\"Calculating baseline losses with no perturbation\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = Decoder(mask_size)\n",
    "    state_dict = torch.load(model_name)\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    # Testing parameters\n",
    "    criterion = D_Loss()\n",
    "    device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "    pretrained_decoder = None\n",
    "    model_to_test = 'decoder'\n",
    "    statistical_testing = False\n",
    "    display_plots = True\n",
    "    \n",
    "    # Run test_model_all without perturbation to get baseline performance\n",
    "    if all_frames:\n",
    "        baseline_results = test_model_all(\n",
    "            test_input, \n",
    "            test_label, \n",
    "            model, \n",
    "            criterion, \n",
    "            device, \n",
    "            pretrained_decoder, \n",
    "            model_to_test, \n",
    "            statistical_testing, \n",
    "            display_plots, \n",
    "            save_plots, \n",
    "            model_name=model_name + '_baseline', \n",
    "            metric=metric, \n",
    "            mean_flag=False,\n",
    "            zones=zones\n",
    "        )\n",
    "        print(\"Baseline test completed\")\n",
    "        return baseline_results['test_performance']\n",
    "    else:\n",
    "        test_model(\n",
    "            test_input, \n",
    "            test_label, \n",
    "            model, \n",
    "            criterion, \n",
    "            device, \n",
    "            pretrained_decoder, \n",
    "            model_to_test, \n",
    "            statistical_testing, \n",
    "            display_plots, \n",
    "            save_plots, \n",
    "            model_name=model_name + '_baseline'\n",
    "        )\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "def test_new_decoder(real=True, model_name='decoder_4609_1650', test_on_train=False, test_input=testset['fMRIs'], \n",
    "                     test_label=testset['videos'], add_name='', regions=[], block_id=None, save_plots=False, all_frames=False,\n",
    "                     change_mode='off', num_blocks=None, metric=\"ssim\", zones=None, compare_to_baseline=True):\n",
    "    '''\n",
    "    Tests the decoder with brain block analysis\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    real : bool\n",
    "        If True, tests on real brain activity; if False, tests on brain activity from encoder\n",
    "    model_name : str\n",
    "        Name of the model file to be used\n",
    "    test_on_train : bool\n",
    "        If True, tests on the training set\n",
    "    test_input : dict\n",
    "        Dictionary with fMRIs for testing (one subdictionary for each film)\n",
    "    test_label : dict\n",
    "        Dictionary with films (one subdictionary for each film)\n",
    "    add_name : str\n",
    "        String to add to the end of output name to avoid overwriting\n",
    "    regions : list\n",
    "        List of region IDs to turn off (legacy parameter, use block_id instead)\n",
    "    block_id : int\n",
    "        ID of the 3D block to turn off (1-27)\n",
    "    save_plots : bool\n",
    "        If True, saves plots\n",
    "    all_frames : bool\n",
    "        If True, runs test_model_all, otherwise runs test_model\n",
    "    change_mode : str\n",
    "        'off' or 'amplify'\n",
    "    zones (str or int, optional): Zones to consider for testing. Default is \"quadrants\", can also be \"center_bg\".\n",
    "                                  If it is an integer, the function will analyze a number of zones = that integer squared.\n",
    "                                  For example, if zones = 4, the function will analyze 16 zones (4x4).\n",
    "    compare_to_baseline : bool\n",
    "        If True, compute baseline performance without perturbation and report differences\n",
    "\n",
    "    '''\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as patches\n",
    "    import pickle\n",
    "    import os\n",
    "\n",
    "    print(\"zones = \", zones, \"\\n\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = Decoder(mask_size)\n",
    "    state_dict = torch.load(model_name)\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    # Testing parameters\n",
    "    criterion = D_Loss()\n",
    "    device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "    pretrained_decoder = None\n",
    "    model_to_test = 'decoder'\n",
    "    statistical_testing = False\n",
    "    display_plots = True\n",
    "    \n",
    "    # Handle special case for training data\n",
    "    if test_on_train:\n",
    "        num_samples = trainset[\"fMRIs\"].shape[0]\n",
    "        random_indices = np.random.choice(num_samples, size=30, replace=False)\n",
    "        testset2 = {\n",
    "            \"fMRIs\": {\n",
    "                \"test\": trainset[\"fMRIs\"][random_indices]\n",
    "            },\n",
    "            \"videos\": {\n",
    "                \"test\": trainset[\"videos\"][random_indices]\n",
    "            }\n",
    "        }\n",
    "        test_input = testset2['fMRIs']\n",
    "        test_label = testset2['videos']\n",
    "    \n",
    "    # Check if we're using a brain block\n",
    "    if num_blocks is not None:\n",
    "        # First, compute the baseline performance if requested\n",
    "        baseline_performance = None\n",
    "        if compare_to_baseline:\n",
    "            print(\"Computing baseline performance with no perturbation...\")\n",
    "            if all_frames:\n",
    "                baseline_results = test_model_all(\n",
    "                    test_input, \n",
    "                    test_label, \n",
    "                    model, \n",
    "                    criterion, \n",
    "                    device, \n",
    "                    pretrained_decoder, \n",
    "                    model_to_test, \n",
    "                    statistical_testing, \n",
    "                    display_plots, \n",
    "                    save_plots, \n",
    "                    model_name=model_name + '_baseline', \n",
    "                    metric=metric,\n",
    "                    mean_flag=False,\n",
    "                    zones=zones\n",
    "                )\n",
    "                baseline_performance = baseline_results['test_performance']\n",
    "                \n",
    "                # Save baseline performance\n",
    "                baseline_file = f'baseline_{model_name}_{metric}_zones{zones}.pkl'\n",
    "                with open(baseline_file, 'wb') as f:\n",
    "                    pickle.dump(baseline_performance, f)\n",
    "                print(f\"Baseline performance saved to {baseline_file}\")\n",
    "                \n",
    "                print(\"Baseline performance:\")\n",
    "                for k, v in baseline_performance.items():\n",
    "                    if isinstance(v, (int, float)):\n",
    "                        print(f\"  {k}: {v:.5f}\")\n",
    "            else:\n",
    "                # For now, assume baseline is not needed for non-all_frames mode\n",
    "                pass\n",
    "                \n",
    "        # Load the 3D brain data\n",
    "        regions_3d = load_and_reshape_data('region_ids_4609+.npy')\n",
    "\n",
    "        # Cut to the tightest rectangular prism around the brain\n",
    "        (x_min, x_max), (y_min, y_max), (z_min, z_max) = find_bounds(regions_3d)\n",
    "        brain_data = regions_3d[x_min:x_max+1, y_min:y_max+1, z_min:z_max+1]\n",
    "        print(f\"Original shape: {regions_3d.shape}, Brain shape: {brain_data.shape}\")\n",
    "\n",
    "        # Divide into blocks\n",
    "        blocks = divide_brain_into_blocks(brain_data, num_blocks)\n",
    "        \n",
    "        # Flatten the mask\n",
    "        mask4609 = np.load('mask_schaefer1000_4609.npy')\n",
    "        flat_mask = mask4609.flatten()\n",
    "\n",
    "        if block_id is not None:  # If some block is specified\n",
    "            for video_name in test_input.keys():\n",
    "                print(f\"Turning off block {block_id} for video {video_name}\")\n",
    "\n",
    "                visualize_blocks(brain_data, blocks, num_blocks=num_blocks, selected_block=block_id)\n",
    "                \n",
    "                # Use the existing turn_off_regions function for the regions in this block\n",
    "                if change_mode == 'off':\n",
    "                    modified_data = turn_off_block_new(test_input[video_name], flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "                else:\n",
    "                    modified_data = turn_off_block_new(test_input[video_name], flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "                \n",
    "                modified_input[video_name] = modified_data\n",
    "                \n",
    "            # Use the modified input for testing\n",
    "            test_input = modified_input\n",
    "\n",
    "            if all_frames:\n",
    "                results = test_model_all(\n",
    "                    test_input, \n",
    "                    test_label, \n",
    "                    model, \n",
    "                    criterion, \n",
    "                    device, \n",
    "                    pretrained_decoder, \n",
    "                    model_to_test, \n",
    "                    statistical_testing, \n",
    "                    display_plots, \n",
    "                    save_plots, \n",
    "                    model_name=model_name + add_name, \n",
    "                    metric=metric\n",
    "                )\n",
    "                \n",
    "                # Compare with baseline if available\n",
    "                if baseline_performance is not None:\n",
    "                    print(\"\\nComparison with baseline:\")\n",
    "                    block_performance = results['test_performance']\n",
    "                    \n",
    "                    # Get the main metric based on metric type\n",
    "                    main_metric_key = f'mean_{metric}_D'\n",
    "                    if main_metric_key in baseline_performance and main_metric_key in block_performance:\n",
    "                        baseline_val = baseline_performance[main_metric_key]\n",
    "                        block_val = block_performance[main_metric_key]\n",
    "                        diff = block_val - baseline_val\n",
    "                        \n",
    "                        print(f\"  {main_metric_key}: {block_val:.5f} (baseline: {baseline_val:.5f}, diff: {diff:.5f})\")\n",
    "                    \n",
    "                    # Compare zone-specific metrics\n",
    "                    for k in baseline_performance.keys():\n",
    "                        if k.startswith('mean_') and k != main_metric_key and k in block_performance:\n",
    "                            baseline_val = baseline_performance[k]\n",
    "                            block_val = block_performance[k]\n",
    "                            diff = block_val - baseline_val\n",
    "                            print(f\"  {k}: {block_val:.5f} (baseline: {baseline_val:.5f}, diff: {diff:.5f})\")\n",
    "                            \n",
    "                return results\n",
    "            else:\n",
    "                test_model(\n",
    "                    test_input, \n",
    "                    test_label, \n",
    "                    model, \n",
    "                    criterion, \n",
    "                    device, \n",
    "                    pretrained_decoder, \n",
    "                    model_to_test, \n",
    "                    statistical_testing, \n",
    "                    display_plots, \n",
    "                    save_plots, \n",
    "                    model_name=model_name + add_name\n",
    "                )\n",
    "                return None\n",
    "\n",
    "        elif block_id is None:  # Loop through all blocks\n",
    "            losses = []\n",
    "            loss_diffs = []  # Store differences from baseline\n",
    "            \n",
    "            # Create a dictionary to store detailed results for each block\n",
    "            block_results = {}\n",
    "            \n",
    "            # Get baseline metric key based on metric type\n",
    "            main_metric_key = f'mean_{metric}_D'\n",
    "            \n",
    "            # Loop through all blocks\n",
    "            for block_id in range(1, num_blocks[0] * num_blocks[1] * num_blocks[2] + 1):\n",
    "                print(f\"\\nProcessing block {block_id}...\")\n",
    "                modified_input = {}\n",
    "                \n",
    "                for video_name in test_input.keys():\n",
    "                    # Turn off this block in the input data\n",
    "                    if change_mode == 'off':\n",
    "                        ffa_mask = np.load('enhanced_union_FFA.npy')\n",
    "                        brain_mask = np.load('mask_schaefer1000_4609.npy')\n",
    "\n",
    "                        # Find which voxels to zero out (intersection of brain mask and FFA mask)\n",
    "                        intersection = (brain_mask > 0) & (ffa_mask > 0)\n",
    "                        brain_indices = np.where(brain_mask.flatten())[0]\n",
    "                        ffa_indices = np.where(intersection.flatten())[0]\n",
    "                        voxels_to_zero = np.where(np.isin(brain_indices, ffa_indices))[0]\n",
    "\n",
    "                        # Create modified data\n",
    "                        modified_data = test_input[video_name].copy()\n",
    "                        print(\"\\n\\nmodified_data shape =\", modified_data.shape, \"\\n\\n\")\n",
    "                        modified_data[:, voxels_to_zero] = 0\n",
    "#                    modified_data = turn_off_block_new(test_input[video_name], flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "\n",
    "#                        modified_data = turn_off_block_new(test_input[video_name], flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "                    else:\n",
    "                        ffa_mask = np.load('enhanced_union_FFA.npy')\n",
    "                        brain_mask = np.load('mask_schaefer1000_4609.npy')\n",
    "\n",
    "                        # Find which voxels to zero out (intersection of brain mask and FFA mask)\n",
    "                        intersection = (brain_mask > 0) & (ffa_mask > 0)\n",
    "                        brain_indices = np.where(brain_mask.flatten())[0]\n",
    "                        ffa_indices = np.where(intersection.flatten())[0]\n",
    "                        voxels_to_zero = np.where(np.isin(brain_indices, ffa_indices))[0]\n",
    "\n",
    "                        # Create modified data\n",
    "                        modified_data = test_input[video_name].copy()\n",
    "                        print(\"\\n\\nmodified_data shape =\", modified_data.shape, \"\\n\\n\")\n",
    "                        modified_data[:, voxels_to_zero] = 0\n",
    "#                    modified_data = turn_off_block_new(test_input[video_name], flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "\n",
    "#                        modified_data = turn_off_block_new(test_input[video_name], flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "                    \n",
    "                    modified_input[video_name] = modified_data\n",
    "                    \n",
    "                # Test with this block turned off\n",
    "                if all_frames:\n",
    "                    results = test_model_all(\n",
    "                        modified_input, \n",
    "                        test_label, \n",
    "                        model, \n",
    "                        criterion, \n",
    "                        device, \n",
    "                        pretrained_decoder, \n",
    "                        model_to_test, \n",
    "                        statistical_testing, \n",
    "                        display_plots, \n",
    "                        save_plots, \n",
    "                        model_name=model_name + f'_block_{block_id}', \n",
    "                        metric=metric, \n",
    "                        mean_flag=False,  # Return full performance dict \n",
    "                        zones=zones\n",
    "                    )\n",
    "                    \n",
    "                    # Store the block's performance\n",
    "                    block_performance = results['test_performance']\n",
    "                    block_results[block_id] = block_performance\n",
    "                    \n",
    "                    # Get the main loss value\n",
    "                    if metric == \"tv\":\n",
    "                        mean_loss = block_performance.get(main_metric_key, 0)\n",
    "                    elif metric == \"ssim\":\n",
    "                        mean_loss = block_performance.get(main_metric_key, 0)\n",
    "                    \n",
    "                    print(f\"Block {block_id}, mean loss = {mean_loss:.5f}\")\n",
    "                    losses.append(mean_loss)\n",
    "                    \n",
    "                    # Calculate difference from baseline if available\n",
    "                    if baseline_performance is not None and main_metric_key in baseline_performance:\n",
    "                        baseline_val = baseline_performance[main_metric_key]\n",
    "                        diff = mean_loss - baseline_val\n",
    "                        loss_diffs.append(diff)\n",
    "                        print(f\"  Difference from baseline: {diff:.5f}\")\n",
    "                    else:\n",
    "                        loss_diffs.append(0)  # Default if baseline not available\n",
    "                    \n",
    "                else:\n",
    "                    test_model(\n",
    "                        modified_input, \n",
    "                        test_label, \n",
    "                        model, \n",
    "                        criterion, \n",
    "                        device, \n",
    "                        pretrained_decoder, \n",
    "                        model_to_test, \n",
    "                        statistical_testing, \n",
    "                        display_plots, \n",
    "                        save_plots, \n",
    "                        model_name=model_name + f'_block_{block_id}'\n",
    "                    )\n",
    "            \n",
    "            # Find the block with the biggest impact\n",
    "            if compare_to_baseline and baseline_performance is not None:\n",
    "                lossiest = np.argmax(np.abs(loss_diffs))\n",
    "                impact_val = loss_diffs[lossiest]\n",
    "            else:\n",
    "                lossiest = np.argmax(losses)\n",
    "                impact_val = losses[lossiest]\n",
    "                \n",
    "            lossiest_block = lossiest + 1  # Convert to 1-based indexing\n",
    "            print(f\"\\nBlock with the biggest impact: {lossiest_block} (value: {impact_val:.5f})\")\n",
    "                \n",
    "            # Visualize with appropriate values\n",
    "            if compare_to_baseline and baseline_performance is not None:\n",
    "                print(\"Visualizing differences from baseline...\")\n",
    "                visualize_blocks_3(\n",
    "                    brain_data,\n",
    "                    blocks,\n",
    "                    loss_diffs,  # Use differences from baseline\n",
    "                    num_blocks=num_blocks,\n",
    "                    colormap='coolwarm'  # Better for showing positive/negative differences\n",
    "                )\n",
    "            else:\n",
    "                print(\"Visualizing absolute loss values...\")\n",
    "                visualize_blocks_3(\n",
    "                    brain_data,\n",
    "                    blocks,\n",
    "                    losses,\n",
    "                    num_blocks=num_blocks,\n",
    "                    colormap='viridis'  # For absolute values\n",
    "                )\n",
    "            \n",
    "            # Save results\n",
    "            results_data = {\n",
    "                'losses': losses,\n",
    "                'baseline_performance': baseline_performance,\n",
    "                'loss_differences': loss_diffs if baseline_performance is not None else None,\n",
    "                'block_with_biggest_impact': lossiest_block,\n",
    "                'block_results': block_results\n",
    "            }\n",
    "            \n",
    "            results_file = f'block_analysis_{model_name}_{metric}_zones{zones}.pkl'\n",
    "            with open(results_file, 'wb') as f:\n",
    "                pickle.dump(results_data, f)\n",
    "            print(f\"Results saved to {results_file}\")\n",
    "            \n",
    "            return results_data\n",
    "\n",
    "    # Original code for regions list\n",
    "    elif regions:\n",
    "        # Specific regions case\n",
    "        fmri_regions_off = test_input.copy()\n",
    "        \n",
    "        for video_name in test_input.keys():\n",
    "            fmri_regions_off[video_name] = turn_off_regions(test_input[video_name], regions)\n",
    "            \n",
    "        test_input = fmri_regions_off\n",
    "    \n",
    "    print(\"test input shape =\", print_dict_tree(test_input))\n",
    "    print(\"test label shape =\", print_dict_tree(test_label))\n",
    "\n",
    "    # Run the appropriate test model function\n",
    "    # Do recall this code is just being used for the case we want regions, not blocks\n",
    "    if all_frames:\n",
    "        results = test_model_all(\n",
    "            test_input, \n",
    "            test_label, \n",
    "            model, \n",
    "            criterion, \n",
    "            device, \n",
    "            pretrained_decoder, \n",
    "            model_to_test, \n",
    "            statistical_testing, \n",
    "            display_plots, \n",
    "            save_plots, \n",
    "            model_name=model_name + add_name, \n",
    "            metric=metric, \n",
    "            mean_flag=True,\n",
    "            zones=zones\n",
    "        )\n",
    "        return results\n",
    "    else:\n",
    "        test_model(\n",
    "            test_input, \n",
    "            test_label, \n",
    "            model, \n",
    "            criterion, \n",
    "            device, \n",
    "            pretrained_decoder, \n",
    "            model_to_test, \n",
    "            statistical_testing, \n",
    "            display_plots, \n",
    "            save_plots, \n",
    "            model_name=model_name + add_name\n",
    "        )\n",
    "        return None\n",
    "\n",
    "'''\n",
    "def run_all_blocks_test():\n",
    "    \"\"\"\n",
    "    Run test with all blocks analysis, comparing to baseline performance\n",
    "    \"\"\"\n",
    "    # Call the test_new_decoder function with baseline comparison\n",
    "    results = test_new_decoder(\n",
    "        real=True,\n",
    "        model_name='decoder_4609_350',\n",
    "        test_input=filtered_trainset['fMRIs'],\n",
    "        test_label=filtered_trainset['videos'],\n",
    "        all_frames=True,\n",
    "        save_plots=False,\n",
    "        add_name='_block_analysis',\n",
    "        change_mode='off',\n",
    "        num_blocks=(2, 2, 2),\n",
    "        metric=\"tv\",\n",
    "        zones=4,\n",
    "        compare_to_baseline=True  # Enable baseline comparison\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Call the function to run the analysis\n",
    "results = run_all_blocks_test()\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_all_blocks_test():\n",
    "    \"\"\"\n",
    "    Run test with all blocks analysis, comparing to baseline performance\n",
    "    Shows difference in loss between perturbed and baseline reconstructions for each frame\n",
    "    \"\"\"\n",
    "    # Step 1: Calculate baseline reconstructions (no perturbation)\n",
    "    print(\"=== STEP 1: Calculating baseline reconstructions (no perturbation) ===\")\n",
    "    \n",
    "    #model_name = 'decoder_4609_350'\n",
    "    model_name = 'decoder_4936_201'\n",
    "    test_input = filtered_trainset['fMRIs']\n",
    "    test_label = filtered_trainset['videos']\n",
    "    num_blocks = (1, 1, 2)\n",
    "    metric = \"tv\"\n",
    "    zones = 4\n",
    "    save_plots = False\n",
    "    \n",
    "    # Load the model\n",
    "    model = Decoder(mask_size)\n",
    "    state_dict = torch.load(model_name)\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    # Testing parameters\n",
    "    criterion = D_Loss()\n",
    "    device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "    pretrained_decoder = None\n",
    "    model_to_test = 'decoder'\n",
    "    statistical_testing = False\n",
    "    display_plots = True\n",
    "    \n",
    "    # Generate baseline predictions\n",
    "    baseline_results = test_model_all(\n",
    "        test_input, \n",
    "        test_label, \n",
    "        model, \n",
    "        criterion, \n",
    "        device, \n",
    "        pretrained_decoder, \n",
    "        model_to_test, \n",
    "        statistical_testing, \n",
    "        display_plots=False,  # Don't display plots for baseline\n",
    "        save_plots=False,\n",
    "        model_name=model_name + '_baseline', \n",
    "        metric=metric, \n",
    "        mean_flag=False,\n",
    "        zones=zones\n",
    "    )\n",
    "    \n",
    "    # Save baseline performance metrics and predictions\n",
    "    baseline_performance = baseline_results['test_performance']\n",
    "    baseline_predictions = baseline_results['decoder_predictions']\n",
    "    \n",
    "    print(\"Baseline performance metrics:\")\n",
    "    for k, v in baseline_performance.items():\n",
    "        if isinstance(v, (int, float)):\n",
    "            print(f\"  {k}: {v:.5f}\")\n",
    "    \n",
    "    # Step 2: Run the perturbation analysis for each block\n",
    "    print(\"\\n=== STEP 2: Running perturbation analysis for each block ===\")\n",
    "    \n",
    "    # Load 3D brain data and prepare blocks\n",
    "    regions_3d = load_and_reshape_data('region_ids_4609+.npy')\n",
    "    (x_min, x_max), (y_min, y_max), (z_min, z_max) = find_bounds(regions_3d)\n",
    "    brain_data = regions_3d[x_min:x_max+1, y_min:y_max+1, z_min:z_max+1]\n",
    "    print(f\"Original shape: {regions_3d.shape}, Brain shape: {brain_data.shape}\")\n",
    "    \n",
    "    # Divide into blocks\n",
    "    blocks = divide_brain_into_blocks(brain_data, num_blocks)\n",
    "    \n",
    "    # Prepare mask for block manipulation\n",
    "    #mask4609 = np.load('mask_schaefer1000_4609.npy')\n",
    "    \n",
    "    mask4609 = np.load('mask_4609+ffa.npy')\n",
    "    flat_mask = mask4609.flatten()\n",
    "    \n",
    "    # Container for results\n",
    "    block_losses = []\n",
    "    loss_differences = []\n",
    "    block_results = {}\n",
    "    \n",
    "    # Main metric key based on chosen metric\n",
    "    main_metric_key = f'mean_{metric}_D'\n",
    "    \n",
    "    # Loop through all blocks\n",
    "    total_blocks = num_blocks[0] * num_blocks[1] * num_blocks[2]\n",
    "    for block_id in range(1, total_blocks + 1):\n",
    "        print(f\"\\nProcessing block {block_id}/{total_blocks}\")\n",
    "        \n",
    "        # Create modified input with current block turned off\n",
    "        modified_input = {}\n",
    "        for video_name in test_input.keys():\n",
    "            if block_id == 1:\n",
    "                print(\"\\n\\nDOING FFA NOW\\n\\n\")\n",
    "                ffa_mask = np.load('enhanced_union_FFA.npy')\n",
    "            else:\n",
    "                print(\"\\n\\nDOING PPA NOW\\n\\n\")\n",
    "                ffa_mask = np.load('resampled_ppa.npy')\n",
    "            #modified_data = turn_off_block_new(\n",
    "            #    test_input[video_name], \n",
    "            #    flat_mask, \n",
    "            #    block_id, \n",
    "            #    blocks, \n",
    "            #    x_min, \n",
    "            #    y_min, \n",
    "            #    z_min\n",
    "            #)\n",
    "            \n",
    "            #brain_mask = np.load('mask_schaefer1000_4609.npy')\n",
    "            brain_mask = np.load('mask_4609+ffa.npy')\n",
    "\n",
    "            # Find which voxels to zero out (intersection of brain mask and FFA mask)\n",
    "            intersection = (brain_mask > 0) & (ffa_mask > 0)\n",
    "            brain_indices = np.where(brain_mask.flatten())[0]\n",
    "            ffa_indices = np.where(intersection.flatten())[0]\n",
    "            voxels_to_zero = np.where(np.isin(brain_indices, ffa_indices))[0]\n",
    "            #print(f\"Zeroing out {len(voxels_to_zero)} voxels out of 4609 total ({100*len(voxels_to_zero)/4609:.1f}%)\")\n",
    "            print(f\"Zeroing out {len(voxels_to_zero)} voxels out of\" + str(mask_size) + f\"total ({100*len(voxels_to_zero)/mask_size:.1f}%)\")\n",
    "\n",
    "            # Create modified data\n",
    "            modified_data = test_input[video_name].copy()\n",
    "            print(\"\\n\\nmodified_data shape =\", modified_data.shape, \"\\n\\n\")\n",
    "            modified_data[:, voxels_to_zero] = 0\n",
    "#                    modified_data = turn_off_block_new(test_input[video_name], flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "\n",
    "#                        modified_data = turn_off_block_new(test_input[video_name], flat_mask, block_id, blocks, x_min, y_min, z_min)\n",
    "        \n",
    "            modified_input[video_name] = modified_data\n",
    "#            modified_input[video_name] = modified_data\n",
    "        \n",
    "        # Run test with this block turned off, passing baseline predictions for comparison\n",
    "        block_results = test_model_all(\n",
    "            modified_input, \n",
    "            test_label, \n",
    "            model, \n",
    "            criterion, \n",
    "            device, \n",
    "            pretrained_decoder, \n",
    "            model_to_test, \n",
    "            statistical_testing, \n",
    "            display_plots=True,  # Show plots with difference visualization\n",
    "            save_plots=save_plots, \n",
    "            model_name=model_name + f'_block_{block_id}', \n",
    "            metric=metric, \n",
    "            mean_flag=False,\n",
    "            zones=zones,\n",
    "            baseline_predictions=baseline_predictions  # Pass baseline predictions for frame-level comparison\n",
    "        )\n",
    "        \n",
    "        # Get the main metric value\n",
    "        block_performance = block_results['test_performance']\n",
    "        if main_metric_key in block_performance:\n",
    "            mean_loss = block_performance[main_metric_key]\n",
    "        else:\n",
    "            # If the key isn't found, try to find a similar key\n",
    "            metric_keys = [k for k in block_performance.keys() if metric in k.lower() and 'mean' in k.lower()]\n",
    "            mean_loss = block_performance[metric_keys[0]] if metric_keys else 0\n",
    "            \n",
    "        print(f\"Block {block_id} - Mean loss: {mean_loss:.5f}\")\n",
    "        block_losses.append(mean_loss)\n",
    "        \n",
    "        # Calculate difference from baseline\n",
    "        if main_metric_key in baseline_performance:\n",
    "            baseline_val = baseline_performance[main_metric_key]\n",
    "            diff = mean_loss - baseline_val\n",
    "            loss_differences.append(diff)\n",
    "            print(f\"  Difference from baseline: {diff:.5f}\")\n",
    "        else:\n",
    "            loss_differences.append(0)\n",
    "    \n",
    "    # Step 3: Visualize block-level results\n",
    "    print(\"\\n=== STEP 3: Visualizing block-level impact analysis ===\")\n",
    "    \n",
    "    # Find block with biggest impact\n",
    "    max_diff_idx = np.argmax(np.abs(loss_differences))\n",
    "    max_diff_block = max_diff_idx + 1\n",
    "    max_diff_value = loss_differences[max_diff_idx]\n",
    "    \n",
    "    print(f\"Block with biggest impact: {max_diff_block} (difference: {max_diff_value:.5f})\")\n",
    "    \n",
    "    # Visualize loss differences across blocks\n",
    "    visualize_blocks_3(\n",
    "        brain_data,\n",
    "        blocks,\n",
    "        loss_differences,  # Use differences from baseline\n",
    "        num_blocks=num_blocks,\n",
    "        colormap='coolwarm',  # Better for showing positive/negative differences\n",
    "        is_difference=True  # Indicate we're showing differences\n",
    "    )\n",
    "    \n",
    "    # Save all results\n",
    "    results_data = {\n",
    "        'baseline_performance': baseline_performance,\n",
    "        'block_losses': block_losses,\n",
    "        'loss_differences': loss_differences,\n",
    "        'max_impact_block': max_diff_block,\n",
    "        'max_impact_value': max_diff_value\n",
    "    }\n",
    "    \n",
    "    # Save to file\n",
    "    import pickle\n",
    "    results_file = f'block_analysis_{model_name}_{metric}_zones{zones}.pkl'\n",
    "    with open(results_file, 'wb') as f:\n",
    "        pickle.dump(results_data, f)\n",
    "    print(f\"Results saved to {results_file}\")\n",
    "    \n",
    "    return results_data\n",
    "\n",
    "# Call the function to run the analysis\n",
    "results = run_all_blocks_test()\n",
    "\n",
    "\n",
    "#i didnt include visualize blocks on this one\n",
    "def run_all_blocks_test_debug():\n",
    "    \"\"\"\n",
    "    Run test with all blocks analysis with extensive debugging\n",
    "    to find why all blocks have the same difference value\n",
    "    \"\"\"\n",
    "    # Step 1: Calculate baseline reconstructions (no perturbation)\n",
    "    print(\"=== STEP 1: Calculating baseline reconstructions (no perturbation) ===\")\n",
    "    \n",
    "    model_name = 'decoder_4609_350'\n",
    "    test_input = filtered_trainset['fMRIs']\n",
    "    test_label = filtered_trainset['videos']\n",
    "    num_blocks = (2, 2, 2)\n",
    "    metric = \"tv\"\n",
    "    zones = 4\n",
    "    save_plots = False\n",
    "    \n",
    "    # Load the model\n",
    "    model = Decoder(mask_size)\n",
    "    state_dict = torch.load(model_name)\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    # Testing parameters\n",
    "    criterion = D_Loss()\n",
    "    device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "    pretrained_decoder = None\n",
    "    model_to_test = 'decoder'\n",
    "    statistical_testing = False\n",
    "    display_plots = True\n",
    "    \n",
    "    # Generate baseline predictions\n",
    "    baseline_results = test_model_all(\n",
    "        test_input, \n",
    "        test_label, \n",
    "        model, \n",
    "        criterion, \n",
    "        device, \n",
    "        pretrained_decoder, \n",
    "        model_to_test, \n",
    "        statistical_testing, \n",
    "        display_plots=False,  # Don't display plots for baseline\n",
    "        save_plots=False,\n",
    "        model_name=model_name + '_baseline', \n",
    "        metric=metric, \n",
    "        mean_flag=False,\n",
    "        zones=zones\n",
    "    )\n",
    "    \n",
    "    # Save baseline performance metrics and predictions\n",
    "    baseline_performance = baseline_results['test_performance']\n",
    "    baseline_predictions = baseline_results['decoder_predictions']\n",
    "    \n",
    "    print(\"\\n==== DEBUG: Baseline performance metrics ====\")\n",
    "    for k, v in baseline_performance.items():\n",
    "        if isinstance(v, (int, float)):\n",
    "            print(f\"  {k}: {v}\")\n",
    "    \n",
    "    # Identify the main metric key we'll be using\n",
    "    if metric == \"tv\":\n",
    "        main_keys = [k for k in baseline_performance.keys() if 'tv' in k.lower() and 'mean' in k.lower()]\n",
    "    else:\n",
    "        main_keys = [k for k in baseline_performance.keys() if 'ssim' in k.lower() and 'mean' in k.lower()]\n",
    "    \n",
    "    print(f\"\\n==== DEBUG: Available metric keys: {main_keys} ====\")\n",
    "    \n",
    "    # Determine the main metric key to use\n",
    "    main_metric_key = f'mean_{metric}_D'\n",
    "    if main_metric_key not in baseline_performance:\n",
    "        if main_keys:\n",
    "            main_metric_key = main_keys[0]\n",
    "            print(f\"Main metric key '{main_metric_key}' not found. Using '{main_metric_key}' instead.\")\n",
    "        else:\n",
    "            print(f\"ERROR: No suitable metric keys found in baseline performance!\")\n",
    "            return None\n",
    "    \n",
    "    baseline_val = baseline_performance[main_metric_key]\n",
    "    print(f\"Using main metric key: {main_metric_key} with baseline value: {baseline_val}\")\n",
    "    \n",
    "    # Step 2: Run the perturbation analysis for each block\n",
    "    print(\"\\n=== STEP 2: Running perturbation analysis for each block ===\")\n",
    "    \n",
    "    # Load 3D brain data and prepare blocks\n",
    "    regions_3d = load_and_reshape_data('region_ids_4609+.npy')\n",
    "    (x_min, x_max), (y_min, y_max), (z_min, z_max) = find_bounds(regions_3d)\n",
    "    brain_data = regions_3d[x_min:x_max+1, y_min:y_max+1, z_min:z_max+1]\n",
    "    print(f\"Original shape: {regions_3d.shape}, Brain shape: {brain_data.shape}\")\n",
    "    \n",
    "    # Divide into blocks\n",
    "    blocks = divide_brain_into_blocks(brain_data, num_blocks)\n",
    "    \n",
    "    # Prepare mask for block manipulation\n",
    "    mask4609 = np.load('mask_schaefer1000_4609.npy')\n",
    "    flat_mask = mask4609.flatten()\n",
    "    \n",
    "    # Container for results\n",
    "    block_losses = []\n",
    "    loss_differences = []\n",
    "    block_results_dict = {}\n",
    "    \n",
    "    # Loop through a subset of blocks for debugging\n",
    "    total_blocks = num_blocks[0] * num_blocks[1] * num_blocks[2]\n",
    "    for block_id in range(1, total_blocks + 1):\n",
    "        print(f\"\\n==== PROCESSING BLOCK {block_id}/{total_blocks} ====\")\n",
    "        \n",
    "        # Create modified input with current block turned off\n",
    "        modified_input = {}\n",
    "        for video_name in test_input.keys():\n",
    "            modified_data = turn_off_block_new(\n",
    "                test_input[video_name], \n",
    "                flat_mask, \n",
    "                block_id, \n",
    "                blocks, \n",
    "                x_min, \n",
    "                y_min, \n",
    "                z_min\n",
    "            )\n",
    "            modified_input[video_name] = modified_data\n",
    "        \n",
    "        # Run test with this block turned off\n",
    "        block_results = test_model_all(\n",
    "            modified_input, \n",
    "            test_label, \n",
    "            model, \n",
    "            criterion, \n",
    "            device, \n",
    "            pretrained_decoder, \n",
    "            model_to_test, \n",
    "            statistical_testing, \n",
    "            display_plots=False,  # Don't show plots during debugging\n",
    "            save_plots=False, \n",
    "            model_name=model_name + f'_block_{block_id}', \n",
    "            metric=metric, \n",
    "            mean_flag=False,\n",
    "            zones=zones,\n",
    "            baseline_predictions=None  # Don't pass baseline during debug - we'll compute differences manually\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n==== DEBUG: Block {block_id} Results ====\")\n",
    "        block_performance = block_results['test_performance']\n",
    "        block_results_dict[block_id] = block_performance\n",
    "        \n",
    "        # Show all metrics in block performance\n",
    "        for k, v in block_performance.items():\n",
    "            if isinstance(v, (int, float)):\n",
    "                print(f\"  {k}: {v}\")\n",
    "        \n",
    "        # Calculate actual block mean loss value\n",
    "        if main_metric_key in block_performance:\n",
    "            mean_loss = block_performance[main_metric_key]\n",
    "        else:\n",
    "            print(f\"WARNING: Main metric key '{main_metric_key}' not found in block_performance!\")\n",
    "            # Try to find similar keys\n",
    "            if metric == \"tv\":\n",
    "                similar_keys = [k for k in block_performance.keys() if 'tv' in k.lower() and 'mean' in k.lower()]\n",
    "            else:\n",
    "                similar_keys = [k for k in block_performance.keys() if 'ssim' in k.lower() and 'mean' in k.lower()]\n",
    "                \n",
    "            if similar_keys:\n",
    "                mean_loss = block_performance[similar_keys[0]]\n",
    "                print(f\"Using alternative key: {similar_keys[0]}\")\n",
    "            else:\n",
    "                mean_loss = 0\n",
    "                print(\"No similar keys found! Using 0.\")\n",
    "        \n",
    "        # Manually calculate the difference\n",
    "        diff = mean_loss - baseline_val\n",
    "        \n",
    "        print(f\"BLOCK {block_id}:\")\n",
    "        print(f\"  Raw loss value: {mean_loss}\")\n",
    "        print(f\"  Baseline value: {baseline_val}\")\n",
    "        print(f\"  Difference: {diff}\")\n",
    "        \n",
    "        # Store the values\n",
    "        block_losses.append(mean_loss)\n",
    "        loss_differences.append(diff)\n",
    "    \n",
    "    # Print all the collected values\n",
    "    print(\"\\n==== FINAL DEBUG: All collected values ====\")\n",
    "    print(\"Block Losses:\")\n",
    "    for i, loss in enumerate(block_losses):\n",
    "        print(f\"  Block {i+1}: {loss}\")\n",
    "    \n",
    "    print(\"\\nDifferences from baseline:\")\n",
    "    for i, diff in enumerate(loss_differences):\n",
    "        print(f\"  Block {i+1}: {diff}\")\n",
    "    \n",
    "    # For testing, try a different approach to calculate differences\n",
    "    print(\"\\nRecalculating differences to double-check:\")\n",
    "    for i, loss in enumerate(block_losses):\n",
    "        recalc_diff = loss - baseline_val\n",
    "        print(f\"  Block {i+1}: Loss={loss}, Baseline={baseline_val}, Diff={recalc_diff}\")\n",
    "    \n",
    "    # Find block with biggest impact\n",
    "    max_diff_idx = np.argmax(np.abs(loss_differences))\n",
    "    max_diff_block = max_diff_idx + 1\n",
    "    max_diff_value = loss_differences[max_diff_idx]\n",
    "    \n",
    "    print(f\"\\nBlock with biggest impact: {max_diff_block} (difference: {max_diff_value})\")\n",
    "    \n",
    "    # Return the debug data for inspection\n",
    "    debug_data = {\n",
    "        'baseline_performance': baseline_performance,\n",
    "        'baseline_value': baseline_val,\n",
    "        'main_metric_key': main_metric_key,\n",
    "        'block_losses': block_losses,\n",
    "        'loss_differences': loss_differences,\n",
    "        'block_results': block_results_dict\n",
    "    }\n",
    "    \n",
    "    return debug_data\n",
    "\n",
    "# Run the debug function\n",
    "#debug_results = run_all_blocks_test_debug()\n",
    "\n",
    "#tag blocks with original and perturbed reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e59e67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearnin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
